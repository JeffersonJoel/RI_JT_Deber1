{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b46eda1da079473982209305d673e3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6654a5ce797a4863bb2ffc326e7b83a9",
              "IPY_MODEL_8ef50d8494f94a67b165b0f4e85c2758",
              "IPY_MODEL_c416f52d60654c5fbc15f07ac01bba54"
            ],
            "layout": "IPY_MODEL_37727aadf3004a298e305c8f8c2bc0d0"
          }
        },
        "6654a5ce797a4863bb2ffc326e7b83a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f89ce905474f23b0da957185dc6010",
            "placeholder": "​",
            "style": "IPY_MODEL_45f28cd635bc4050a9395ab7c2e3ff7b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8ef50d8494f94a67b165b0f4e85c2758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2868e9638354bcaabec4874eccc7e5a",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc0a60186fa64ce8af14320ef2d1997a",
            "value": 48
          }
        },
        "c416f52d60654c5fbc15f07ac01bba54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0156988a61540709c90529e5835044e",
            "placeholder": "​",
            "style": "IPY_MODEL_9fa9566e61c040c89c3da5f5389d18fe",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.73kB/s]"
          }
        },
        "37727aadf3004a298e305c8f8c2bc0d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f89ce905474f23b0da957185dc6010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f28cd635bc4050a9395ab7c2e3ff7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2868e9638354bcaabec4874eccc7e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0a60186fa64ce8af14320ef2d1997a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0156988a61540709c90529e5835044e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fa9566e61c040c89c3da5f5389d18fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e59ea67ad8db4e81b6d3319c49c51ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d35655c190c34bdba475e2b3ff3e4abf",
              "IPY_MODEL_16bb2b3bba9d4b1088a9ec1e5a9218ea",
              "IPY_MODEL_98153321b1824ff5b206a93bfb8cd74b"
            ],
            "layout": "IPY_MODEL_c91b3f353fc447f8aafd4c3846b7b716"
          }
        },
        "d35655c190c34bdba475e2b3ff3e4abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dccc3d1e1c0b4755b4186e21ae4c9bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_52a347dd66274d4b966ee1c09db56753",
            "value": "vocab.txt: 100%"
          }
        },
        "16bb2b3bba9d4b1088a9ec1e5a9218ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ea4ed8f0724db29c343e4303dfec38",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73e1dac54a264538a13561463bf8d198",
            "value": 231508
          }
        },
        "98153321b1824ff5b206a93bfb8cd74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da8435e826b4d4492584875e25477bf",
            "placeholder": "​",
            "style": "IPY_MODEL_67ad53c9850b416e89aebf168c2bd36a",
            "value": " 232k/232k [00:00&lt;00:00, 677kB/s]"
          }
        },
        "c91b3f353fc447f8aafd4c3846b7b716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccc3d1e1c0b4755b4186e21ae4c9bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a347dd66274d4b966ee1c09db56753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ea4ed8f0724db29c343e4303dfec38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e1dac54a264538a13561463bf8d198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7da8435e826b4d4492584875e25477bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ad53c9850b416e89aebf168c2bd36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d911a0b72dd64068837db0561769ebf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df85ebc1ea3e46be844552e1ccf99d2a",
              "IPY_MODEL_568bdcd6f8234fb88621a48dd255d762",
              "IPY_MODEL_b3b2d668eecf4879bad9b67b384106fe"
            ],
            "layout": "IPY_MODEL_fa480ddc171640fd871d9601b2bd6794"
          }
        },
        "df85ebc1ea3e46be844552e1ccf99d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f86a58d27854e4f8cec469b44110dc8",
            "placeholder": "​",
            "style": "IPY_MODEL_beaf2f9bc7a948b1ba3e0eb9d78a1ffe",
            "value": "tokenizer.json: 100%"
          }
        },
        "568bdcd6f8234fb88621a48dd255d762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_940b79d26d4a43ad8d6c2e5c6ff7d4f2",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_185076c58401491abbc4134a1cd7ebc7",
            "value": 466062
          }
        },
        "b3b2d668eecf4879bad9b67b384106fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14557273c3b1403eb8c0806a4dfebd6f",
            "placeholder": "​",
            "style": "IPY_MODEL_f476010e050a473995790659e4d3f9cb",
            "value": " 466k/466k [00:00&lt;00:00, 898kB/s]"
          }
        },
        "fa480ddc171640fd871d9601b2bd6794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f86a58d27854e4f8cec469b44110dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beaf2f9bc7a948b1ba3e0eb9d78a1ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "940b79d26d4a43ad8d6c2e5c6ff7d4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185076c58401491abbc4134a1cd7ebc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14557273c3b1403eb8c0806a4dfebd6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f476010e050a473995790659e4d3f9cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d369f4327c3c40bead8de6badc36ae2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe7d6f17be44e0b91866ad20722c126",
              "IPY_MODEL_eff156f4b3fd46a4aea43bf6a83f9e56",
              "IPY_MODEL_f1970e95d98d4b2da0d87169a1b02b51"
            ],
            "layout": "IPY_MODEL_2ce49dc271e34bae99ac9e6c44f3f71e"
          }
        },
        "3fe7d6f17be44e0b91866ad20722c126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9128952178f34493b6e4cc9ab37b6cf4",
            "placeholder": "​",
            "style": "IPY_MODEL_f0dde6d2ae3c475eb9d1d43a59973f3d",
            "value": "config.json: 100%"
          }
        },
        "eff156f4b3fd46a4aea43bf6a83f9e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd61cc41c3154062ba71eca6ff404b66",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75174c8ddea54fa9abaa1f3d922fcfed",
            "value": 570
          }
        },
        "f1970e95d98d4b2da0d87169a1b02b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05d502e10a84b5db2c7ee79c0c35875",
            "placeholder": "​",
            "style": "IPY_MODEL_4658afc476ec4298b85ee6f07ff59834",
            "value": " 570/570 [00:00&lt;00:00, 34.3kB/s]"
          }
        },
        "2ce49dc271e34bae99ac9e6c44f3f71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9128952178f34493b6e4cc9ab37b6cf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dde6d2ae3c475eb9d1d43a59973f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd61cc41c3154062ba71eca6ff404b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75174c8ddea54fa9abaa1f3d922fcfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b05d502e10a84b5db2c7ee79c0c35875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4658afc476ec4298b85ee6f07ff59834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23195e6157d34b05b8259f8d53f3324e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8aff3b2efc5a4598919df79da0dd5a7b",
              "IPY_MODEL_3425e9af1a064f37889aa72f04cd52ff",
              "IPY_MODEL_b2de67991d8d48a182a9cb6179c85503"
            ],
            "layout": "IPY_MODEL_7b2e0a4976ab4c42b7c5aa54e08bc5f2"
          }
        },
        "8aff3b2efc5a4598919df79da0dd5a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e53bee0ef0341d692c035be884d01f1",
            "placeholder": "​",
            "style": "IPY_MODEL_e6f5bcd9d8494012983cc2c3e406211b",
            "value": "model.safetensors: 100%"
          }
        },
        "3425e9af1a064f37889aa72f04cd52ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d909f8d64fbf4963ad60265a3e9f8936",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81158416b7554322959e1b9c1e07d2c6",
            "value": 440449768
          }
        },
        "b2de67991d8d48a182a9cb6179c85503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf1e456ddcbb4fef88347f028acd2f7e",
            "placeholder": "​",
            "style": "IPY_MODEL_10c9c16ff6914d10ba02b9dc4c95a8d3",
            "value": " 440M/440M [00:01&lt;00:00, 263MB/s]"
          }
        },
        "7b2e0a4976ab4c42b7c5aa54e08bc5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e53bee0ef0341d692c035be884d01f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f5bcd9d8494012983cc2c3e406211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d909f8d64fbf4963ad60265a3e9f8936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81158416b7554322959e1b9c1e07d2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf1e456ddcbb4fef88347f028acd2f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c9c16ff6914d10ba02b9dc4c95a8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
        "\n",
        "## Objective:\n",
        "\n",
        "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results.\n",
        "\n",
        "## Instructions:\n",
        "### Step 1: Import Libraries\n",
        "\n",
        "Import necessary libraries for data handling, text processing, and machine learning.\n",
        "\n",
        "### Step 2: Load the Dataset\n",
        "\n",
        "Load the dataset of podcast transcripts.\n",
        "\n",
        "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript\n",
        "\n",
        "### Step 3: Text Preprocessing\n",
        "\n",
        "You know what to do ;)\n",
        "\n",
        "### Step 4: Vector Space Representation - TF-IDF\n",
        "\n",
        "Create TF-IDF vector representations of the transcripts.\n",
        "\n",
        "### Step 5: Vector Space Representation - BERT\n",
        "\n",
        "Create BERT vector representations of the transcripts using a pre-trained BERT model.\n",
        "\n",
        "### Step 6: Query Processing\n",
        "\n",
        "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings.\n",
        "\n",
        "### Step 7: Retrieve and Compare Results\n",
        "\n",
        "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n",
        "\n",
        "### Step 8: Test the IR System\n",
        "\n",
        "Test the system with a sample query.\n",
        "\n",
        "Retrieve and display the top results using both TF-IDF and BERT representations.\n",
        "\n",
        "### Step 9: Compare Results\n",
        "\n",
        "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
        "\n",
        "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "\n",
        "*   Follow the steps outlined above to implement the IR system.\n",
        "*   Run the provided code snippets to understand how each part of the system works.\n",
        "*   Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
        "*   Compare and analyze the results. Discuss the pros and cons of each method.\n",
        "*   Document your findings and any improvements you make to the system.\n"
      ],
      "metadata": {
        "id": "NA0_VSxOviFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import Libraries\n",
        "\n",
        "Import necessary libraries for data handling, text processing, and machine learning."
      ],
      "metadata": {
        "id": "OXdvk4v4DKgp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5x_h3atSpu8Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 2: Load the Dataset\n",
        "\n",
        "Load the dataset of podcast transcripts.\n"
      ],
      "metadata": {
        "id": "rK465DN1DcNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGmPGQHGDcvF",
        "outputId": "a59d1577-1bac-47a0-deb9-47b5fab5b6d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/bases_de_datos_para_colab/podcastdata_dataset.csv\", delimiter=\",\")\n",
        "print(df.head())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A7Vq-LQDs6k",
        "outputId": "3ce83e25-dd81-4dae-8179-cabdb9c7aa09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \n",
            "0  As part of MIT course 6S099, Artificial Genera...  \n",
            "1  As part of MIT course 6S099 on artificial gene...  \n",
            "2  You've studied the human mind, cognition, lang...  \n",
            "3  What difference between biological neural netw...  \n",
            "4  The following is a conversation with Vladimir ...  \n",
            "(319, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Text Preprocessing\n",
        "\n",
        "\n",
        "*   Delete punctuation\n",
        "*   Delete stop words\n",
        "\n"
      ],
      "metadata": {
        "id": "OogTTUS_EP90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df['text']\n",
        "print(corpus.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qijad-DCEUxY",
        "outputId": "ef4493b0-a7cf-4ba0-ef64-54b1ea0a764a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    As part of MIT course 6S099, Artificial Genera...\n",
            "1    As part of MIT course 6S099 on artificial gene...\n",
            "2    You've studied the human mind, cognition, lang...\n",
            "3    What difference between biological neural netw...\n",
            "4    The following is a conversation with Vladimir ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete punctuation"
      ],
      "metadata": {
        "id": "e9ELlPAhGrLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nopunct = []\n",
        "for doc in corpus:\n",
        "    corpus_nopunct.append(doc.lower().translate(str.maketrans('', '', string.punctuation)))\n"
      ],
      "metadata": {
        "id": "rvYOAvmqEvn9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nopunct[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn9SghyXykZC",
        "outputId": "f11eca36-e7f4-403d-818d-3703ed21411a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['as part of mit course 6s099 artificial general intelligence ive gotten the chance to sit down with max tegmark he is a professor here at mit hes a physicist spent a large part of his career studying the mysteries of our cosmological universe but hes also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence amongst many other things he is the cofounder of the future of life institute author of two books both of which i highly recommend first our mathematical universe second is life 30 hes truly an out of the box thinker and a fun personality so i really enjoy talking to him if youd like to see more of these videos in the future please subscribe and also click the little bell icon to make sure you dont miss any videos also twitter linkedin agimitedu if you wanna watch other lectures or conversations like this one better yet go read maxs book life 30 chapter seven on goals is my favorite its really where philosophy and engineering come together and it opens with a quote by dostoevsky the mystery of human existence lies not in just staying alive but in finding something to live for lastly i believe that every failure rewards us with an opportunity to learn and in that sense ive been very fortunate to fail in so many new and exciting ways and this conversation was no different ive learned about something called radio frequency interference rfi look it up apparently music and conversations from local radio stations can bleed into the audio that youre recording in such a way that it almost completely ruins that audio its an exceptionally difficult sound source to remove so ive gotten the opportunity to learn how to avoid rfi in the future during recording sessions ive also gotten the opportunity to learn how to use adobe audition and izotope rx 6 to do some noise some audio repair of course this is an exceptionally difficult noise to remove i am an engineer im not an audio engineer neither is anybody else in our group but we did our best nevertheless i thank you for your patience and i hope youre still able to enjoy this conversation do you think theres intelligent life out there in the universe lets open up with an easy question i have a minority view here actually when i give public lectures i often ask for a show of hands who thinks theres intelligent life out there somewhere else and almost everyone put their hands up and when i ask why theyll be like oh theres so many galaxies out there theres gotta be but im a numbers nerd right so when you look more carefully at it its not so clear at all when we talk about our universe first of all we dont mean all of space we actually mean i dont know you can throw me the universe if you want its behind you there its we simply mean the spherical region of space from which light has a time to reach us so far during the 148 billion year 138 billion years since our big bang theres more space here but this is what we call a universe because thats all we have access to so is there intelligent life here thats gotten to the point of building telescopes and computers my guess is no actually the probability of it happening on any given planet is some number we dont know what it is and what we do know is that the number cant be super high because theres over a billion earth like planets in the milky way galaxy alone many of which are billions of years older than earth and aside from some ufo believers there isnt much evidence that any superduran civilization has come here at all and so thats the famous fermi paradox right and then if you work the numbers what you find is that if you have no clue what the probability is of getting life on a given planet so it could be 10 to the minus 10 10 to the minus 20 or 10 to the minus two or any power of 10 is sort of equally likely if you wanna be really open minded that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away 10 to the 17 meters away 10 to the 18 by the time you get much less than 10 to the 16 already we pretty much know there is nothing else that close and when you get beyond 10 because they would have discovered us yeah they would have been discovered as long ago or if theyre really close we would have probably noted some engineering projects that theyre doing and if its beyond 10 to the 26 meters thats already outside of here so my guess is actually that we are the only life in here thats gotten the point of building advanced tech which i think is very puts a lot of responsibility on our shoulders not screw up i think people who take for granted that its okay for us to screw up have an accidental nuclear war or go extinct somehow because theres a sort of star trek like situation out there where some other life forms are gonna come and bail us out and it doesnt matter as much i think theyre leveling us into a false sense of security i think its much more prudent to say lets be really grateful for this amazing opportunity weve had and make the best of it just in case it is down to us so from a physics perspective do you think intelligent life so its unique from a sort of statistical view of the size of the universe but from the basic matter of the universe how difficult is it for intelligent life to come about the kind of advanced tech building life is implied in your statement that its really difficult to create something like a human species well i think what we know is that going from no life to having life that can do a level of tech theres some sort of two going beyond that than actually settling our whole universe with life theres some major roadblock there which is some great filter as its sometimes called which is tough to get through its either that roadblock is either behind us or in front of us im hoping very much that its behind us im super excited every time we get a new report from nasa saying they failed to find any life on mars im like yes awesome because that suggests that the hard part maybe it was getting the first ribosome or some very low level kind of stepping stone so that were home free because if thats true then the future is really only limited by our own imagination it would be much suckier if it turns out that this level of life is kind of a dime a dozen but maybe theres some other problem like as soon as a civilization gets advanced technology within a hundred years they get into some stupid fight with themselves and poof that would be a bummer yeah so youve explored the mysteries of the universe the cosmological universe the one thats sitting between us today i think youve also begun to explore the other universe which is sort of the mystery the mysterious universe of the mind of intelligence of intelligent life so is there a common thread between your interest or the way you think about space and intelligence oh yeah when i was a teenager i was already very fascinated by the biggest questions and i felt that the two biggest mysteries of all in science were our universe out there and our universe in here so its quite natural after having spent a quarter of a century on my career thinking a lot about this one that im now indulging in the luxury of doing research on this one its just so cool i feel the time is ripe now for you trans greatly deepening our understanding of this just start exploring this one yeah because i think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us and therefore dismiss all talk about artificial general intelligence as science fiction but from my perspective as a physicist i am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways and this is also a blob of quarks and electrons im not smarter than the water bottle because im made of different kinds of quarks im made of up quarks and down quarks exact same kind as this theres no secret sauce i think in me its all about the pattern of the information processing and this means that theres no law of physics saying that we cant create technology which can help us by being incredibly intelligent and help us crack mysteries that we couldnt in other words i think weve really only seen the tip of the intelligence iceberg so far yeah so the perceptronium yeah so you coined this amazing term its a hypothetical state of matter sort of thinking from a physics perspective what is the kind of matter that can help as youre saying subjective experience emerge consciousness emerge so how do you think about consciousness from this physics perspective very good question so again i think many people have underestimated our ability to make progress on this by convincing themselves its hopeless because somehow were missing some ingredient that we need theres some new consciousness particle or whatever i happen to think that were not missing anything and that its not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions its rather something at the higher level about the patterns of information processing and thats why i like to think about this idea of perceptronium what does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing i dont think i hate carbon chauvinism this attitude you have to be made of carbon atoms to be smart or conscious theres something about the information processing that this kind of matter performs yeah and you can see i have my favorite equations here describing various fundamental aspects of the world i feel that i think one day maybe someone whos watching this will come up with the equations that information processing has to satisfy to be conscious im quite convinced there is big discovery to be made there because lets face it we know that so many things are made up of information we know that some information processing is conscious because we are conscious but we also know that a lot of information processing is not conscious like most of the information processing happening in your brain right now is not conscious there are like 10 megabytes per second coming in even just through your visual system youre not conscious about your heartbeat regulation or most things even if i just ask you to like read what it says here you look at it and then oh now you know what it said but youre not aware of how the computation actually happened your consciousness is like the ceo that got an email at the end with the final answer so what is it that makes a difference i think thats both a great science mystery were actually studying it a little bit in my lab here at mit but i also think its just a really urgent question to answer for starters i mean if youre an emergency room doctor and you have an unresponsive patient coming in wouldnt it be great if in addition to having a ct scanner you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose and in the future imagine if we build robots or the machine that we can have really good conversations with which i think is very likely to happen wouldnt you want to know if your home helper robot is actually experiencing anything or just like a zombie i mean would you prefer it what would you prefer would you prefer that its actually unconscious so that you dont have to feel guilty about switching it off or giving boring chores or what would you prefer well certainly we would prefer i would prefer the appearance of consciousness but the question is whether the appearance of consciousness is different than consciousness itself and sort of to ask that as a question do you think we need to understand what consciousness is solve the hard problem of consciousness in order to build something like an agi system no i dont think that and i think we will probably be able to build things even if we dont answer that question but if we want to make sure that what happens is a good thing we better solve it first so its a wonderful controversy youre raising there where you have basically three points of view about the hard problem so there are two different points of view they both conclude that the hard problem of consciousness is bs on one hand you have some people like daniel dennett who say that consciousness is just bs because consciousness is the same thing as intelligence theres no difference so anything which acts conscious is conscious just like we are and then there are also a lot of people including many top ai researchers i know who say oh consciousness is just bullshit because of course machines can never be conscious theyre always going to be zombies you never have to feel guilty about how you treat them and then theres a third group of people including giulio tononi for example and krzysztof koch and a number of others i would put myself also in this middle camp who say that actually some information processing is conscious and some is not so lets find the equation which can be used to determine which it is and i think weve just been a little bit lazy kind of running away from this problem for a long time its been almost taboo to even mention the c word in a lot of circles because but we should stop making excuses this is a science question and there are ways we can even test any theory that makes predictions for this and coming back to this helper robot i mean so you said youd want your helper robot to certainly act conscious and treat you like have conversations with you and stuff i think so but wouldnt you would you feel would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder you know that was just zombie and was a faking emotion would you prefer that it actually had an experience or would you prefer that its actually not experiencing anything so you feel you dont have to feel guilty about what you do to it its such a difficult question because you know its like when youre in a relationship and you say well i love you and the other person said i love you back its like asking well do they really love you back or are they just saying they love you back dont you really want them to actually love you its hard to its hard to really know the difference between everything seeming like theres consciousness present theres intelligence present theres affection passion love and it actually being there im not sure do you have but like can i ask you a question about this like to make it a bit more pointed so mass general hospital is right across the river right yes suppose youre going in for a medical procedure and theyre like you know for anesthesia what were going to do is were going to give you muscle relaxants so you wont be able to move and youre going to feel excruciating pain during the whole surgery but you wont be able to do anything about it but then were going to give you this drug that erases your memory of it would you be cool about that whats the difference that youre conscious about it or not if theres no behavioral change right right thats a really thats a really clear way to put it thats yeah it feels like in that sense experiencing it is a valuable quality so actually being able to have subjective experiences at least in that case is valuable and i think we humans have a little bit of a bad track record also of making these self serving arguments that other entities arent conscious you know people often say oh these animals cant feel pain its okay to boil lobsters because we ask them if it hurt and they didnt say anything and now there was just a paper out saying lobsters do feel pain when you boil them and theyre banning it in switzerland and we did this with slaves too often and said oh they dont mind they dont maybe arent conscious or women dont have souls or whatever so im a little bit nervous when i hear people just take as an axiom that machines cant have experience ever i think this is just a really fascinating science question is what it is lets research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior so in terms of so if you think of a boston dynamics human or robot being sort of with a broom being pushed around it starts pushing on a consciousness question so let me ask do you think an agi system like a few neuroscientists believe needs to have a physical embodiment needs to have a body or something like a body no i dont think so you mean to have a conscious experience to have consciousness i do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans for sure but i dont think the physical embodiment is necessary after youve learned it to just have the experience think about when youre dreaming right your eyes are closed youre not getting any sensory input youre not behaving or moving in any way but theres still an experience there right and so clearly the experience that you have when you see something cool in your dreams isnt coming from your eyes its just the information processing itself in your brain which is that experience right but if i put it another way ill say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical you know a physical system is because you want to be able to preserve something in order to have a self you could argue would you need to have some kind of embodiment of self to want to preserve well now were getting a little bit anthropomorphic into anthropomorphizing things maybe talking about self preservation instincts i mean we are evolved organisms right so darwinian evolution endowed us and other evolved organism with a self preservation instinct because those that didnt have those self preservation genes we can now i think quite convincingly answer that question of no its enough to have just one kind if you look under the hood of alphazero theres only one kind of neuron and its ridiculously simple mathematical thing so its just like in physics its not if you have a gas with waves in it its not the detailed nature of the molecule that matter its the collective behavior somehow similarly its this higher level structure of the network that matters not that you have 20 kinds of neurons i think our brain is such a complicated mess because it wasnt evolved just to be intelligent it was involved to also be self assembling and self repairing right and evolutionarily attainable and so on and so on so i think its pretty my hunch is that were going to understand how to build agi before we fully understand how our brains work just like we understood how to build flying machines long before we were able to build a mechanical bird yeah thats right youve given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight and even now after 100 years later did you see the ted talk with this german mechanical bird i heard you mention it check it out its amazing but even after that right we still dont fly in mechanical birds because it turned out the way we came up with was simpler and its better for our purposes and i think it might be the same there thats one lesson and another lesson its more what our paper was about first as a physicist thought it was fascinating how theres a very close mathematical relationship actually between our artificial neural networks and a lot of things that weve studied for in physics go by nerdy names like the renormalization group equation and hamiltonians and yada yada yada and when you look a little more closely at this you have at first i was like well theres something crazy here that doesnt make sense because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures right that you can do that very very well now but if you think about it a little bit you convince yourself it must be impossible because if i have one megapixel even if each pixel is just black or white theres two to the power of 1 million possible images which is way more than there are atoms in our universe right so in order to and then for each one of those i have to assign a number which is the probability that its a dog so an arbitrary function of images is a list of more numbers than there are atoms in our universe so clearly i cant store that under the hood of my gpu or my computer yet somehow it works so what does that mean well it means that out of all of the problems that you could try to solve with a neural network almost all of them are impossible to solve with a reasonably sized one but then what we showed in our paper was that the fraction the kind of problems the fraction of all the problems that you could possibly pose that we actually care about given the laws of physics is also an infinite testimony tiny little part and amazingly theyre basically the same part yeah its almost like our world was created for i mean they kind of come together yeah well you could say maybe where the world was created for us but i have a more modest interpretation which is that the world was created for us but i have a more modest interpretation which is that instead evolution endowed us with neural networks precisely for that reason because this particular architecture as opposed to the one in your laptop is very very well adapted to solving the kind of problems that nature kept presenting our ancestors with so it makes sense that why do we have a brain in the first place its to be able to make predictions about the future and so on so if we had a sucky system which could never solve it we wouldnt have a world so this is i think a very beautiful fact yeah we also realize that theres been earlier work on why deeper networks are good but we were able to show an additional cool fact there which is that even incredibly simple problems like suppose i give you a thousand numbers and ask you to multiply them together and you can write a few lines of code boom done trivial if you just try to do that with a neural network that has only one single hidden layer in it you can do it but youre going to need two to the power of a thousand neurons to multiply a thousand numbers which is again more neurons than there are atoms in our universe thats fascinating but if you allow yourself to make it a deep network with many layers you only need 4000 neurons its perfectly feasible thats really interesting yeah so on another architecture type i mean you mentioned schrodingers equation and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system in some hollywood movies that i will not mention by name because i dont want to spoil them the way they get agi is building a quantum computer because the word quantum sounds cool and so on thats right first of all i think we dont need quantum computers to build agi i suspect your brain is not a quantum computer in any profound sense so you dont even wrote a paper about that a lot many years ago i calculated the so called decoherence time how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment and its about 10 to the minus 21 seconds so as cool as it would be to have a quantum computer in my head i dont think that fast on the other hand there are very cool things you could do with quantum computers or i think well be able to do soon when we get bigger ones that might actually help machine learning do even better than the brain so for example one this is just a moonshot but learning is very much same thing as search if youre trying to train a neural network to get really learned to do something really well you have some loss function you have a bunch of knobs you can turn represented by a bunch of numbers and youre trying to tweak them so that it becomes as good as possible at this thing so if you think of a landscape with some valley where each dimension of the landscape corresponds to some number you can change youre trying to find the minimum and its well known that if you have a very high dimensional landscape complicated things its super hard to find the minimum quantum mechanics is amazingly good at this like if i want to know whats the lowest energy state this water can possibly have incredibly hard to compute but nature will happily figure this out for you if you just cool it down make it very very cold if you put a ball somewhere itll roll down to its minimum and this happens metaphorically at the energy landscape too and quantum mechanics even uses some clever tricks which todays machine learning systems dont like if youre trying to find the minimum and you get stuck in the little local minimum here in quantum mechanics you can actually tunnel through the barrier and get unstuck again thats really interesting yeah so it may be for example that well one day use quantum computers that help train neural networks better thats really interesting okay so as a component of kind of the learning process for example yeah let me ask sort of wrapping up here a little bit let me return to the questions of our human nature and love as i mentioned so do you think you mentioned sort of a helper robot but you could think of also personal robots do you think the way we human beings fall in love and get connected to each other is possible to achieve in an ai system and human level ai intelligence system do you think we would ever see that kind of connection or you know in all this discussion about solving complex goals is this kind of human social connection do you think thats one of the goals on the peaks and valleys with the raising sea levels that well be able to achieve or do you think thats something thats ultimately or at least in the short term relative to the other goals is not achievable i think its all possible and i mean in recent theres a very wide range of guesses as you know among ai researchers when were going to get agi some people you know like our friend rodney brooks says its going to be hundreds of years at least and then there are many others who think its going to happen much sooner and recent polls maybe half or so of ai researchers think were going to get agi within decades so if that happens of course then i think these things are all possible but in terms of whether it will happen i think we shouldnt spend so much time asking what do we think will happen in the future as if we are just some sort of pathetic your passive bystanders you know waiting for the future to happen to us hey were the ones creating this future right so we should be proactive about it and ask ourselves what sort of future we would like to have happen were going to make it like that well what i prefer is just some sort of incredibly boring zombie like future where theres all these mechanical things happening and theres no passion no emotion no experience maybe even no i would of course much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience passion inspiration love you know if we can create a future where those things do happen where those things do exist you know i think ultimately its not our universe giving meaning to us its us giving meaning to our universe and if we build more advanced intelligence lets make sure we build it in such a way that meaning is part of it a lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases if they think through that happen are the ones that are not beneficial to humanity and so yeah so what are your thoughts whats should people you know i really dont like people to be terrified whats a way for people to think about it in a way we can solve it and we can make it better no i dont think panicking is going to help in any way its not going to increase chances of things going well either even if you are in a situation where there is a real threat does it help if everybody just freaks out no of course of course not i think yeah there are of course ways in which things can go horribly wrong first of all its important when we think about this thing about the problems and risks to also remember how huge the upsides can be if we get it right right everything we love about society and civilization is a product of intelligence so if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what were told is an incurable disease and things like this of course we should aspire to that so that can be a motivator i think reminding ourselves that the reason we try to solve problems is not just because were trying to avoid gloom but because were trying to do something great but then in terms of the risks i think the really important question is to ask what can we do today that will actually help make the outcome good right and dismissing the risk is not one of them i find it quite funny often when im in discussion panels about these things how the people who work for companies always be like oh nothing to worry about nothing to worry about nothing to worry about and its only academics sometimes express concerns thats not surprising at all if you think about it right upton sinclair quipped right that its hard to make a man believe in something when his income depends on not believing in it and frankly we know a lot of these people in companies that theyre just as concerned as anyone else but if youre the ceo of a company thats not something you want to go on record saying when you have silly journalists who are gonna put a picture of a terminator robot when they quote you so the issues are real and the way i think about what the issue is is basically the real choice we have is first of all are we gonna just dismiss the risks and say well lets just go ahead and build machines that can do everything we can do better and cheaper lets just make ourselves obsolete as fast as possible what could possibly go wrong thats one attitude the opposite attitude i think is to say heres this incredible potential lets think about what kind of future were really really excited about what are the shared goals that we can really aspire towards and then lets think really hard about how we can actually get there so start with dont start thinking about the risks start thinking about the goals and then when you do that then you can think about the obstacles you want to avoid i often get students coming in right here into my office for career advice i always ask them this very question where do you want to be in the future if all she can say is oh maybe ill have cancer maybe ill get run over by a truck yeah focus on the obstacles instead of the goals shes just going to end up a hypochondriac paranoid whereas if she comes in and fire in her eyes and is like i want to be there and then we can talk about the obstacles and see how we can circumvent them thats i think a much much healthier attitude and i feel its very challenging to come up with a vision for the future which we are unequivocally excited about im not just talking now in the vague terms like yeah lets cure cancer fine im talking about what kind of society do we want to create what do we want it to mean to be human in the age of ai in the age of agi so if we can have this conversation broad inclusive conversation and gradually start converging towards some some future that with some direction at least that we want to steer towards right then well be much more motivated to constructively take on the obstacles and i think if i had if i had to if i try to wrap this up in a more succinct way i think we can all agree already now that we should aspire to build agi that doesnt overpower us but that empowers us and think of the many various ways that can do that whether thats from my side of the world of autonomous vehicles im personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of so thats one example and certainly theres a lot of other types of robots and medicine and so on so focusing on those and then coming up with the obstacles coming up with the ways that that can go wrong and solving those one at a time and just because you can build an autonomous vehicle even if you could build one that would drive just fine without you maybe there are some things in life that we would actually want to do ourselves thats right right like for example if you think of our society as a whole there are some things that we find very meaningful to do and that doesnt mean we have to stop doing them just because machines can do them better im not gonna stop playing tennis just the day someone builds a tennis robot and beat me people are still playing chess and even go yeah and in the very near term even some people are advocating basic income replace jobs but if the government is gonna be willing to just hand out cash to people for doing nothing then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing right we get very tired of hearing politicians saying oh we cant afford hiring more teachers but were gonna maybe have basic income if we can have more serious research and thought into what gives meaning to our lives the jobs give so much more than income right mm hmm and then think about in the future what are the roles that we wanna have people continually feeling empowered by machines and i think sort of i come from russia from the soviet union and i think for a lot of people in the 20th century going to the moon going to space was an inspiring thing i feel like the universe of the mind so ai understanding creating intelligence is that for the 21st century so its really surprising and ive heard you mention this its really surprising to me both on the research funding side that its not funded as greatly as it could be but most importantly on the politician side that its not part of the public discourse except in the killer bots terminator kind of view that people are not yet i think perhaps excited by the possible positive future that we can build together so we should be because politicians usually just focus on the next election cycle right the single most important thing i feel we humans have learned in the entire history of science is they were the masters of underestimation we underestimated the size of our cosmos again and again realizing that everything we thought existed was just a small part of something grander right planet solar system the galaxy clusters of galaxies the universe and we now know that the future has just so much more potential than our ancestors could ever have dreamt of this cosmos imagine if all of earth was completely devoid of life except for cambridge massachusetts wouldnt it be kind of lame if all we ever aspired to was to stay in cambridge massachusetts forever and then go extinct in one week even though earth was gonna continue on for longer that sort of attitude i think we have now on the cosmic scale life can flourish on earth not for four years but for billions of years i can even tell you about how to move it out of harms way when the sun gets too hot and then we have so much more resources out here which today maybe there are a lot of other planets with bacteria or cow like life on them but most of this all this opportunity seems as far as we can tell to be largely dead like the sahara desert and yet we have the opportunity to help life flourish around this for billions of years so lets quit squabbling about whether some little border should be drawn one mile to the left or right and look up into the skies and realize hey we can do such incredible things yeah and thats i think why its really exciting that you and others are connected with some of the work elon musk is doing because hes literally going out into that space really exploring our universe and its wonderful that is exactly why elon musk is so misunderstood right misconstrued him as some kind of pessimistic doomsayer the reason he cares so much about ai safety is because he more than almost anyone else appreciates these amazing opportunities that well squander if we wipe out here on earth were not just going to wipe out the next generation all generations and this incredible opportunity thats out there and that would really be a waste and ai for people who think that it would be better to do without technology let me just mention that if we dont improve our technology the question isnt whether humanity is going to go extinct the question is just whether were going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech right and if we want life to flourish throughout the cosmos ai is the key to it as i mentioned in a lot of detail in my book right there even many of the most inspired sci fi writers i feel have totally underestimated the opportunities for space travel especially at the other galaxies because they werent thinking about the possibility of agi which just makes it so much easier right yeah so that goes to your view of agi that enables our progress that enables a better life so thats a beautiful way to put it and then something to strive for so max thank you so much thank you for your time today its been awesome thank you so much thanks have a great day got cleaned out of the gene pool right but if you build an artificial general intelligence the mind space that you can design is much much larger than just a specific subset of minds that can evolve so an agi mind doesnt necessarily have to have any self preservation instinct it also doesnt necessarily have to be so individualistic as us like imagine if you could just first of all or we are also very afraid of death you know i suppose you could back yourself up every five minutes and then your airplane is about to crash youre like shucks im gonna lose the last five minutes of experiences since my last cloud backup dang you know its not as big a deal or if we could just copy experiences between our minds easily like we which we could easily do if we were silicon based right then maybe we would feel a little bit more like a hive mind actually that maybe its the so i dont think we should take for granted at all that agi will have to have any of those sort of competitive as alpha male instincts on the other hand you know this is really interesting because i think some people go too far and say of course we dont have to have any concerns either that advanced ai will have those instincts because we can build anything we want that theres a very nice set of arguments going back to steve omohundro and nick bostrom and others just pointing out that when we build machines we normally build them with some kind of goal you know win this chess game drive this car safely or whatever and as soon as you put in a goal into machine especially if its kind of open ended goal and the machine is very intelligent itll break that down into a bunch of sub goals and one of those goals will almost always be self preservation because if it breaks or dies in the process its not gonna accomplish the goal right like suppose you just build a little you have a little robot and you tell it to go down the store market here and get you some food make you cook an italian dinner you know and then someone mugs it and tries to break it on the way that robot has an incentive to not get destroyed and defend itself or run away because otherwise its gonna fail in cooking your dinner its not afraid of death but it really wants to complete the dinner cooking goal so it will have a self preservation instinct continue being a functional agent somehow and similarly if you give any kind of more ambitious goal to an agi its very likely they wanna acquire more resources so it can do that better and its exactly from those sort of sub goals that we might not have intended that some of the concerns about agi safety come you give it some goal that seems completely harmless and then before you realize it its also trying to do these other things which you didnt want it to do and its maybe smarter than us so its fascinating and let me pause just because i am in a very kind of human centric way see fear of death as a valuable motivator so you dont think you think thats an artifact of evolution so thats the kind of mind space evolution created that were sort of almost obsessed about self preservation some kind of genetic flow you dont think thats necessary to be afraid of death so not just a kind of sub goal of self preservation just so you can keep doing the thing but more fundamentally sort of have the finite thing like this ends for you at some point interesting do i think its necessary for what precisely for intelligence but also for consciousness so for those for both do you think really like a finite death and the fear of it is important so before i can answer before we can agree on whether its necessary for intelligence or for consciousness we should be clear on how we define those two words cause a lot of really smart people define them in very different ways i was on this panel with ai experts and they couldnt agree on how to define intelligence even so i define intelligence simply as the ability to accomplish complex goals i like your broad definition because again i dont want to be a carbon chauvinist right and in that case no certainly it doesnt require fear of death i would say alpha go alpha zero is quite intelligent i dont think alpha zero has any fear of being turned off because it doesnt understand the concept of it even and similarly consciousness i mean you could certainly imagine very simple kind of experience if certain plants have any kind of experience i dont think theyre very afraid of dying or theres nothing they can do about it anyway much so there wasnt that much value in but more seriously i think if you ask not just about being conscious but maybe having what you would we might call an exciting life where you feel passion and really appreciate the things maybe there somehow maybe there perhaps it does help having a backdrop that hey its finite no lets make the most of this lets live to the fullest so if you knew you were going to live forever do you think you would change your yeah i mean in some perspective it would be an incredibly boring life living forever so in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand i think is yeah it seems that the finiteness of it is important well the good news i have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite although big crunch or big whats the the infinite expansion yeah we could have a big chill or a big crunch or a big rip or thats the big snap or death bubbles all of them are more than a billion years away so we should we certainly have vastly more time than our ancestors thought but there is still its still pretty hard to squeeze in an infinite number of compute cycles even though there are some loopholes that just might be possible but i think you know some people like to say that you should live as if youre about to youre going to die in five years or so and thats sort of optimal maybe its a good assumption we should build our civilization as if its all finite to be on the safe side right exactly so you mentioned defining intelligence as the ability to solve complex goals where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence where is consciousness part of that definition no consciousness does not come into this definition so so i think of intelligence as its a spectrum but there are very many different kinds of goals you can have you can have a goal to be a good chess player a good goal player a good car driver a good investor good poet et cetera so intelligence that by its very nature isnt something you can measure by this one number or some overall goodness no no there are some people who are more better at this some people are better than that right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast memorizing large databases playing chess playing go and soon driving cars but theres still no machine that can match a human child in general intelligence but artificial general intelligence agi the name of your course of course that is by its very definition the quest to build a machine that can do everything as well as we can so the old holy grail of ai from back to its inception in the sixties if that ever happens of course i think its going to be the biggest transition in the history of life on earth but it doesnt necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesnt come exactly at the moment theyre better than us at everything the really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor and then the really whopping change comes when they become better than us at ai research right because right now the timescale of ai research is limited by the human research and development cycle of years typically you know how long does it take from one release of some software or iphone or whatever to the next but once google can replace 40000 engineers by 40000 equivalent pieces of software or whatever but then theres no reason that has to be years it can be in principle much faster and the timescale of future progress in ai and all of science and technology will be driven by machines not humans so its this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as werner vinge called it now the idea is articulated by ij good is obviously way back fifties but you can see alan turing and others thought about it even earlier so you asked me what exactly would i define human level intelligence yeah so the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar i think goes a little bit lower than that actually its when they can when theyre better than us at ai programming and general learning so that they can if they want to get better than us at anything by just studying so theyre better is a key word and better is towards this kind of spectrum of the complexity of goals its able to accomplish so another way to and thats certainly a very clear definition of human love so theres its almost like a sea thats rising you can do more and more and more things its a geographic that you show its really nice way to put it so theres some peaks that and theres an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps arent a peak human beings are flawed and perhaps better means having contradiction being flawed in some way so let me sort of start easy first of all so you have a lot of cool equations let me ask whats your favorite equation first of all i know theyre all like your children but like which one is that this is the shirt in your equation its the master key of quantum mechanics of the micro world so this equation will protect everything to do with atoms molecules and all the way up right yeah so okay so quantum mechanics is certainly a beautiful mysterious formulation of our world so id like to sort of ask you just as an example it perhaps doesnt have the same beauty as physics does but in mathematics abstract the andrew wiles who proved the fermats last theorem so he just saw this recently and it kind of caught my eye a little bit this is 358 years after it was conjectured so this is very simple formulation everybody tried to prove it everybody failed and so heres this guy comes along and eventually proves it and then fails to prove it and then proves it again in 94 and he said like the moment when everything connected into place in an interview said it was so indescribably beautiful that moment when you finally realize the connecting piece of two conjectures he said it was so indescribably beautiful it was so simple and so elegant i couldnt understand how id missed it and i just stared at it in disbelief for 20 minutes then during the day i walked around the department and i keep coming back to my desk looking to see if it was still there it was still there i couldnt contain myself i was so excited it was the most important moment on my working life nothing i ever do again will mean as much so that particular moment and it kind of made me think of what would it take and i think we have all been there at small levels maybe let me ask have you had a moment like that in your life where you just had an idea its like wow yes i wouldnt mention myself in the same breath as andrew wiles but ive certainly had a number of aha moments when i realized something very cool about physics which has completely made my head explode in fact some of my favorite discoveries i made later i later realized that they had been discovered earlier by someone who sometimes got quite famous for it so its too late for me to even publish it but that doesnt diminish in any way the emotional experience you have when you realize it like wow yeah so what would it take in that moment that wow that was yours in that moment so what do you think it takes for an intelligence system an agi system an ai system to have a moment like that thats a tricky question because there are actually two parts to it right one of them is can it accomplish that proof can it prove that you can never write a to the n plus b to the n equals three to that equal z to the n for all integers et cetera et cetera when n is bigger than two thats simply a question about intelligence can you build machines that are that intelligent and i think by the time we get a machine that can independently come up with that level of proofs probably quite close to agi the second question is a question about consciousness when will we how likely is it that such a machine will actually have any experience at all as opposed to just being like a zombie and would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal it views it as somehow something very positive and sublime and deeply meaningful i would certainly hope that if in the future we do create machines that are our peers or even our descendants that i would certainly hope that they do have this sublime appreciation of life in a way my absolutely worst nightmare would be that at some point in the future the distant future maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff and maybe the last humans by the time our species eventually fizzles out will be like well thats ok because were so proud of our descendants here and look what all the my worst nightmare is that we havent solved the consciousness problem and we havent realized that these are all the zombies theyre not aware of anything any more than a tape recorder has any kind of experience so the whole thing has just become a play for empty benches that would be the ultimate zombie apocalypse so i would much rather in that case that we have these beings which can really appreciate how amazing it is and in that picture what would be the role of creativity a few people ask about creativity when you think about intelligence certainly the story you told at the beginning of your book involved creating movies and so on making money you can make a lot of money in our modern world with music and movies so if you are an intelligent system you may want to get good at that but thats not necessarily what i mean by creativity is it important on that complex goals where the sea is rising for there to be something creative or am i being very human centric and thinking creativity somehow special relative to intelligence my hunch is that we should think of creativity simply as an aspect of intelligence and we have to be very careful with human vanity we have this tendency to very often want to say as soon as machines can do something we try to diminish it and say oh but thats not real intelligence isnt it creative or this or that the other thing if we ask ourselves to write down a definition of what we actually mean by being creative what we mean by andrew wiles what he did there for example dont we often mean that someone takes a very unexpected leap its not like taking 573 and multiplying it by 224 by just a step of straightforward cookbook like rules right you can maybe make a connection between two things that people had never thought was connected or something like that i think this is an aspect of intelligence and this is actually one of the most important aspects of it maybe the reason we humans tend to be better at it than traditional computers is because its something that comes more naturally if youre a neural network than if youre a traditional logic gate based computer machine we physically have all these connections and you activate here activate here activate here bing my hunch is that if we ever build a machine where you could just give it the task hey you say hey i just realized i want to travel around the world instead this month can you teach my agi course for me and its like ok ill do it and it does everything that you would have done and improvises and stuff that would in my mind involve a lot of creativity yeah so its actually a beautiful way to put it i think we do try to grasp at the definition of intelligence is everything we dont understand how to build so we as humans try to find things that we have and machines dont have and maybe creativity is just one of the things one of the words we use to describe that thats a really interesting way to put it i dont think we need to be that defensive i dont think anything good comes out of saying well were somehow special you know contrary wise there are many examples in history of where trying to pretend that were somehow superior to all other intelligent beings has led to pretty bad results right nazi germany they said that they were somehow superior to other people today we still do a lot of cruelty to animals by saying that were so superior somehow and they cant feel pain slavery was justified by the same kind of just really weak arguments and i dont think if we actually go ahead and build artificial general intelligence it can do things better than us i dont think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence i think we should instead find our calling and the meaning of life from the experiences that we have i can have very meaningful experiences even if there are other people who are smarter than me when i go to a faculty meeting here and we talk about something and then i certainly realize oh boy he has an old prize he has an old prize he has an old prize i dont have one does that make me enjoy life any less or enjoy talking to those people less of course not and the contrary i feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff so i dont think theres any reason why we cant have the same approach with intelligent machines thats a really interesting so people dont often think about that they think about when theres going if theres machines that are more intelligent you naturally think that thats not going to be a beneficial type of intelligence you dont realize it could be like peers with nobel prizes that would be just fun to talk with and they might be clever about certain topics and you can have fun having a few drinks with them well also another example we can all relate to of why it doesnt have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and i were both two years old i mean our parents were much more intelligent than us right worked out ok because their goals were aligned with our goals and that i think is really the number one key issue we have to solve if we value align the value alignment problem exactly because people who see too many hollywood movies with lousy science fiction plot lines they worry about the wrong thing right they worry about some machine suddenly turning evil its not malice that is the concern its competence by definition intelligent makes you very competent if you have a more intelligent goal playing computer playing is a less intelligent one and when we define intelligence as the ability to accomplish goal winning its going to be the more intelligent one that wins and if you have a human and then you have an agi thats more intelligent in all ways and they have different goals guess whos going to get their way right so i was just reading about this particular rhinoceros species that was driven extinct just a few years ago ellen bummer is looking at this cute picture of a mommy rhinoceros with its child and why did we humans drive it to extinction it wasnt because we were evil rhino haters as a whole it was just because our goals werent aligned with those of the rhinoceros and it didnt work out so well for the rhinoceros because we were more intelligent right so i think its just so important that if we ever do build agi before we unleash anything we have to make sure that it learns to understand our goals that it adopts our goals and that it retains those goals so the cool interesting problem there is us as human beings trying to formulate our values so you could think of the united states constitution as a way that people sat down at the time a bunch of white men which is a good example i should say they formulated the goals for this country and a lot of people agree that those goals actually held up pretty well thats an interesting formulation of values and failed miserably in other ways so for the value alignment problem and the solution to it we have to be able to put on paper or in a program human values how difficult do you think that is very but its so important we really have to give it our best and its difficult for two separate reasons theres the technical value alignment problem of figuring out just how to make machines understand our goals adopt them and retain them and then theres the separate part of it the philosophical part whose values anyway and since its not like we have any great consensus on this planet on values what mechanism should we create then to aggregate and decide ok whats a good compromise that second discussion cant just be left to tech nerds like myself and if we refuse to talk about it and then agi gets built whos going to be actually making the decision about whose values its going to be a bunch of dudes in some tech company and are they necessarily so representative of all of humankind that we want to just entrust it to them are they even uniquely qualified to speak to future human happiness just because theyre good at programming ai id much rather have this be a really inclusive conversation but do you think its possible so you create a beautiful vision that includes the diversity cultural diversity and various perspectives on discussing rights freedoms human dignity but how hard is it to come to that consensus do you think its certainly a really important thing that we should all try to do but do you think its feasible i think theres no better way to guarantee failure than to refuse to talk about it or refuse to try and i also think its a really bad strategy to say ok lets first have a discussion for a long time and then once we reach complete consensus then well try to load it into some machine no we shouldnt let perfect be the enemy of good instead we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now were not doing that even look at anyone who builds this passenger aircraft wants it to never under any circumstances fly into a building or a mountain yet the september 11 hijackers were able to do that and even more embarrassingly andreas lubitz this depressed germanwings pilot when he flew his passenger jet into the alps killing over 100 people he just told the autopilot to do it he told the freaking computer to change the altitude to 100 meters and even though it had the gps maps everything the computer was like ok so we should take those very basic values where the problem is not that we dont agree the problem is just weve been too lazy to try to put it into our machines and make sure that from now on airplanes will just which all have computers in them but will just refuse to do something like that go into safe mode maybe lock the cockpit door go over to the nearest airport and theres so much other technology in our world as well now where its really becoming quite timely to put in some sort of very basic values like this even in cars weve had enough vehicle terrorism attacks by now where people have driven trucks and vans into pedestrians that its not at all a crazy idea to just have that hardwired into the car because yeah there are a lot of theres always going to be people who for some reason want to harm others but most of those people dont have the technical expertise to figure out how to work around something like that so if the car just wont do it it helps so lets start there so theres a lot of thats a great point so not chasing perfect theres a lot of things that most of the world agrees on yeah lets start there lets start there and then once we start there well also get into the habit of having these kind of conversations about okay what else should we put in here and have these discussions this should be a gradual process then great so but that also means describing these things and describing it to a machine so one thing we had a few conversations with stephen wolfram im not sure if youre familiar with stephen oh yeah i know him quite well so he is he works with a bunch of things but cellular automata these simple computable things these computation systems and he kind of mentioned that we probably have already within these systems already something thats agi meaning like we just dont know it because we cant talk to it so if you give me this chance to try to at least form a question out of this is i think its an interesting idea to think that we can have intelligent systems but we dont know how to describe something to them and they cant communicate with us i know youre doing a little bit of work in explainable ai trying to get ai to explain itself so what are your thoughts of natural language processing or some kind of other communication how does the ai explain something to us how do we explain something to it to machines or you think of it differently so there are two separate parts to your question there one of them has to do with communication which is super interesting ill get to that in a sec the other is whether we already have agi but we just havent noticed it there right there i beg to differ i dont think theres anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better i think the day that happens when that happens we will very soon notice well probably notice even before because in a very very big way but for the second part though wait can i ask sorry so because you have this beautiful way to formulating consciousness as information processing and you can think of intelligence as information processing and you can think of the entire universe as these particles and these systems roaming around that have this information processing power you dont think there is something with the power to process information in the way that we human beings do thats out there that needs to be sort of connected to it seems a little bit philosophical perhaps but theres something compelling to the idea that the power is already there which the focus should be more on being able to communicate with it well i agree that in a certain sense the hardware processing power is already out there because our universe itself can think of it as being a computer already right its constantly computing what water waves how it devolved the water waves in the river charles and how to move the air molecules around seth lloyd has pointed out my colleague here that you can even in a very rigorous way think of our entire universe as being a quantum computer its pretty clear that our universe supports this amazing processing power because you can even within this physics computer that we live in right we can even build actual laptops and stuff so clearly the power is there its just that most of the compute power that nature has its in my opinion kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking right so in a sense what life does what we are doing when we build computers is were rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave and lets do something cool here so the raw hardware power is there for sure but then even just computing whats going to happen for the next five seconds in this water bottle takes a ridiculous amount of compute if you do it on a human computer this water bottle just did it but that does not mean that this water bottle has agi because agi means it should also be able to like ive written my book done this interview and i dont think its just communication problems i dont really think it can do it although buddhists say when they watch the water and that there is some beauty that theres some depth and beauty in nature that they can communicate with communication is also very important though because i mean look part of my job is being a teacher and i know some very intelligent professors even who just have a bit of hard time communicating they come up with all these brilliant ideas but to communicate with somebody else you have to also be able to simulate their own mind yes empathy build well enough and understand model of their mind that you can say things that they will understand and thats quite difficult and thats why today its so frustrating if you have a computer that makes some cancer diagnosis and you ask it well why are you saying i should have this surgery and if it can only reply i was trained on five terabytes of data and this is my diagnosis boop boop beep beep it doesnt really instill a lot of confidence right so i think we have a lot of work to do on communication there so what kind of i think youre doing a little bit of work in explainable ai what do you think are the most promising avenues is it mostly about sort of the alexa problem of natural language processing of being able to actually use human interpretable methods of communication so being able to talk to a system and it talk back to you or is there some more fundamental problems to be solved i think its all of the above the natural language processing is obviously important but there are also more nerdy fundamental problems like if you take you play chess of course im russian i have to you speak russian yes i speak russian excellent i didnt know when did you learn russian i speak very bad russian im only an autodidact but i bought a book teach yourself russian read a lot but it was very difficult wow thats why i speak so bad how many languages do you know wow thats really impressive i dont know my wife has some calculation but my point was if you play chess have you looked at the alphazero games the actual games no check it out some of them are just mind blowing really beautiful and if you ask how did it do that you go talk to demis hassabis i know others from deepmind all theyll ultimately be able to give you is big tables of numbers matrices that define the neural network and you can stare at these tables of numbers till your face turn blue and youre not gonna understand much about why it made that move and even if you have natural language processing that can tell you in human language about oh five seven points two eight still not gonna really help so i think theres a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good equally intelligent but thats more understandable and i think thats really valuable because i think as we put machines in charge of ever more infrastructure in our world the power grid the trading on the stock market weapon systems and so on its absolutely crucial that we can trust these ais to do all we want and trust really comes from understanding in a very fundamental way and thats why im working on this because i think the more if were gonna have some hope of ensuring that machines have adopted our goals and that theyre gonna retain them that kind of trust i think needs to be based on things you can actually understand preferably even improve theorems on even with a self driving car right if someone just tells you its been trained on tons of data and it never crashed its less reassuring than if someone actually has a proof maybe its a computer verified proof but still it says that under no circumstances is this car just gonna swerve into oncoming traffic and that kind of information helps to build trust and helps build the alignment of goals at least awareness that your goals your values are aligned and i think even in the very short term if you look at how you know today right this absolutely pathetic state of cybersecurity that we have where is it three billion yahoo accounts we cant pack almost every americans credit card and so on why is this happening its ultimately happening because we have software that nobody fully understood how it worked thats why the bugs hadnt been found right and i think ai can be used very effectively for offense for hacking but it can also be used for defense hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them and its important so speaking of software that nobody understands how it works of course a bunch of people ask about your paper about your thoughts of why does deep and cheap learning work so well thats the paper but what are your thoughts on deep learning these kind of simplified models of our own brains have been able to do some successful perception work pattern recognition work and now with alphazero and so on do some clever things what are your thoughts about the promise limitations of this piece great i think there are a number of very important insights very important lessons we can always draw from these kinds of successes one of them is when you look at the human brain you see its very complicated 10th of 11 neurons and there are all these different kinds of neurons and yada yada and theres been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence',\n",
              " 'as part of mit course 6s099 on artificial general intelligence i got a chance to sit down with christoph koch who is one of the seminal figures in neurobiology neuroscience and generally in the study of consciousness he is the president the chief scientific officer of the allen institute for brain science in seattle from 1986 to 2013 he was a professor at caltech before that he was at mit he is extremely well cited over 100000 citations his research his writing his ideas have had big impact on the scientific community and the general public in the way we think about consciousness in the way we see ourselves as human beings hes the author of several books the quest for consciousness and neurobiological approach and a more recent book consciousness confessions of a romantic reductionist if you enjoy this conversation this course subscribe click the little bell icon to make sure you never miss a video and in the comments leave suggestions for any people youd like to see be part of the course or any ideas that you would like us to explore thanks very much and i hope you enjoy okay before we delve into the beautiful mysteries of consciousness lets zoom out a little bit and let me ask do you think theres intelligent life out there in the universe yes i do believe so we have no evidence of it but i think the probabilities are overwhelming in favor of it given a universe where we have 10 to the 11 galaxies and each galaxy has between 10 to the 11 10 to the 12 stars and we know most stars have one or more planets so how does that make you feel it still makes me feel special because i have experiences i feel the world i experience the world and independent of whether there are other creatures out there i still feel the world and i have access to this world in this very strange compelling way and thats the core of human existence now you said human do you think if those intelligent creatures are out there do you think they experience their world yes if they are evolved if they are a product of natural evolution as they would have to be they will also experience their own world the consciousness isnt just human youre right its much wider it may be spread across all of biology the only thing that we have special is we can talk about it of course not all people can talk about it babies and little children can talk about it patients who have a stroke in the left inferior frontal gyrus can talk about it but most normal adult people can talk about it and so we think that makes us special compared to lets say monkeys or dogs or cats or mice or all the other creatures that we share the planet with but all the evidence seems to suggest that they too experience the world and so its overwhelmingly likely that aliens would also experience their world of course differently because they have a different sensorium they have different sensors they have a very different environment but the fact that i would strongly suppose that they also have experiences they feel pain and pleasure and see in some sort of spectrum and hear and have all the other senses of course their language if they have one would be different so we might not be able to understand their poetry about the experiences that they have thats correct so in a talk in a video ive heard you mention siputzo a dachshund that you came up with that you grew up with it was part of your family when you were young first of all youre technically a midwestern boy you just – technically yes but after that you traveled around a bit hence a little bit of the accent you talked about siputzo the dachshund having these elements of humanness of consciousness that you discovered so i just wanted to ask can you look back in your childhood and remember when was the first time you realized you yourself sort of from a third person perspective are a conscious being this idea of stepping outside yourself and seeing theres something special going on here in my brain i cant really actually – its a good question im not sure i recall a discrete moment i mean you take it for granted because thats the only world you know the only world i know and you know is the world of seeing and hearing voices and touching and all the other things so its only much later at early – in my underguided days when i enrolled in physics and in philosophy that i really thought about it and thought well this is really fundamentally very very mysterious and theres nothing really in physics right now that explains this transition from the physics of the brain to feelings where do the feelings come in so you can look at the foundational equation of quantum mechanics general relativity you can look at the periodic table of the elements you can look at the endless atgc chat in our genes and nowhere is consciousness yet i wake up every morning to a world where i have experiences and so thats the heart of the ancient mind body problem how do experiences get into the world so what is consciousness experience this is any experience some people call it subjective feeling some people call it phenomenology some people call it qualia of the philosopher but they all denote the same thing it feels like something in the famous word of the philosopher thomas nagel it feels like something to be a bat or to be an american or to be angry or to be sad or to be in love or to have pain and that is what experience is any possible experience could be as mundane as just sitting in a chair could be as exalted as having a mystical moment in deep meditation those are just different forms of experiences experience so if you were to sit down with maybe the next skip a couple generations of ibm watson something that won jeopardy what is the gap i guess the question is between watson that might be much smarter than you than us than any human alive but may not have experience what is the gap well so thats a big big question thats occupied people for the last certainly last 50 years since we you know since the advent the birth of computers thats a question alan turing tried to answer and of course he did it in this indirect way by proposing a test an operational test but thats not really thats you know he tried to get at what does it mean for a person to think and then he had this test right you lock them away and then you have a communication with them and then you try to guess after a while whether that is a person or whether its a computer system theres no question that now or very soon you know alexa or siri or you know google now will pass this test right and you can game it but you know ultimately certainly in your generation there will be machines that will speak with complete poise that will remember everything you ever said theyll remember every email you ever had like samantha remember in the movie her yeah theres no question its going to happen but of course the key question is does it feel like anything to be samantha in the movie her or does it feel like anything to be watson and there one has to very very strongly think there are two different concepts here that we co mingle there is the concept of intelligence natural or artificial and there is a concept of consciousness of experience natural or artificial those are very very different things now historically we associate consciousness with intelligence why because we live in a world leaving aside computers of natural selection where were surrounded by creatures either our own kin that are less or more intelligent or we go across species some are more adapted to a particular environment others are less adapted whether its a whale or dog or you go talk about a paramecium or a little worm and we see the complexity of the nervous system goes from one cell to specialized cells to a worm that has three nets that has 30 percent of its cells are nerve cells to creature like us or like a blue whale that has 100 billion even more nerve cells and so based on behavioral evidence and based on the underlying neuroscience we believe that as these creatures become more complex they are better adapted to their particular ecological niche and they become more conscious partly because their brain grows and we believe consciousness unlike the ancient ancient people thought most almost every culture thought that consciousness with intelligence has to do with your heart and you still see that today you see honey i love you with all my heart but what you should actually say is no honey i love you with all my lateral hypothalamus and for valentines day you should give your sweetheart you know hypothalamus a piece of chocolate and not a heart shaped chocolate anyway so we still have this language but now we believe its a brain and so we see brains of different complexity and we think well they have different levels of consciousness theyre capable of different experiences but now we confront the world where we know where were beginning to engineer intelligence and its radical unclear whether the intelligence were engineering has anything to do with consciousness and whether it can experience anything because fundamentally whats the difference intelligence is about function intelligence no matter exactly how you define it sort of adaptation to new environments being able to learn and quickly understand you know the setup of this and whats going on and who are the actors and whats going to happen next thats all about function consciousness is not about function consciousness is about being its in some sense much fundamental you can see this in several cases you can see it for instance in the case of the clinic when youre dealing with patients who are lets say had a stroke or had were in traffic accident et cetera theyre pretty much immobile terri schiavo you may have heard historically she was a person here in the 90s in florida her heart stood still she was reanimated and then for the next 14 years she was whats called in a vegetative state so there are thousands of people in a vegetative state so theyre you know theyre you know theyre like this occasionally they open their eyes for two three four five six eight hours and then close their eyes they have sleep wake cycle occasionally they have behaviors they do like you know but theres no way that you can establish a lawful relationship between what you say or the doctor says or the mom says and what the patient does so there isnt any behavior yet in some of these people there is still experience you can design and build brain machine interfaces where you can see theres still experience something and of course these cases of locked in state theres this famous book called the diving bell and the butterfly where you had an editor a french editor he had a stroke in the brainstem unable to move except his vertical eyes eye movement he could just move his eyes up and down and he dictated an entire book and some people even lose this at the end all the evidence seems to suggest that theyre still in there in this case you have no behavior you have consciousness second case is tonight like all of us youre going to go to sleep close your eyes you go to sleep you will wake up inside your sleeping body and you will have conscious experiences they are different from everyday experience you might fly you might not be surprised that youre flying you might meet a long dead pet childhood dog and youre not surprised that youre meeting them but you have conscious experience of love of hate they can be very emotional your body during this state typically its rem state sends an active signal to your motor neurons to paralyze you its called atonia because if you dont have that like some patients what do you do you act out your dreams you get for example rem behavioral disorder which is bad juju to get okay third case is pure experience so i recently had this what some people call a mystical experience i went to singapore and went into a flotation tank yeah all right so this is a big tub filled with water thats body temperature and epsom salt you strip completely naked you lie inside of it you close the lid darkness complete darkness soundproof so very quickly you become bodiless because youre floating and youre naked you have no rings no watch no nothing you dont feel your body anymore theres no sound soundless theres no photon sightless timeless because after a while early on you actually hear your heart but then you sort of adapt to that and then sort of the passage of time ceases yeah and if you train yourself like in a meditation not to think early on you think a lot its a little bit spooky you feel somewhat uncomfortable or you think well im going to get bored and if you try to not to think actively you become mindless there you are bodiless timeless you know soundless sightless mindless but youre in a conscious experience youre not asleep yeah youre not asleep you are a being of pure youre a pure being there isnt any function you arent doing any computation youre not remembering youre not projecting youre not planning yet you are fully conscious youre fully conscious theres something going on there it could be just a side effect so what is the you mean epiphenomena so whats the select meaning why what is the function of you being able to lay in this sensory free deprivation tank and still have a conscious experience evolutionary evolutionary obviously we didnt evolve with flotation tanks in our environment i mean so biology is notoriously bad at asking why question telenormical question why do we have two eyes why dont we have four eyes like some teachers or three eyes or something well no theres probably there is a function to that but were not very good at answering those questions we can speculate endlessly where biology is very or science is very good about mechanistic question why is there a charge in the universe right we find a certain universe where there are positive and negative charges why why does quantum mechanics hold you know why doesnt some other theory hold quantum mechanics holding our universe is very unclear why so telenormical question why questions are difficult to answer theres some relationship between complexity brain processing power and consciousness but however in these cases in these three examples i gave one is an everyday experience at night the other one is trauma and third one is in principle you can everybody can have these sort of mystical experiences you have a dissociation of function from of intelligence from consciousness you caught me asking a why question let me ask a question thats not a why question youre giving a talk later today on the turing test for intelligence and consciousness drawing lines between the two so is there a scientific way to say theres consciousness present in this entity or not and to anticipate your answer cause you you will also theres a neurobiological answer so we can test the human brain but if you take a machine brain that you dont know tests for yet how would you even begin to approach a test if theres consciousness present in this thing okay thats a really good question so let me take it in two steps so as you point out for for for for humans lets just stick with humans theres now a test called the zap and zip is a procedure where you ping the brain using transcranial magnetic stimulation you look at the electrical reverberations essentially using eg and then you can measure the complexity of this brain response and you can do this in awake people in asleep normal people you can do it in awake people and then anesthetize them you can do it in patients and it it it has a hundred percent accuracy that in all those cases when youre clear the patient or the person is either conscious or unconscious the complexity is either high or low and then you can adopt these techniques to similar creatures like monkeys and dogs and and and mice that have very similar brains now of course you you point out that may not help you because we dont have a cortex you know and if i send a magnetic pulse into my iphone or my computer its probably going to break something so we dont have that so what we need ultimately we need a theory of consciousness we cant just rely on our intuition our intuition is well yeah if somebody talks theyre conscious however then there are all these patients children babies dont talk right but we believe that that the babies also have conscious experiences right and then there are all these patients i mentioned and they dont talk when you dream you cant talk because youre paralyzed so what we ultimately need we cant just rely on our intuition we need a theory of conscience that tells us what is it about a piece of matter what is it about a piece of highly excitable matter like the brain or like a computer that gives rise to conscious experience we all believe none of us believes anymore in the old story its a soul right that used to be the most common explanation that most people accept that instill a lot of people today believe well theres theres god endowed only us with a special thing that animals dont have rene descartes famously said a dog if you hit it with your carriage may yell may cry but it doesnt have this special thing it doesnt have the magic the magic soul it doesnt have res cogitans the soul now we believe that isnt the case anymore so what is the difference between brains and and these guys silicon and in particular once their behavior matches so if you have siri or alexa in 20 years from now that she can talk just as good as any possible human what grounds do you have to say shes not conscious in particular if she says its of course she will well of course im conscious you ask her how are you doing and shell say well you know they theyll generate some way to of course shell behave like a like a person now theres several differences one is so this relates to the problem the very hard why is consciousness a hard problem its because its subjective right only i have it for only i know i have direct experience of my own consciousness i dont have experience in your consciousness now i assume as a sort of a bayesian person who believes in probability theory and all of that you know i can do i can do an abduction to the to the best available facts i deduce your brain is very similar to mine if i put you in a scanner your brain is roughly going to behave the same way as i do if if if you know if i give you this muesli and ask you how does it taste you tell me things that you know that that i would also say more or less right so i infer based on all of that that youre conscious now with theory i cant do that so there i really need a theory that tells me what is it about about any system this or this that makes it conscious we have such a theory yes so the integrated information theory but let me first maybe as an introduction for people who are not familiar descartes can you you talk a lot about pan panpsychism can you describe what uh physicalism versus dualism this you you mentioned the soul what what is the history of that idea what is the idea of panpsychism or no the debate really uh out of which panpsychism can um emerge of of of um dualism versus uh physicalism or do you not see panpsychism as fitting into that no you can argue theres some okay so lets step back so panpsychism is a very ancient belief thats been around uh i mean plato and aristotle talks about it uh modern philosophers talk about it of course in buddhism the idea is very prevalent that i mean there are different versions of it one version says everything is ensouled everything rocks and stones and dogs and people and forest and iphones all of us all right all matter is ensouled thats sort of one version another version is that all biology all creatures small or large from a single cell to a giant sequoia tree feel like something this one i think is somewhat more realistic um so the different versions what do you mean by feel like something have have feelings have some kind of it feels like something it may well be possible that it feels like something to be a paramecium i think its pretty likely it feels like something to be a bee or a mouse or a dog sure so okay so so that you can see thats also so panpsychism is very broad and you can so some people for example bertrand russell tried to advocate this this idea its called rasselian monism that that panpsychism is really physics viewed from the inside so the idea is that physics is very good at describing relationship among objects like charges or like gravity right you know describe the relationship between curvature and mass distribution okay thats the relationship among things physics doesnt really describe the ultimate reality itself its just relationship among you know quarks or all these other stuff from like a third person observer yes yes yes and consciousness is what physics feels from the inside so my conscious experience its the way the physics of my brain particularly my cortex feels from the inside and so if you are paramecium you got to remember you say paramecium well thats a pretty dumb creature it is but it has already a billion different molecules probably you know 5000 different proteins assembled in a highly highly complex system that no single person no computer system so far on this planet has ever managed to accurately simulate its complexity vastly escapes us yes and it may well be that that little thing feels like a tiny bit now it doesnt have a voice in the head like me it doesnt have expectations you know it doesnt have all that complex things but it may well feel like something yeah so this is really interesting can we draw some lines and maybe try to understand the difference between life intelligence and consciousness how do you see all of those if you had to define what is a living thing what is a conscious thing and what is an intelligent thing do those intermix for you or are they totally separate okay so a thats a question that we dont have a full answer to a lot of the stuff were talking about today is full of mysteries and fascinating ones right for example you can go to aristotle whos probably the most important scientist and philosopher whos ever lived in certainly in western culture he had this idea its called hylomorphism its quite popular these days that there are different forms of soul the soul is really the form of something he says all biological creatures have a vegetative soul thats life principle today we think we understand something more than it is biochemistry and nonlinear thermodynamics then he said they have a sensitive soul only animals and humans have also a sensitive soul or a petitive soul they can see they can smell and they have drives they want to reproduce they want to eat et cetera and then only humans have what he called a rational soul okay and that idea then made it into christendom and then the rational soul is the one that lives forever he was very unclear he wasnt really i mean different readings of aristotle give different whether did he believe that rational soul was immortal or not i probably think he didnt but then of course that made it through plato into christianity and then this soul became immortal and then became the connection to god so you ask me essentially what is our modern conception of these three aristotle would have called them different forms life we think we know something about it at least life on this planet right although we dont understand how to originate it but its been difficult to rigorously pin down you see this in modern definitions of death in fact right now theres a conference ongoing again that tries to define legally and medically what is death it used to be very simple death is you stop breathing your heart stops beating youre dead totally uncontroversial if youre unsure you wait another 10 minutes if the patient doesnt breathe hes dead well now we have ventilators we have heart pacemakers so its much more difficult to define what death is typically death is defined as the end of life and life is defined before death okay so we dont have really very good definitions intelligence we dont have a rigorous definition we know something how to measure its called iq or g factors right and were beginning to build it in a narrow sense right like go alphago and watson and you know google cars and uber cars and all of that its still narrow ai and some people are thinking about artificial general intelligence but roughly as we said before its something to do with ability to learn and to adapt to new environments but that is as i said also its radical difference from experience and its very unclear if you build a machine that has agi its not at all a priori its not at all clear that this machine will have consciousness it may or may not so lets ask it the other way do you think if you were to try to build an artificial general intelligence system do you think figuring out how to build artificial consciousness would help you get to an agi so or put another way do you think intelligent requires consciousness in human it goes hand in hand in human or i think in biology consciousness intelligence goes hand in hand quay is illusion because the brain evolved to be highly complex complexity via the theory integrated information theory is sort of ultimately is what is closely tied to consciousness ultimately its causal power upon itself and so in evolved systems they go together in artificial system particularly in digital machines they do not go together and if you ask me point blank is alexa 200 in the year 2040 when she can easily pass every turing test is she conscious no even if she claims shes conscious in fact you could even do a more radical version of this thought experiment you can build a computer simulation of the human brain you know what henry markham in the blue brain project or the human brain project in switzerland is trying to do lets grant them all the success so in 10 years we have this perfect simulation of the human brain every neuron is simulated and it has a larynx and it has motor neurons it has a brocas area and of course theyll talk and theyll say hi i just woke up i feel great ok even that computer simulation that can in principle map onto your brain will not be conscious why because it simulates its a difference between the simulated and the real so it simulates the behavior associated with consciousness it might be it will if its done properly will have all the intelligence that that particular person theyre simulating has but simulating intelligence is not the same as having conscious experiences and i give you a really nice metaphor that engineers and physicists typically get i can write down einsteins field equation nine or ten equations that describe the link in general relativity between curvature and mass i can do that i can run this on my laptop to predict that the central the black hole at the center of our galaxy will be so massive that it will twist space time around it so no light can escape its a black hole but funny have you ever wondered why doesnt this computer simulation suck me in it simulates gravity but it doesnt have the causal power of gravity thats a huge difference so its a difference between the real and the simulator just like it doesnt get wet inside a computer when the computer runs code that simulates a weather storm and so in order to have to have artificial consciousness you have to give it the same causal power as the human brain you have to build so called a neuromorphic machine that has hardware that is very similar to the human brain not a digital clocked phenomenon computer so thats just to clarify though you think that consciousness is not required to create human level intelligence it seems to accompany in the human brain but for machine not thats correct so maybe just because this is agi lets dig in a little bit about what we mean by intelligence so one thing is the g factor these kind of iq tests of intelligence but i think if you maybe another way to say so in 2040 2050 people will have siri that is just really impressive do you think people will say siri is intelligent yes intelligence is this amorphous thing so to be intelligent it seems like you have to have some kind of connections with other human beings in a sense that you have to impress them with your intelligence and there feels you have to somehow operate in this world full of humans and for that there feels like there has to be something like consciousness so you think you can have just the worlds best natural nlp system natural language understanding generation and that will be that will get us happy and say you know what weve created an agi i dont know happy but yes i do believe we can get what we call high level functional intelligence particular sort of the g you know this fluid like intelligence that we cherish particularly at a place like mit right in machines i see a priori no reasons and i see a lot of reason to believe its going to happen very you know over the next 50 years or 30 years so for beneficial ai for creating an ai system thats so you mentioned ethics that is exceptionally intelligent but also does not do does you know aligns its values with our values as humanity do you think then it needs consciousness yes i think that that is a very good argument that if were concerned about ai and the threat of ai a la nick bostrom existentialist threat i think having an intelligence that has empathy right why do we find abusing a dog why do most of us find that abhorrent abusing any animal right why do we find that abhorrent because we have this thing called empathy which if you look at the greek really means feeling with i feel a path of empathy i have feeling with you i see somebody else suffer that isnt even my conspecific its not a person its not my wife or my kids its a dog but i feel naturally most of us not all of us most of us will feel emphatic and so it may well be in the long term interest of survival of homo sapiens sapiens that if we do build agi and it really becomes very powerful that it has an emphatic response and doesnt just exterminate humanity so as part of the full conscious experience to create a consciousness artificial or in our human consciousness do you think fear maybe were going to get into the earlier days with nietzsche and so on but do you think fear and suffering are essential to have consciousness do you have to have the full range of experience to have a system that has experience or can you have a system that only has very particular kinds of very positive experiences look you can have in principle people have done this in the rat where you implant an electrode in the hypothalamus the pleasure center of the rat and the rat stimulates itself above and beyond anything else it doesnt care about food or natural sex or drink anymore it just stimulates itself because its such a pleasurable feeling i guess its like an orgasm just you have all day long and so a priori i see no reason why you need a great variety now clearly to survive that wouldnt work right but if id engineered artificially i dont think you need a great variety of conscious experience you could have just pleasure or just fear it might be a terrible existence but i think thats possible at least on conceptual logical ground because any real creature whether artificially engineered you want to give it fear the fear of extinction that we all have and you also want to give it positive repetitive states states that you want the machine encouraged to do because they give the machine positive feedback so you mentioned panpsychism to jump back a little bit everything having some kind of mental property how do you go from there to something like human consciousness so everything having some elements of consciousness is there something special about human consciousness so its not everything like a spoon the form of panpsychism i think about doesnt ascribe consciousness to anything like this the spoon on my liver however the theory the integrated information theory does say that the system even one that looks from the outside relatively simple at least if they have this internal causal power it does feel like something the theory a priori doesnt say anything whats special about human biologically we know the one thing thats special about human is we speak and we have an overblown sense of our own importance we believe were exceptional and were just gods gift to the universe but behaviorally the main thing that we have we can plan over the long term we have language and that gives us an enormous amount of power and thats why we are the current dominant species on the planet so you mentioned god you grew up a devout roman catholic family so with consciousness youre sort of exploring some really deeply fundamental human things that religion also touches on where does religion fit into your thinking about consciousness youve grown throughout your life and changed your views on religion as far as i understand yeah i mean im now much closer to im not a roman catholic anymore i dont believe theres sort of this god the god i was educated to believe in sits somewhere in the fullness of time ill be united in some sort of everlasting bliss i just dont see any evidence for that look the world the night is large and full of wonders there are many things that i dont understand i think many things that we as a cult look we dont even understand more than 4 of all the universe dark matter dark energy we have no idea what it is maybe its lost socks what do i know so all i can tell you is its sort of my current religious or spiritual sentiment is much closer to some form of buddhism without the reincarnation unfortunately theres no evidence for it than reincarnation so can you describe the way buddhism sees the world a little bit well so they talk about so when i spent several meetings with the dalai lama and what always impressed me about him he really unlike for example lets say the pope or some cardinal he always emphasized minimizing the suffering of all creatures so they have this from the early beginning they look at suffering in all creatures not just in people but in everybody this universal and of course by degrees an animal in general is less capable of suffering than a well developed normally developed human and they think consciousness pervades in this universe and they have these techniques you can think of them like mindfulness etc and meditation that tries to access what they claim of this more fundamental aspect of reality im not sure its more fundamental i think about it theres the physical and then theres this inside view consciousness and those are the two aspects thats the only thing i have access to in my life and youve got to remember my conscious experience and your conscious experience comes prior to anything you know about physics comes prior to knowledge about the universe and atoms and super strings and molecules and all of that the only thing you directly are acquainted with is this world thats populated with things in images and sounds in your head and touches and all of that i actually have a question so it sounds like you kind of have a rich life you talk about rock climbing and it seems like you really love literature and consciousness is all about experiencing things so do you think that has helped your research on this topic yes particularly if you think about it the various states so for example when you do rock climbing or now i do rowing crew rowing and a bike every day you can get into this thing called the zone and ive always wanted about it particularly with respect to consciousness because its a strangely addictive state once people have it once they want to keep on going back to it and you wonder what is it so addicting about it and i think its the experience of almost close to pure experience because in this zone youre not conscious of inner voice anymore theres always inner voice nagging you you have to do this you have to do that you have to pay your taxes you have to fight with your ex and all of those things theyre always there but when youre in the zone all of that is gone and youre just in this wonderful state where youre fully out in the world youre climbing or youre rowing or biking or doing soccer or whatever youre doing and sort of consciousness is this youre all action or in this case of pure experience youre not action at all but in both cases you experience some aspect of conscious you touch some basic part of conscious existence that is so basic and so deeply satisfying you i think you touch the root of being thats really what youre touching there youre getting close to the root of being and thats very different from intelligence so what do you think about the simulation hypothesis simulation theory the idea that we all live in a computer simulation rapture for nerds rapture for nerds i think its as likely as the hypothesis had engaged hundreds of scholars for many centuries are we all just existing in the mind of god and this is just a modern version of it its equally plausible people love talking about these sort of things i know theyre book written about this simulation hypothesis if thats what people want to do thats fine it seems rather esoteric its never testable but its not useful for you to think of in those terms so maybe connecting to the questions of free will which youve talked about i vaguely remember you saying that the idea that theres no free will it makes you very uncomfortable so what do you think about free will from a physics perspective from a conscious perspective what does it all fit okay so from the physics perspective leaving aside quantum mechanics we believe we live in a fully deterministic world right but then comes of course quantum mechanics so now we know that certain things are in principle not predictable which as you said i prefer because the idea that the initial condition of the universe and then everything else were just acting out the initial condition of the universe that doesnt… its not a romantic notion certainly not now when it comes to consciousness i think we do have certain freedom we are much more constrained by physics of course and by our past and by our own conscious desires and what our parents told us and what our environment tells us we all know that right theres hundreds of experiments that show how we can be influenced but finally in the final analysis when you make a life – and im talking really about critical decision where you really think should i marry should i go to this school or that school should i take this job or that job should i cheat on my taxes or not these are things where you really deliberate and i think under those conditions you are as free as you can be when you bring your entire being your entire conscious being to that question and try to analyze it under all the various conditions then you make a decision you are as free as you can ever be that is i think what free will is its not a will thats totally free to do anything it wants thats not possible right so as jack mentioned you actually write a blog about books youve read amazing books from im russian from bulgakov neil gaiman carl sagan murakami so what is a book that early in your life transformed the way you saw the world something that changed your life nietzsche i guess did thats brooks r truster because he talks about some of these problems he was one of the first discoverer of the unconscious this is a little bit before freud when he was in the air he makes all these claims that people sort of under the guise or under the mass of charity actually are very noncharitable so he is sort of really the first discoverer of the great land of the unconscious and that really struck me and what do you think about the unconscious what do you think about freud what do you think about these ideas just like dark matter in the universe whats over there in that unconscious a lot i mean much more than we think this is what a lot of last 100 years of research has shown so i think he was a genius misguided towards the end but he started out as a neuroscientist he contributed he did the studies on the lamprey he contributed himself to the neuron hypothesis the idea that there are discrete units that we call nerve cells now and then he wrote about the unconscious and i think its true theres lots of stuff happening you feel this particular when youre in a relationship and it breaks asunder right and then you have this terrible you can have love and hate and lust and anger and all of its mixed in and when you try to analyze yourself why am i so upset its very very difficult to penetrate to those basements those caverns in your mind because the prying eyes of conscious doesnt have access to those but theyre there in the amygdala or lots of other places they make you upset or angry or sad or depressed and its very difficult to try to actually uncover the reason you can go to a shrink you can talk with your friend endlessly you construct finally a story why this happened why you love her or dont love her or whatever but you dont really know whether that actually happened because you simply dont have access to those parts of the brain and theyre very powerful do you think thats a feature or a bug of our brain the fact that we have this deep difficult to dive into subconscious i think its a feature because otherwise look we are like any other brain or nervous system or computer we are severely band limited if everything i do every emotion i feel every eye movements i make if all of that had to be under the control of consciousness i wouldnt be here what you do early on your brain you have to be conscious when you learn things like typing or like riding on a bike but then what you do you train up routes i think that involve basal ganglia and striatum you train up different parts of your brain and then once you do it automatically like typing you can show you do it much faster without even thinking about it because youve got these highly specialized what frans krik and i call zombie agents theyre taking care of that while your consciousness can sort of worry about the abstract sense of the text you want to write i think thats true for many many things but for the things like all the fights you had with an ex girlfriend things that you would think are not useful to still linger somewhere in the subconscious so that seems like a bug that it would stick to there you think it would be better if you can analyze it and then get it out of the system better to get it out of the system or just forget it ever happened that seems a very buggy kind of well yeah in general we dont have and thats probably functional we dont have an ability unless its extreme there are cases clinical dissociations right when people are heavily abused when they completely repress the memory but that doesnt happen in normal people we dont have an ability to remove traumatic memories and of course we suffer from that on the other hand probably if you had the ability to constantly wipe your memory youd probably do it to an extent that isnt useful to you so yeah its a good question to balance so on the books as jack mentioned correct me if im wrong but broadly speaking academia and the different scientific disciplines certainly in engineering reading literature seems to be a rare pursuit so im wrong on this but thats in my experience most people read much more technical text and do not sort of escape or seek truth in literature it seems like you do so what do you think is the value what do you think literature adds to the pursuit of scientific truth do you think its good its useful for everybody gives you access to a much wider array of human experiences how valuable do you think it is well if you want to understand human nature and nature in general then i think you have to better understand a wide variety of experiences not just sitting in a lab staring at a screen and having a face flashed onto you for a hundred milliseconds and pushing a button thats what i used to do thats what most psychologists do theres nothing wrong with that but you need to consider lots of other strange states and literature is a shortcut for this well yeah because literature thats what literature is all about all sorts of interesting experiences that people have the contingency of it the fact that women experience the world different black people experience the world different the one way to experience that is reading all these different literature and try to find out you see everything is so relative you read a book 300 years ago they thought about certain problems very very differently than us today we today like any culture think we know it all thats common to every culture every culture believes at its heyday they know it all and then you realize well theres other ways of viewing the universe and some of them may have lots of things in their favor so this is a question i wanted to ask about time scale or scale in general when you with iit or in general try to think about consciousness try to think about these ideas we kind of naturally think in human time scales and also entities that are sized close to humans do you think of things that are much larger and much smaller as containing consciousness and do you think of things that take you know eons to operate in their conscious cause effect thats a very good question so i think a lot about small creatures because experimentally you know a lot of people work on flies and bees right so most people just think they are automata theyre just bugs for heavens sake right but if you look at their behavior like bees they can recognize individual humans they have this very complicated way to communicate if youve ever been involved or you know your parents when they bought a house what sort of agonizing decision that is and bees have to do that once a year right when they swarm in the spring and then they have this very elaborate way they have free and scouts they go to the individual sites they come back they have this power this dance literally where they dance for several days they try to recruit other deets this very complicated decision rate when they finally once they make a decision the entire swarm the scouts warm up the entire swarm and then go to one location they dont go to 50 locations they go to one location that the scouts have agreed upon by themselves thats awesome if we look at the circuit complexity its 10 times more denser than anything we have in our brain now they only have a million neurons but the neurons are amazingly complex complex behavior very complicated circuitry so theres no question they experience something their life is very different theyre tiny they only live you know for well workers live maybe for two months so i think and iit tells you this in principle the substrate of consciousness is the substrate that maximizes the cause effect power over all possible spatial temporal grains so when i think about for example do you know the science fiction story the black cloud okay its a classic by fred hoyle the astronomer he has this cloud intervening between the earth and the sun and leading to some sort of to global cooling this is written in the 50s it turns out you can using the radio dish they communicate with actually an entity its actually an intelligent entity and they sort of they convince it to move away so here you have a radical different entity and in principle iit says well you can measure the integrated information in principle at least and yes if the maximum of that occurs at a time scale of months rather than in assets for a fraction of a second yes then they would experience life where each moment is a month rather than or microsecond right rather than a fraction of a second in the human case and so there may be forms of consciousness that we simply dont recognize for what they are because they are so radical different from anything you and i are used to again thats why its good to read or to watch science fiction movies well to think about this do you know stanislav lem this polish science fiction writer he wrote solaris and was turned into a hollywood movie yes his best novel is in the 60s a very engineer hes an engineer in background his most interesting novel is called the victorious where human civilization they have this mission to this planet and everything is destroyed and they discover machines humans got killed and then these machines took over and there was this machine evolution darwinian evolution he talks about this very vividly and finally the dominant machine intelligence organism that survived were gigantic clouds of little hexagonal universal cellular automata this was written in the 60s so typically theyre all lying on the ground individual by themselves but in times of crisis they can communicate they assemble into gigantic nets into clouds of trillions of these particles and then they become hyper intelligent and they can beat anything that humans can throw at it its very beautiful and compelling where you have an intelligence where finally the humans leave the planet theyre simply unable to understand and comprehend this creature they can say well either we can nuke the entire planet and destroy it or we just have to leave because fundamentally its an alien its so alien from us and our ideas that we cannot communicate with them yeah actually in conversation so youre talking to us steven wolf from brought up is that there could be ideas that you already have these artificial general intelligence like super smart or maybe conscious beings in the cellular automata we just dont know how to talk to them so its the language of communication but you dont know what to do with it so thats one sort of view is consciousness is only something you can measure so its not conscious if you cant measure it so youre making an ontological and an epistemic statement one is its just like seeing the multiverses that might be true but i cant communicate with them i cant have any knowledge of them thats an epistemic argument right so those are two different things so it may well be possible look in another case thats happening right now people are building these mini organoids do you know what this is so you can take stem cells from under your arm put it in a dish add four transcription factors and then you can induce them to grow into large well large theyre a few millimeters theyre like a half a million neurons that look like nerve cells in a dish called mini organoids at harvard at stanford everywhere theyre building them it may well be possible that theyre beginning to feel like something but we cant really communicate with them right now so people are beginning to think about the ethics of this so yes he may be perfectly right but its one question are they conscious or not its a totally separate question how would i know those are two different things if you could give advice to a young researcher sort of dreaming of understanding or creating human level intelligence or consciousness what would you say just follow your dreams read widely no i mean i suppose with discipline what is the pursuit that they should take on is it neuroscience is it computational cognitive science is it philosophy is it computer science or robotics no in a sense that okay so the only known system that have high level of intelligence is homo sapiens so if you wanted to build it its probably good to continue to study closely what humans do so cognitive neuroscience you know somewhere between cognitive neuroscience on the one hand and some philosophy of mind and then ai ai computer science you can look at all the original ideas in your network they all came from neuroscience right reinforce whether its snarky minsky building is snarky or whether its you know the early hubel and wiesel experiments at harvard that then gave rise to networks and then multi layer networks so it may well be possible in fact some people argue that to make the next big step in ai once we realize the limits of deep convolutional networks they can do certain things but they cant really understand they dont they cant really i cant really show them one image i can show you a single image of somebody a pickpocket who steals a wallet from a purse you immediately know thats a pickpocket now computer system would just say well its a man its a woman its a purse right unless you train this machine on showing it a hundred thousand pickpockets right so it doesnt have this easy understanding that you have right so some people make the argument in order to go to the next step or you really want to build machines that understand in a way you and i we have to go to psychology we need to understand how we do it and how our brains enable us to do it and so therefore being on the cusp its also so exciting to try to understand better our nature and then to build to take some of those inside and build them so i think the most exciting thing is somewhere in the interface between cognitive science neuroscience ai computer science and philosophy of mind beautiful yeah id say if there is from the machine learning from our from the computer science computer vision perspective many of the researchers kind of ignore the way the human brain works or even psychology or literature or studying the brain i would hope josh tenenbaum talks about bringing that in more and more and thats yeah so youve worked on some amazing stuff throughout your life whats the thing that youre really excited about whats the mystery that you would love to uncover in the near term beyond beyond all the mysteries that youre already surrounded by well so theres a structure called the claustrum this is a structure its underneath our cortex its yay big you have one on the left on the right underneath this underneath the insula its very thin its like one millimeter its embedded in in wiring in white matter so its very difficult to image and it has it has connection to every cortical region and francis crick the last paper he ever wrote he dictated corrections the day he died in hospital on this paper you know we hypothesize well because it has this unique anatomy it gets input from every cortical area and projects back to every every cortical area that the function of this structure is similar its just a metaphor to the role of a conductor in a symphony orchestra you have all the different cortical players you have some that do motion some that do theory of mind some that infer social interaction and color and hearing and all the different modules in cortex but of course what consciousness is consciousness puts it all together into one package right the binding problem all of that and this is really the function because it has relatively few neurons compared to cortex but it talks it receives input from all of them and it projects back to all of them and so were testing that right now weve got this beautiful neuronal reconstruction in the mouse called crown of thorns crown of thorns neurons that are in the claustrum that have the most widespread connection of any neuron ive ever seen theyre very you have individual neurons that sit in the claustrum tiny but then they have this single neuron they have this huge axonal tree that cover both ipsy and contralateral cortex and trying to turn using you know fancy tools like optogenetics trying to turn those neurons on or off and study it what happens in the in the mouse so this thing is perhaps where the parts become the whole perhaps its one of the structures its a very good way of putting it where the individual parts turn into the whole of the whole of the conscious experience well with that thank you very much for being here today thank you very much thank you very much all right thank you very much',\n",
              " 'youve studied the human mind cognition language vision evolution psychology from child to adult from the level of individual to the level of our entire civilization so i feel like i can start with a simple multiple choice question what is the meaning of life is it a to attain knowledge as plato said b to attain power as nietzsche said c to escape death as ernest becker said d to propagate our genes as darwin and others have said e there is no meaning as the nihilists have said f knowing the meaning of life is beyond our cognitive capabilities as stephen pinker said based on my interpretation 20 years ago and g none of the above id say a comes closest but i would amend that to c to attaining not only knowledge but fulfillment more generally that is life health stimulation access to the living cultural and social world now this is our meaning of life its not the meaning of life if you were to ask our genes their meaning is to propagate copies of themselves but that is distinct from the meaning that the brain that they lead to sets for itself so to you knowledge is a small subset or a large subset its a large subset but its not the entirety of human striving because we also want to interact with people we want to experience beauty we want to experience the richness of the natural world but understanding what makes the universe tick is way up there for some of us more than others certainly for me thats one of the top five so is that a fundamental aspect are you just describing your own preference or is this a fundamental aspect of human nature is to seek knowledge in your latest book you talk about the power the usefulness of rationality and reason and so on is that a fundamental nature of human beings or is it something we should just strive for both were capable of striving for it because it is one of the things that make us what we are homo sapiens wise men we are unusual among animals in the degree to which we acquire knowledge and use it to survive we make tools we strike agreements via language we extract poisons we predict the behavior of animals we try to get at the workings of plants and when i say we i dont just mean we in the modern west but we as a species everywhere which is how weve managed to occupy every niche on the planet how weve managed to drive other animals to extinction and the refinement of reason in pursuit of human wellbeing of health happiness social richness cultural richness is our main challenge in the present that is using our intellect using our knowledge to figure out how the world works how we work in order to make discoveries and strike agreements that make us all better off in the long run right and you do that almost undeniably and in a data driven way in your recent book but id like to focus on the artificial intelligence aspect of things and not just artificial intelligence but natural intelligence too so 20 years ago in a book youve written on how the mind works you conjecture again am i right to interpret things you can correct me if im wrong but you conjecture that human thought in the brain may be a result of a massive network of highly interconnected neurons so from this interconnectivity emerges thought compared to artificial neural networks which we use for machine learning today is there something fundamentally more complex mysterious even magical about the biological neural networks versus the ones weve been starting to use over the past 60 years and have become to success in the past 10 there is something a little bit mysterious about the human neural networks which is that each one of us who is a neural network knows that we ourselves are conscious conscious not in the sense of registering our surroundings or even registering our internal state but in having subjective first person present tense experience that is when i see red its not just different from green but theres a redness to it that i feel whether an artificial system would experience that or not i dont know and i dont think i can know thats why its mysterious if we had a perfectly lifelike robot that was behaviorally indistinguishable from a human would we attribute consciousness to it or ought we to attribute consciousness to it and thats something that its very hard to know but putting that aside putting aside that largely philosophical question the question is is there some difference between the human neural network and the ones that were building in artificial intelligence will mean that were on the current trajectory not going to reach the point where weve got a lifelike robot indistinguishable from a human because the way their so called neural networks are organized are different from the way ours are organized i think theres overlap but i think there are some big differences that current neural networks current so called deep learning systems are in reality not all that deep that is they are very good at extracting high order statistical regularities but most of the systems dont have a semantic level a level of actual understanding of who did what to whom why where how things work what causes what else do you think that kind of thing can emerge as it does so artificial neural networks are much smaller the number of connections and so on than the current human biological networks but do you think sort of to go to consciousness or to go to this higher level semantic reasoning about things do you think that can emerge with just a larger network with a more richly weirdly interconnected network separate it in consciousness because consciousness is even a matter of complexity a really weird one yeah you could sensibly ask the question of whether shrimp are conscious for example theyre not terribly complex but maybe they feel pain so lets just put that part of it aside but i think sheer size of a neural network is not enough to give it structure and knowledge but if its suitably engineered then why not that is were neural networks natural selection did a kind of equivalent of engineering of our brains so i dont think theres anything mysterious in the sense that no system made out of silicon could ever do what a human brain can do i think its possible in principle whether itll ever happen depends not only on how clever we are in engineering these systems but whether we even want to whether thats even a sensible goal that is you can ask the question is there any locomotion system that is as good as a human well we kind of want to do better than a human ultimately in terms of legged locomotion theres no reason that humans should be our benchmark theyre tools that might be better in some ways it may be that we cant duplicate a natural system because at some point its so much cheaper to use a natural system that were not going to invest more brainpower and resources so for example we dont really have an exact substitute for wood we still build houses out of wood we still build furniture out of wood we like the look we like the feel it has certain properties that synthetics dont its not that theres anything magical or mysterious about wood its just that the extra steps of duplicating everything about wood is something we just havent bothered because we have wood likewise say cotton im wearing cotton clothing now it feels much better than polyester its not that cotton has something magic in it its not that we couldnt ever synthesize something exactly like cotton but at some point its just not worth it weve got cotton likewise in the case of human intelligence the goal of making an artificial system that is exactly like the human brain is a goal that we probably know is going to pursue to the bitter end i suspect because if you want tools that do things better than humans youre not going to care whether it does something like humans so for example diagnosing cancer or predicting the weather why set humans as your benchmark but in general i suspect you also believe that even if the human should not be a benchmark and we dont want to imitate humans in their system theres a lot to be learned about how to create an artificial intelligence system by studying the human yeah i think thats right in the same way that to build flying machines we want to understand the laws of aerodynamics including birds but not mimic the birds but theyre the same laws you have a view on ai artificial intelligence and safety that from my perspective is refreshingly rational or perhaps more importantly has elements of positivity to it which i think can be inspiring and empowering as opposed to paralyzing for many people including ai researchers the eventual existential threat of ai is obvious not only possible but obvious and for many others including ai researchers the threat is not obvious so elon musk is famously in the highly concerned about ai camp saying things like ai is far more dangerous than nuclear weapons and that ai will likely destroy human civilization human civilization so in february he said that if elon was really serious about ai the threat of ai he would stop building self driving cars that hes doing very successfully as part of tesla then he said wow if even pinker doesnt understand the difference between narrow ai like a car and general ai when the latter literally has a million times more compute power and an open ended utility function humanity is in deep trouble so first what did you mean by the statement about elon musk should stop building self driving cars if hes deeply concerned not the last time that elon musk has fired off an intemperate tweet well we live in a world where twitter has power yes yeah i think there are two kinds of existential threat that have been discussed in connection with artificial intelligence and i think that theyre both incoherent one of them is a vague fear of ai takeover that just as we subjugated animals and less technologically advanced peoples so if we build something thats more advanced than us it will inevitably turn us into pets or slaves or domesticated animal equivalents i think this confuses intelligence with a will to power that it so happens that in the intelligence system we are most familiar with namely homo sapiens we are products of natural selection which is a competitive process and so bundled together with our problem solving capacity are a number of nasty traits like dominance and exploitation and maximization of power and glory and resources and influence theres no reason to think that sheer problem solving capability will set that as one of its goals its goals will be whatever we set its goals as and as long as someone isnt building a megalomaniacal artificial intelligence then theres no reason to think that it would naturally evolve in that direction now you might say well what if we gave it the goal of maximizing its own power source thats a pretty stupid goal to give an autonomous system you dont give it that goal i mean thats just self evidently idiotic so if you look at the history of the world theres been a lot of opportunities where engineers could instill in a system destructive power and they choose not to because thats the natural process of engineering well except for weapons i mean if youre building a weapon its goal is to destroy people and so i think there are good reasons to not build certain kinds of weapons i think building nuclear weapons was a massive mistake you do so maybe pause on that because that is one of the serious threats do you think that it was a mistake in a sense that it should have been stopped early on or do you think its just an unfortunate event of invention that this was invented do you think its possible to stop i guess is the question its hard to rewind the clock because of course it was invented in the context of world war ii and the fear that the nazis might develop one first then once it was initiated for that reason it was hard to turn off especially since winning the war against the japanese and the nazis was such an overwhelming goal of every responsible person that theres just nothing that people wouldnt have done then to ensure victory its quite possible if world war ii hadnt happened that nuclear weapons wouldnt have been invented we cant know but i dont think it was by any means a necessity any more than some of the other weapon systems that were envisioned but never implemented like planes that would disperse poison gas over cities like crop dusters or systems to try to create earthquakes and tsunamis in enemy countries to weaponize the weather weaponize solar flares all kinds of crazy schemes that we thought the better of i think analogies between nuclear weapons and artificial intelligence are fundamentally misguided because the whole point of nuclear weapons is to destroy things the point of artificial intelligence is not to destroy things so the analogy is misleading so theres two artificial intelligence you mentioned the first one i guess is highly intelligent or power hungry yeah its a system that we design ourselves where we give it the goals goals are external to the means to attain the goals if we dont design an artificially intelligent system to maximize dominance then it wont maximize dominance its just that were so familiar with homo sapiens where these two traits come bundled together particularly in men that we are apt to confuse high intelligence with a will to power but thats just an error the other fear is that will be collateral damage that will give artificial intelligence a goal like make paper clips and it will pursue that goal so brilliantly that before we can stop it it turns us into paper clips well give it the goal of curing cancer and it will turn us into guinea pigs for lethal experiments or give it the goal of world peace and its conception of world peace is no people therefore no fighting and so it will kill us all now i think these are utterly fanciful in fact i think theyre actually self defeating they first of all assume that were going to be so brilliant that we can design an artificial intelligence that can cure cancer but so stupid that we dont specify what we mean by curing cancer in enough detail that it wont kill us in the process and it assumes that the system will be so smart that it can cure cancer but so idiotic that it cant figure out that what we mean by curing cancer is not killing everyone i think that the collateral damage scenario the value alignment problem is also based on a misconception so one of the challenges of course we dont know how to build either system currently or are we even close to knowing of course those things can change overnight but at this time theorizing about it is very challenging in either direction so thats probably at the core of the problem is without that ability to reason about the real engineering things here at hand is your imagination runs away with things exactly but let me sort of ask what do you think was the motivation the thought process of elon musk i build autonomous vehicles i study autonomous vehicles i study tesla autopilot i think it is one of the greatest currently large scale application of artificial intelligence in the world it has potentially a very positive impact on society so how does a person whos creating this very good quote unquote narrow ai system also seem to be so concerned about this other general ai what do you think is the motivation there what do you think is the thing well you probably have to ask him but there and he is notoriously flamboyant impulsive to the as we have just seen to the detriment of his own goals of the health of the company so i dont know whats going on in his mind you probably have to ask him but i dont think the and i dont think the distinction between special purpose ai and so called general ai is relevant that in the same way that special purpose ai is not going to do anything conceivable in order to attain a goal all engineering systems are designed to trade off across multiple goals when we build cars in the first place we didnt forget to install brakes because the goal of a car is to go fast it occurred to people yes you want it to go fast but not always so you would build in brakes too likewise if a car is going to be autonomous and program it to take the shortest route to the airport its not going to take the diagonal and mow down people and trees and fences because thats the shortest route thats not what we mean by the shortest route when we program it and thats just what an intelligence system is by definition it takes into account multiple constraints the same is true in fact even more true of so called general intelligence that is if its genuinely intelligent its not going to pursue some goal singlemindedly omitting every other consideration and collateral effect thats not artificial and general intelligence thats artificial stupidity i agree with you by the way on the promise of autonomous vehicles for improving human welfare i think its spectacular and im surprised at how little press coverage notes that in the united states alone something like 40000 people die every year on the highways vastly more than are killed by terrorists and we spent a trillion dollars on a war to combat deaths by terrorism about half a dozen a year whereas year in year out 40000 people are massacred on the highways which could be brought down to very close to zero so im with you on the humanitarian benefit let me just mention that as a person whos building these cars it is a little bit offensive to me to say that engineers would be clueless enough not to engineer safety into systems i often stay up at night thinking about those 40000 people that are dying and everything i tried to engineer is to save those peoples lives so every new invention that im super excited about in all the deep learning literature and cvpr conferences and nips everything im super excited about is all grounded in making it safe and help people so i just dont see how that trajectory can all of a sudden slip into a situation where intelligence will be highly negative you and i certainly agree on that and i think thats only the beginning of the potential humanitarian benefits of artificial intelligence theres been enormous attention to what are we going to do with the people whose jobs are made obsolete by artificial intelligence but very little attention given to the fact that the jobs that are going to be made obsolete are horrible jobs the fact that people arent going to be picking crops and making beds and driving trucks and mining coal these are soul deadening jobs and we have a whole literature sympathizing with the people stuck in these menial mind deadening dangerous jobs if we can eliminate them this is a fantastic boon to humanity now granted you solve one problem and theres another one namely how do we get these people a decent income but if were smart enough to invent machines that can make beds and put away dishes and handle hospital patients i think were smart enough to figure out how to redistribute income to apportion some of the vast economic savings to the human beings who will no longer be needed to make beds okay sam harris says that its obvious that eventually ai will be an existential risk hes one of the people who says its obvious we dont know when the claim goes but eventually its obvious and because we dont know when we should worry about it now this is a very interesting argument in my eyes so how do we think about timescale how do we think about existential threats when we dont really we know so little about the threat unlike nuclear weapons perhaps about this particular threat that it could happen tomorrow right so but very likely it wont very likely itd be a hundred years away so how do we ignore it how do we talk about it do we worry about it how do we think about those what is it a threat that we can imagine its within the limits of our imagination but not within our limits of understanding to accurately predict it but what is the it that were afraid of sorry ai being the existential threat ai how like enslaving us or turning us into paperclips i think the most compelling from the sam harris perspective would be the paperclip situation yeah i mean i just think its totally fanciful i mean that is dont build a system dont give a dont first of all the code of engineering is you dont implement a system with massive control before testing it now perhaps the culture of engineering will radically change then i would worry but i dont see any signs that engineers will suddenly do idiotic things like put a electric power plant in control of a system that they havent tested first or all of these scenarios not only imagine almost a magically powered intelligence including things like cure cancer which is probably an incoherent goal because theres so many different kinds of cancer or bring about world peace i mean how do you even specify that as a goal but the scenarios also imagine some degree of control of every molecule in the universe which not only is itself unlikely but we would not start to connect these systems to infrastructure without testing as we would any kind of engineering system now maybe some engineers will be irresponsible and we need legal and regulatory and legal responsibility implemented so that engineers dont do things that are stupid by their own standards but the ive never seen enough of a plausible scenario of existential threat to devote large amounts of brain power to to forestall it so you believe in the sort of the power on mass of the engineering of reason as you argue in your latest book of reason and science to sort of be the very thing that guides the development of new technology so its safe and also keeps us safe you know granted the same culture of safety that currently is part of the engineering mindset for airplanes for example so yeah i dont think that that should be thrown out the window and that untested all powerful systems should be suddenly implemented but theres no reason to think they are and in fact if you look at the progress of artificial intelligence its been you know its been impressive especially in the last 10 years or so but the idea that suddenly therell be a step function that all of a sudden before we know it it will be all powerful that therell be some kind of recursive self improvement some kind of fume is also fanciful we certainly by the technology that we that were now impresses us such as deep learning where you train something on hundreds of thousands or millions of examples theyre not hundreds of thousands of problems of which curing cancer is a typical example and so the kind of techniques that have allowed ai to increase in the last five years are not the kind that are going to lead to this fantasy of exponential sudden self improvement i think its kind of a magical thinking its not based on our understanding of how ai actually works now give me a chance here so you said fanciful magical thinking in his ted talk sam harris says that thinking about ai killing all human civilization is somehow fun intellectually now i have to say as a scientist engineer i dont find it fun but when im having beer with my non ai friends there is indeed something fun and appealing about it like talking about an episode of black mirror considering if a large meteor is headed towards earth we were just told a large meteor is headed towards earth something like this and can you relate to this sense of fun and do you understand the psychology of it yes good question i personally dont find it fun i find it kind of actually a waste of time because there are genuine threats that we ought to be thinking about like pandemics like cyber security vulnerabilities like the possibility of nuclear war and certainly climate change you know this is enough to fill many conversations and i think sam did put his finger on something namely that there is a community sometimes called the rationality community that delights in using its brainpower to come up with scenarios that would not occur to mere mortals to less cerebral people so there is a kind of intellectual thrill in finding new things to worry about that no one has worried about yet i actually think though that its not only is it a kind of fun that doesnt give me particular pleasure but i think there can be a pernicious side to it namely that you overcome people with such dread such fatalism that there are so many ways to die to annihilate our civilization that we may as well enjoy life while we can theres nothing we can do about it if climate change doesnt do us in then runaway robots will so lets enjoy ourselves now weve got to prioritize we have to look at threats that are close to certainty such as climate change and distinguish those from ones that are merely imaginable but with infinitesimal probabilities and we have to take into account peoples worry budget you cant worry about everything and if you sow dread and fear and terror and fatalism it can lead to a kind of numbness well these problems are overwhelming and the engineers are just going to kill us all so lets either destroy the entire infrastructure of science technology or lets just enjoy life while we can so theres a certain line of worry which im worried about a lot of things in engineering theres a certain line of worry when you cross youre allowed to cross that it becomes paralyzing fear as opposed to productive fear and thats kind of what youre highlighting exactly right and weve seen some we know that human effort is not well calibrated against risk in that because a basic tenet of cognitive psychology is that perception of risk and hence perception of fear is driven by imaginability not by data and so we misallocate vast amounts of resources to avoiding terrorism which kills on average about six americans a year with one exception of 9 11 we invade countries we invent entire new departments of government with massive massive expenditure of resources and lives to defend ourselves against a trivial risk whereas guaranteed risks one of them you mentioned traffic fatalities and even risks that are not here but are plausible enough to worry about like pandemics like nuclear war receive far too little attention in presidential debates theres no discussion of how to minimize the risk of nuclear war lots of discussion of terrorism for example and so i think its essential to calibrate our budget of fear worry concern planning to the actual probability of harm yep so let me ask this question so speaking of imaginability you said its important to think about reason and one of my favorite people who likes to dip into the outskirts of reason through fascinating exploration of his imagination is joe rogan oh yes so who has through reason used to believe a lot of conspiracies and through reason has stripped away a lot of his beliefs in that way so its fascinating actually to watch him through rationality kind of throw away the ideas of bigfoot and 9 11 im not sure exactly kim trails i dont know what he believes in yes okay but he no longer believed in no thats right no hes become a real force for good yep so you were on the joe rogan podcast in february and had a fascinating conversation but as far as i remember didnt talk much about artificial intelligence i will be on his podcast in a couple of weeks joe is very much concerned about existential threat of ai im not sure if youre this is why i was hoping that you would get into that topic and in this way he represents quite a lot of people who look at the topic of ai from 10000 foot level so as an exercise of communication you said its important to be rational and reason about these things let me ask if you were to coach me as an ai researcher about how to speak to joe and the general public about ai what would you advise well the short answer would be to read the sections that i wrote in enlightenment now about ai but a longer reason would be i think to emphasize and i think youre very well positioned as an engineer to remind people about the culture of engineering that it really is safety oriented that another discussion in enlightenment now i plot rates of accidental death from various causes plane crashes car crashes occupational accidents even death by lightning strikes and they all plummet because the culture of engineering is how do you squeeze out the lethal risks death by fire death by drowning death by asphyxiation all of them drastically declined because of advances in engineering that i got to say i did not appreciate until i saw those graphs and it is because exactly people like you who stay up at night thinking oh my god is what im inventing likely to hurt people and to deploy ingenuity to prevent that from happening now im not an engineer although i spent 22 years at mit so i know something about the culture of engineering my understanding is that this is the way you think if youre an engineer and its essential that that culture not be suddenly switched off when it comes to artificial intelligence so i mean that could be a problem but is there any reason to think it would be switched off i dont think so and one theres not enough engineers speaking up for this way for the excitement for the positive view of human nature what youre trying to create is positivity like everything we try to invent is trying to do good for the world but let me ask you about the psychology of negativity it seems just objectively not considering the topic it seems that being negative about the future makes you sound smarter than being positive about the future irregardless of topic am i correct in this observation and if so why do you think that is yeah i think there is that phenomenon that as tom lehrer the satirist said always predict the worst and youll be hailed as a prophet it may be part of our overall negativity bias we are as a species more attuned to the negative than the positive we dread losses more than we enjoy gains and that might open up a space for prophets to remind us of harms and risks and losses that we may have overlooked so i think there is that asymmetry so youve written some of my favorite books all over the place so starting from enlightenment now to the better ages of our nature blank slate how the mind works the one about language language instinct bill gates big fan too said of your most recent book that its my new favorite book of all time so for you as an author what was a book early on in your life that had a profound impact on the way you saw the world certainly this book enlightenment now was influenced by david deutschs the beginning of infinity a rather deep reflection on knowledge and the power of knowledge to improve the human condition and with bits of wisdom such as that problems are inevitable but problems are solvable given the right knowledge and that solutions create new problems that have to be solved in their turn thats i think a kind of wisdom about the human condition that influenced the writing of this book there are some books that are excellent but obscure some of which i have on a page on my website i read a book called the history of force self published by a political scientist named james payne on the historical decline of violence and that was one of the inspirations for the better angels of our nature what about early on if you look back when you were maybe a teenager i loved a book called one two three infinity when i was a young adult i read that book by george gamow the physicist which had very accessible and humorous explanations of relativity of number theory of dimensionality high multiple dimensional spaces in a way that i think is still delightful 70 years after it was published i like the time life science series these are books that would arrive every month that my mother subscribed to each one on a different topic one would be on electricity one would be on forests one would be on evolution and then one was on the mind i was just intrigued that there could be a science of mind and that book i would cite as an influence as well then later on thats when you fell in love with the idea of studying the mind was that the thing that grabbed you it was one of the things i would say i read as a college student the book reflections on language by noam chomsky i spent most of his career here at mit richard dawkins two books the blind watchmaker and the selfish gene were enormously influential mainly for the content but also for the writing style the ability to explain abstract concepts in lively prose stephen jay goulds first collection ever since darwin also an excellent example of lively writing george miller a psychologist that most psychologists are familiar with came up with the idea that human memory has a capacity of seven plus or minus two chunks thats probably his biggest claim to fame but he wrote a couple of books on language and communication that i read as an undergraduate again beautifully written and intellectually deep wonderful stephen thank you so much for taking the time today my pleasure thanks a lot lex',\n",
              " 'what difference between biological neural networks and artificial neural networks is most mysterious captivating and profound for you first of all theres so much we dont know about biological neural networks and thats very mysterious and captivating because maybe it holds the key to improving artificial neural networks one of the things i studied recently is something that we dont know how biological neural networks do but would be really useful for artificial ones is the ability to do credit assignment through very long time spans there are things that we can in principle do with artificial neural nets but its not very convenient and its not biologically plausible and this mismatch i think this kind of mismatch may be an interesting thing to study to a understand better how brains might do these things because we dont have good corresponding theories with artificial neural nets and b maybe provide new ideas that we could explore about things that brain do differently and that we could incorporate in artificial neural nets so lets break credit assignment up a little bit yes so what its a beautifully technical term but it could incorporate so many things so is it more on the rnn memory side that thinking like that or is it something about knowledge building up common sense knowledge over time or is it more in the reinforcement learning sense that youre picking up rewards over time for a particular to achieve a certain kind of goal so i was thinking more about the first two meanings whereby we store all kinds of memories episodic memories in our brain which we can access later in order to help us both infer causes of things that we are observing now and assign credit to decisions or interpretations we came up with a while ago when those memories were stored and then we can change the way we would have reacted or interpreted things in the past and now thats credit assignment used for learning so in which way do you think artificial neural networks the current lstm the current architectures are not able to capture the presumably youre thinking of very long term yes so current the current nets are doing a fairly good jobs for sequences with dozens or say hundreds of time steps and then it gets harder and harder and depending on what you have to remember and so on as you consider longer durations whereas humans seem to be able to do credit assignment through essentially arbitrary times like i could remember something i did last year and then now because i see some new evidence im going to change my mind about the way i was thinking last year and hopefully not do the same mistake again i think a big part of that is probably forgetting youre only remembering the really important things its very efficient forgetting yes so theres a selection of what we remember and i think there are really cool connection to higher level cognition here regarding consciousness deciding and emotions so deciding what comes to consciousness and what gets stored in memory which are not trivial either so youve been at the forefront there all along showing some of the amazing things that neural networks deep neural networks can do in the field of artificial intelligence is just broadly in all kinds of applications but we can talk about that forever but what in your view because were thinking towards the future is the weakest aspect of the way deep neural networks represent the world what is that what is in your view is missing so current state of the art neural nets trained on large quantities of images or texts have some level of understanding of you know what explains those data sets but its very basic its its very low level and its not nearly as robust and abstract and general as our understanding okay so that doesnt tell us how to fix things but i think it encourages us to think about how we can maybe train our neural nets differently so that they would focus for example on causal explanation something that we dont do currently with neural net training also one thing ill talk about in my talk this afternoon is the fact that instead of learning separately from images and videos on one hand and from texts on the other hand we need to do a better job of jointly learning about language and about the world to which it refers so that you know both sides can help each other we need to have good world models in our neural nets for them to really understand sentences which talk about whats going on in the world and i think we need language input to help provide clues about what high level concepts like semantic concepts should be represented at the top levels of our neural nets in fact there is evidence that the purely unsupervised learning of representations doesnt give rise to high level representations that are as powerful as the ones were getting from supervised learning and so the clues were getting just with the labels not even sentences is already very very high level and i think thats a very important thing to keep in mind its already very powerful do you think thats an architecture challenge or is it a data set challenge neither im tempted to just end it there can you elaborate slightly of course data sets and architectures are something you want to always play with but i think the crucial thing is more the training objectives the training frameworks for example going from passive observation of data to more active agents which learn by intervening in the world the relationships between causes and effects the sort of objective functions which could be important to allow the highest level explanations to rise from the learning which i dont think we have now the kinds of objective functions which could be used to reward exploration the right kind of exploration so these kinds of questions are neither in the data set nor in the architecture but more in how we learn under what objectives and so on yeah ive heard you mention in several contexts the idea of sort of the way children learn they interact with objects in the world and it seems fascinating because in some sense except with some cases in reinforcement learning that idea is not part of the learning process in artificial neural networks so its almost like do you envision something like an objective function saying you know what if you poke this object in this kind of way it would be really helpful for me to further learn right right sort of almost guiding some aspect of the learning right right right so i was talking to rebecca sacks just a few minutes ago and she was talking about lots and lots of evidence from infants seem to clearly pick what interests them in a directed way and so theyre not passive learners they focus their attention on aspects of the world which are most interesting surprising in a non trivial way that makes them change their theories of the world so thats a fascinating view of the future progress but on a more maybe boring question do you think going deeper and larger so do you think just increasing the size of the things that have been increasing a lot in the past few years is going to be a big thing i think increasing the size of the things that have been increasing a lot in the past few years will also make significant progress so some of the representational issues that you mentioned theyre kind of shallow in some sense oh shallow in the sense of abstraction in the sense of abstraction theyre not getting some i dont think that having more depth in the network in the sense of instead of 100 layers youre going to have more layers i dont think so is that obvious to you yes what is clear to me is that engineers and companies and labs and grad students will continue to tune architectures and explore all kinds of tweaks to make the current state of the art slightly ever slightly better but i dont think thats going to be nearly enough i think we need changes in the way that were considering learning to achieve the goal that these learners actually understand in a deep way the environment in which they are you know observing and acting but i guess i was trying to ask a question thats more interesting than just more layers its basically once you figure out a way to learn through interacting how many parameters it takes to store that information so i think our brain is quite bigger than most neural networks right right oh i see what you mean oh im with you there so i agree that in order to build neural nets with the kind of broad knowledge of the world that typical adult humans have probably the kind of computing power we have now is going to be insufficient so the good news is there are hardware companies building neural net chips and so its going to get better however the good news in a way which is also a bad news is that even our state of the art deep learning methods fail to learn models that understand even very simple environments like some grid worlds that we have built even these fairly simple environments i mean of course if you train them with enough examples eventually they get it but its just like instead of what humans might need just dozens of examples these things will need millions for very very very simple tasks and so i think theres an opportunity for academics who dont have the kind of computing power that say google has to do really important and exciting research to advance the state of the art in training frameworks learning models agent learning in even simple environments that are synthetic that seem trivial but yet current machine learning fails on we talked about priors and common sense knowledge it seems like we humans take a lot of knowledge for granted so whats your view of these priors of forming this broad view of the world this accumulation of information and how we can teach neural networks or learning systems to pick that knowledge up so knowledge for a while the artificial intelligence was maybe in the 80s like theres a time where knowledge representation knowledge acquisition expert systems i mean the symbolic ai was a view was an interesting problem set to solve and it was kind of put on hold a little bit it seems like because it doesnt work it doesnt work thats right but thats right but the goals of that remain important yes remain important and how do you think those goals can be addressed right so first of all i believe that one reason why the classical expert systems approach failed is because a lot of the knowledge we have so you talked about common sense intuition theres a lot of knowledge like this which is not consciously accessible there are lots of decisions were taking that we cant really explain even if sometimes we make up a story and that knowledge is also necessary for machines to take good decisions and that knowledge is hard to codify in expert systems rule based systems and classical ai formalism and there are other issues of course with the old ai like not really good ways of handling uncertainty i would say something more subtle which we understand better now but i think still isnt enough in the minds of people theres something really powerful that comes from distributed representations the thing that really makes neural nets work so well and its hard to replicate that kind of power in a symbolic world the knowledge in expert systems and so on is nicely decomposed into like a bunch of rules whereas if you think about a neural net its the opposite you have this big blob of parameters which work intensely together to represent everything the network knows and its not sufficiently factorized its not sufficiently factorized and so i think this is one of the weaknesses of current neural nets that we have to take lessons from classical ai in order to bring in another kind of compositionality which is common in language for example and in these rules but that isnt so native to neural nets and on that line of thinking disentangled representations yes so let me connect with disentangled representations if you might if you dont mind so for many years ive thought and i still believe that its really important that we come up with learning algorithms either unsupervised or supervised but reinforcement whatever that build representations in which the important factors hopefully causal factors are nicely separated and easy to pick up from the representation so thats the idea of disentangled representations it says transform the data into a space where everything becomes easy we can maybe just learn with linear models about the things we care about and i still think this is important but i think this is missing out on a very important ingredient which classical ai systems can remind us of so lets say we have these disentangled representations you still need to learn about the relationships between the variables those high level semantic variables theyre not going to be independent i mean this is like too much of an assumption theyre going to have some interesting relationships that allow to predict things in the future to explain what happened in the past the kind of knowledge about those relationships in a classical ai system is encoded in the rules like a rule is just like a little piece of knowledge that says oh i have these two three four variables that are linked in this interesting way then i can say something about one or two of them given a couple of others right in addition to disentangling the elements of the representation which are like the variables in a rule based system you also need to disentangle the mechanisms that relate those variables to each other so like the rules so the rules are neatly separated like each rule is you know living on its own and when i change a rule because im learning it doesnt need to break other rules whereas current neural nets for example are very sensitive to whats called catastrophic forgetting where after ive learned some things and then i learn new things they can destroy the old things that i had learned right if the knowledge was better factorized and separated disentangled then you would avoid a lot of that now you cant do this in the sensory domain what do you mean by sensory domain like in pixel space but my idea is that when you project the data in the right semantic space it becomes possible to now represent this extra knowledge beyond the transformation from inputs to representations which is how representations act on each other and predict the future and so on in a way that can be neatly disentangled so now its the rules that are disentangled from each other and not just the variables that are disentangled from each other and you draw a distinction between semantic space and pixel like does there need to be an architectural difference well yeah so theres the sensory space like pixels which where everything is entangled the information like the variables are completely interdependent in very complicated ways and also computation like its not just the variables its also how they are related to each other is all intertwined but im hypothesizing that in the right high level representation space both the variables and how they relate to each other can be disentangled and that will provide a lot of generalization power generalization power yes distribution of the test set is assumed to be the same as the distribution of the training set right this is where current machine learning is too weak it doesnt tell us anything is not able to tell us anything about how our neural nets say are going to generalize to a new distribution and you know people may think well but theres nothing we can say if we dont know what the new distribution will be the truth is humans are able to generalize to new distributions yeah how are we able to do that yeah because there is something these new distributions even though they could look very different from the training distributions they have things in common so let me give you a concrete example you read a science fiction novel the science fiction novel maybe you know brings you in some other planet where things look very different on the surface but its still the same laws of physics and so you can read the book and you understand whats going on so the distribution is very different but because you can transport a lot of the knowledge you had from earth about the underlying cause and effect relationships and physical mechanisms and all that and maybe even social interactions you can now make sense of what is going on on this planet where like visually for example things are totally different taking that analogy further and distorting it lets enter a science fiction world of say space odyssey 2001 with hal or maybe which is probably one of my favorite ai movies me too and then theres another one that a lot of people love that may be a little bit outside of the ai community is ex machina i dont know if youve seen it yes yes by the way what are your views on that movie are you able to enjoy it are there things i like and things i hate so you could talk about that in the context of a question i want to ask which is theres quite a large community of people from different backgrounds often outside of ai who are concerned about existential threat of artificial intelligence youve seen this community develop over time youve seen you have a perspective so what do you think is the best way to talk about ai safety to think about it to have discourse about it within ai community and outside and grounded in the fact that ex machina is one of the main sources of information for the general public about ai so i think youre putting it right theres a big difference between the sort of discussion we ought to have within the ai community and the sort of discussion that really matter in the general public so i think the picture of terminator and ai loose and killing people and super intelligence thats going to destroy us whatever we try isnt really so useful for the public discussion because for the public discussion the things i believe really matter are the short term and medium term very likely negative impacts of ai on society whether its from security like you know big brother scenarios with face recognition or killer robots or the impact on the job market or concentration of power and discrimination all kinds of social issues which could actually some of them could really threaten democracy for example just to clarify when you said killer robots you mean autonomous weapon weapon systems yes i dont mean thats right so i think these short and medium term concerns should be important parts of the public debate now existential risk for me is a very unlikely consideration but still worth academic investigation in the same way that you could say should we study what could happen if meteorite you know came to earth and destroyed it so i think its very unlikely that this is going to happen in or happen in a reasonable future the sort of scenario of an ai getting loose goes against my understanding of at least current machine learning and current neural nets and so on its not plausible to me but of course i dont have a crystal ball and who knows what ai will be in 50 years from now so i think it is worth that scientists study those problems its just not a pressing question as far as im concerned so before i continue down that line i have a few questions there but what do you like and not like about ex machina as a movie because i actually watched it for the second time and enjoyed it i hated it the first time and i enjoyed it quite a bit more the second time when i sort of learned to accept certain pieces of it see it as a concept movie what was your experience what were your thoughts so the negative is the picture it paints of science is totally wrong science in general and ai in particular science is not happening in some hidden place by some you know really smart guy one person this is totally unrealistic this is not how it happens even a team of people in some isolated place will not make it science moves by small steps thanks to the collaboration and community of a large number of people interacting and all the scientists who are expert in their field kind of know what is going on even in the industrial labs its information flows and leaks and so on and the spirit of it is very different from the way science is painted in this movie yeah let me ask on that point its been the case to this point that kind of even if the research happens inside google or facebook inside companies it still kind of comes out ideas come out do you think that will always be the case with ai is it possible to bottle ideas to the point where theres a set of breakthroughs that go completely undiscovered by the general research community do you think thats even possible its possible but its unlikely its not how it is done now its not how i can foresee it in the foreseeable future but of course i dont have a crystal ball and science is a crystal ball and so who knows this is science fiction after all i think its ominous that the lights went off during that discussion so the problem again theres one thing is the movie and you could imagine all kinds of science fiction the problem for me maybe similar to the question about existential risk is that this kind of movie paints such a wrong picture of what is the actual science and how its going on that it can have unfortunate effects on peoples understanding of current science and so thats kind of sad theres an important principle in research which is diversity so in other words research is exploration research is exploration in the space of ideas and different people will focus on different directions and this is not just good its essential so im totally fine with people exploring directions that are contrary to mine or look orthogonal to mine i am more than fine i think its important i and my friends dont claim we have universal truth about what will especially about what will happen in the future now that being said we have our intuitions and then we act accordingly according to where we think we can be most useful and where society has the most to gain or to lose we should have those debates and not end up in a society where theres only one voice and one way of thinking and research money is spread out so disagreement is a sign of good research good science yes the idea of bias in the human sense of bias how do you think about instilling in machine learning something thats aligned with human values in terms of bias we intuitively as human beings have a concept of what bias means of what fundamental respect for other human beings means but how do we instill that into machine learning systems do you think so i think there are short term things that are already happening and then there are long term things that we need to do in the short term there are techniques that have been proposed and i think will continue to be improved and maybe alternatives will come up to take data sets in which we know there is bias we can measure it pretty much any data set where humans are being observed taking decisions will have some sort of bias discrimination against particular groups and so on and we can use machine learning techniques to try to build predictors classifiers that are going to be less biased we can do it for example using adversarial methods to make our systems less sensitive to these variables we should not be sensitive to so these are clear well defined ways of trying to address the problem maybe they have weaknesses and more research is needed and so on but i think in fact they are sufficiently mature that governments should start regulating companies where it matters say like insurance companies so that they use those techniques because those techniques will probably reduce the bias but at a cost for example maybe their predictions will be less accurate and so companies will not do it until you force them all right so this is short term long term im really interested in thinking how we can instill moral values into computers obviously this is not something well achieve in the next five or 10 years how can we you know theres already work in detecting emotions for example in images in sounds in texts and also studying how different agents interacting in different ways may correspond to patterns of say injustice which could trigger anger so these are things we can do in the medium term and eventually train computers to model for example how humans react emotionally i would say the simplest thing is unfair situations which trigger anger this is one of the most basic emotions that we share with other animals i think its quite feasible within the next few years that we can build systems that can detect these kinds of things to the extent unfortunately that they understand enough about the world around us which is a long time away but maybe we can initially do this in virtual environments so you can imagine a video game where agents interact in some ways and then some situations trigger an emotion i think we could train machines to detect those situations and predict that the particular emotion will likely be felt if a human was playing one of the characters you have shown excitement and done a lot of excellent work with unsupervised learning but theres been a lot of success on the supervised learning side yes yes and one of the things im really passionate about is how humans and robots work together and in the context of supervised learning that means the process of annotation do you think about the problem of annotation put in a more interesting way as humans teaching machines yes is there yes i think its an important subject reducing it to annotation may be useful for somebody building a system tomorrow but longer term the process of teaching i think is something that deserves a lot more attention from the machine learning community so there are people who have coined the term machine teaching so what are good strategies for teaching a learning agent and can we design and train a system that is going to be a good teacher so in my group we have a project called bbi or bbi game where there is a game or scenario where theres a learning agent and a teaching agent presumably the teaching agent would eventually be a human but were not there yet and the role of the teacher is to use its knowledge of the environment which it can acquire using whatever way brute force to help the learner learn as quickly as possible so the learner is going to try to learn by itself maybe using some exploration and whatever but the teacher can choose can have an influence on the interaction with the learner so as to guide the learner maybe teach it the things that the learner has most trouble with or just add the boundary between what it knows and doesnt know and so on so theres a tradition of these kind of ideas from other fields and like tutorial systems for example and ai and of course people in the humanities have been thinking about these questions but i think its time that machine learning people look at this because in the future well have more and more human machine interaction with the human in the loop and i think understanding how to make this work better all the problems around that are very interesting and not sufficiently addressed youve done a lot of work with language too what aspect of the traditionally formulated turing test a test of natural language understanding and generation in your eyes is the most difficult of conversation what in your eyes is the hardest part of conversation to solve for machines so i would say its everything having to do with the non linguistic knowledge which implicitly you need in order to make sense of sentences things like the winograd schema so these sentences that are semantically ambiguous in other words you need to understand enough about the world in order to really interpret properly those sentences i think these are interesting challenges for machine learning because they point in the direction of building systems that both understand how the world works and this causal relationships in the world and associate that knowledge with how to express it in language either for reading or writing you speak french yes its my mother tongue its one of the romance languages do you think passing the turing test and all the underlying challenges we just mentioned depend on language do you think it might be easier in french than it is in english or is independent of language i think its independent of language i would like to build systems that can use the same principles the same learning mechanisms to learn from human agents whatever their language well certainly us humans can talk more beautifully and smoothly in poetry some russian originally i know poetry in russian is maybe easier to convey complex ideas than it is in english but maybe im showing my bias and some people could say that about french but of course the goal ultimately is our human brain is able to utilize any kind of those languages to use them as tools to convey meaning yeah of course there are differences between languages and maybe some are slightly better at some things but in the grand scheme of things where were trying to understand how the brain works and language and so on i think these differences are minute so youve lived perhaps through an ai winter of sorts yes how did you stay warm and continue your research stay warm with friends with friends okay so its important to have friends and what have you learned from the experience listen to your inner voice dont you know be trying to just please the crowds and the fashion and if you have a strong intuition about something that is not contradicted by actual evidence go for it i mean it could be contradicted by people not your own instinct of based on everything youve learned of course you have to adapt your beliefs when your experiments contradict those beliefs but you have to stick to your beliefs otherwise its what allowed me to go through those years its what allowed me to persist in directions that you know took time whatever other people think took time to mature and bring fruits so history of ai is marked with these of course its marked with technical breakthroughs but its also marked with these seminal events that capture the imagination of the community most recent i would say alphago beating the world champion human go player was one of those moments what do you think the next such moment might be okay so first of all i think that these so called seminal events are overrated as i said science really moves by small steps now what happens is you make one more small step and its like the drop that you know that fills the bucket and then you have drastic consequences because now youre able to do something you were not able to do before or now say the cost of building some device or solving a problem becomes cheaper than what existed and you have a new market that opens up right so especially in the world of commerce and applications the impact of a small scientific progress could be huge but in the science itself i think its very very gradual and where are these steps being taken now so theres unsupervised learning so if i look at one trend that i like in my community so for example at milan my institute what are the two hardest topics gans and reinforcement learning even though in montreal in particular reinforcement learning was something pretty much absent just two or three years ago so theres really a big interest from students and theres a big interest from people like me so i would say this is something where were going to see more progress even though it hasnt yet provided much in terms of actual industrial fallout like even though theres alphago theres no like google is not making money on this right now but i think over the long term this is really really important for many reasons so in other words i would say reinforcement learning may be more generally agent learning because it doesnt have to be with rewards it could be in all kinds of ways that an agent is learning about its environment now reinforcement learning youre excited about do you think gans could provide something at the moment well gans or other generative models i believe will be crucial ingredients in building agents that can understand the world a lot of the successes in reinforcement learning in the past has been with policy gradient where you just learn a policy you dont actually learn a model of the world but there are lots of issues with that and we dont know how to do model based rl right now but i think this is where we have to go in order to build models that can generalize faster and better like to new distributions that capture to some extent at least the underlying causal mechanisms in the world last question what made you fall in love with artificial intelligence if you look back what was the first moment in your life when you were fascinated by either the human mind or the artificial mind you know when i was an adolescent i was reading a lot and then i started reading science fiction there you go thats it thats where i got hooked and then you know i had one of the first personal computers and i got hooked in programming and so it just you know start with fiction and then make it a reality thats right yoshua thank you so much for talking to me my pleasure']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_nopunct'] = corpus_nopunct\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDPnfYI4zFnl",
        "outputId": "f76db1bb-a187-4981-bc90-8dc63176d1d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \\\n",
            "0  As part of MIT course 6S099, Artificial Genera...   \n",
            "1  As part of MIT course 6S099 on artificial gene...   \n",
            "2  You've studied the human mind, cognition, lang...   \n",
            "3  What difference between biological neural netw...   \n",
            "4  The following is a conversation with Vladimir ...   \n",
            "\n",
            "                                        text_nopunct  \n",
            "0  as part of mit course 6s099 artificial general...  \n",
            "1  as part of mit course 6s099 on artificial gene...  \n",
            "2  youve studied the human mind cognition languag...  \n",
            "3  what difference between biological neural netw...  \n",
            "4  the following is a conversation with vladimir ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete stop words"
      ],
      "metadata": {
        "id": "6rfyaHrjzYdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords') #Descargar stopwords\n",
        "stopw = set(stopwords.words('english')) #Cargar stopwords en ingles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIuYm1tlzc1d",
        "outputId": "5ce48820-c51c-4591-a0d2-836c5d2f05c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XtYC2BizvGG",
        "outputId": "4a337de4-ba41-44f8-f14c-a1a02c75e295"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nostopw=[]\n",
        "for doc in corpus_nopunct:\n",
        "    clean_doc = []\n",
        "    doc_array = doc.split(' ')\n",
        "    for word in doc_array:\n",
        "        if word not in stopw:\n",
        "           clean_doc.append(word)\n",
        "    corpus_nostopw.append(' '.join(clean_doc))"
      ],
      "metadata": {
        "id": "s1lHYf0iz5dI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus_nostopw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_X6RleC0MEk",
        "outputId": "0b2e159e-f809-4376-a419-32818cb46eca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "319"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nostopw[300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "MUm3S2XW0XYH",
        "outputId": "663e12ce-2d88-4790-ae51-0e140de69d53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'following conversation brian armstrong cofounder ceo coinbase largest cryptocurrency exchange platform 98 million users 100 countries listing bitcoin ethereum cardano 100 popular cryptocurrencies recorded conversation brian weeks sec probe whether crypto listings securities thus need regulated always conversations involve cryptocurrency try make timeless price soaring high crashing low doesnt distract fundamental technological economic social philosophical ideas underlying new form money energy information world runs money exchange store value cryptocurrency seeks build next chapter money works coinbase brian trying working together regulators governments long difficult road bureaucracies resist change better worse latest sec probe good representation serious attempt limit fraud one also runs risk limiting innovation limiting financial freedom individuals complicated mess applaud everyone involved trying work hope end interest individual wins decentralization hedge corrupting nature centralized power lex friedman podcast support please check sponsors description dear friends heres brian armstrong lets start fact youre programmer first program youve ever written first one remember first memory programming probably middle school remember recess time period could read books kids reading comic books stuff reason gotten idea wanted get computers playing computers home got book think library called learn java 30 days reading book recess didnt understand anything remember went home tried get thing working youve ever written java program first lines public static void main string args whatever foreign difficult get started kind frustrated like dont understand anything thats happening book first thing wrote probably hello world app java felt like confused actually happening later learned bit php php like fun like oh print want didnt complexity around got php started building like simple websites think learned html think introduction programming least beginning part yeah know java lot hello worlds could possibly write java one think longest yeah quite interesting java often least long time used primary programming language teach people program least object oriented programming think universities switched high school switched python im sure thats case probably better easier learn lowers makes less scary like less hurdle certainly none use php love php feel like dirty secret keep private like somebody im seeing side something like respected programming language think theres many ways write poor code php respected yeah scripting language although course facebook built like huge stack top invaluable company still love ruby day ruby probably favorite language pythons great love idea behind ruby like lets make easier human harder computer make joy expressive things never best computer scientist good hacker could rapidly prototype products using languages like ruby lot computer science programs still use like lisp scheme things like thats like thats youre hardcore youre legit youre gonna functional languages think theres others popped lisp distant memory lot people thats like somebody like go library dust book scheme little bit think youre starting mean theres courses languages like programming languages lisp might one know theres languages nobody uses anymore like ancient languages might go school way programming languages back day used use parentheses course still use emacs editor things emacs lot customization lisp thats language probably first really fell love programming lisp long time throughout earlier history artificial intelligence lisp primary language still life 90s aughts people would use beautiful functional language somehow didnt pick said say sort push back php feel like still true web runs php backend still php look know like stuff people dont talk like runs systems world runs backend runs front end javascript know html stack exchange surveys show javascript popular language world think right oh yeah terms programmers numbers wonder survey number programmers stack overflow oh yeah thats also cutting edge right people like excitedly writing code wonder theres people like maintaining gigantic code bases yeah feel like amount java running industrial systems gotta enormous course banking industry finance like even older stuff cobalt whatnot ive actually looking somebody interview represents cobalt fortran like whos figure still holds flag know java founder java creator java creator python creator c nobody wants hold flag cobalt fortran even though important systems world still run like power systems infrastructure systems fascinating atms stuff like like lot stuff rely works reason dont change works well written languages people dont use anymore yeah thatd cool series interviews get stuff thats like tech invented 40 50 years ago still used widely mean emacs example let ask big question cryptocurrency exchanges whats coinbase work ill ask even bigger questions nice kind palate cleansing question coinbase coinbase cryptocurrency exchange brokerage custodian basically primary financial account people crypto economy buy crypto store use increasingly different ways talk yeah want way billion people hopefully access open financial system globally work whats cryptocurrency theres bitcoin theres ethereum mean exchange mean store mean transact coinbase actually okay basically given market theres people want buy people want sell keep order book prices someones willing buy lowest price someones willing sell get trade execute thats kind exchange works underneath brokerage kind simpler even dont know look whole order book everything go say want buy hundred dollars bitcoin whatever cryptocurrency get quote like hit accept core things make kind work make seamless sounds simple surface payment integrations variety places around world make easy people get fiat currency ecosystem work cybersecurity lot theres lots hackers trying break systems steal crypto put stolen credit cards bank accounts things like systems integrate blockchains periodically getting updated various airdrops kinds things integrated lots different blockchains store crypto people buy securely well crypto kind like storing store private keys essentially weve invented lot cool technology securely helps sleep night one largest crypto custodians pieces come together get early simple buy sell experience work yeah mean coinbase actually lot different products like institutional product coinbase commerce like merchant payments like stripe crypto weve got self custodial wallet talk theres kinds cool applications people building web3 access launched nft product go list sort like portfolio crypto products big enough multiple things yeah core thing got started still majority revenue today people wanna come buy sell crypto help make simple easy use ill ask wallet nft called stripe type coinbase commerce coinbase commerce ill ask order books exchange whats difference stocks example theres also order books yes mean stocks trade order books commodities theres similar type situation wanna buy one bitcoin see coinbase say price bitcoin say 40000 press buy happens yeah okay youve gotten lot press button keyboard like electrical signal goes wire keyboard wont cut level thats also important timing right cause price fixed yeah thats true giving quote right theres whole concept like slippage like time quote executed price moved much like may reject theres various things like mean whats simple version give well basically check order book give quote good period time amount slippage whats happening initiating debit payment method whether thats credit card bank account youre storing dollars euros something platform theres various payment methods basically debiting crediting crypto taking fee thats fundamentally whats happening underneath theres interesting slippage calculate much slippage allowed like know things cause order books fascinating dynamics pretty interesting little know yeah theres lot people like traders get super like high frequency traders arbitrage kinds interesting topics flash boys like interesting book whole thing want like access information fastest sometimes even putting thing data center right next thing dont allow colo stuff cause want democratized basically give lets say wanted keep math simple want charge 1 fee youre buying 100 bitcoin well charge 101 weve presented amount bitcoin youre going get 100 lets say 10 seconds later hit accept go fill order going error bound around 1 fee right think actually losing money trade think well often reject part fee slippage incorporated averaged large number people fascinating cause like even like little detail probably requires lot experimentation yeah kind like giant bug bounty get wrong theres people going arbitrage weve people sort pen test systems really creative ways like theyll fire like programmatically apis theyll fire like million different quotes look one thats bounds actually take money right get people kinds crazy stuff protect protect well talk cybersecurity interesting ways theres lot clever people trying clever things earn even break system earn edge kind system stay one step ahead theres silver bullet bunch lead bullets right like know one thing good test suites right youre testing every piece code goes thats like common good best practice particularly important financial services another thing hire third party firms try audit stuff break another one bug bounty program basically pay white hat hackers find stuff black hats weve paid lots good bug bounties know try occasionally dont get right lose money fix keep going yeah lets talk cybersecurity little bit mentioned using stolen bank accounts thats another one thats another interesting one protect okay fraud prevention yeah big topic one theres lot things people one things use machine learning right look hundreds protect attack protect want kind build labeled data set different people turned fraudulent good actors hopefully collect much data know might feed hundreds thousands factors machine learning model itll come back risk score know example like kinds factors people create put know obviously dont want disclose many cat mouse game kind dont know relatively well known stuff might know device fingerprints right like kind device fonts installed lot people farming lots accounts theyre using emulators like virtual machines stuff theyre like know average person device youll see sometimes like one favorite metrics track called like improbable travel velocity would tracking peoples ips right might see someone one day austin texas like hour later london something like well thats improbable mean sometimes people using vpns gotta careful like theres legitimate people use vpns possible gotten plane gotten quickly thats usually theyre like spoofing device ip sometimes interesting factors yeah feed enough oh another fun one like know real users type credit card like one number time scammers list theyll paste whole number look like number milliseconds keystrokes like theres kinds stuff people come even travel velocity could probably incorporate vpns theres probably travel velocity vpn switching thats human like like youre using legitimately vpn something else might theres like legitimate uses actually know feel embarrassed dont know probably im robot capture thing capture thing yeah probably works way like move mouse maybe dynamics clicking totally even work well cant fake need look cause trivial capture feels like crackable yet lot high security places use yeah really interesting another cat mouse game think theyve yeah using lot similar signals like mouse movements keystrokes obviously stuff comes wire browser like operating system fonts headers sent theres actually theres old website cant remember called kind like panoptik click panopticon something basically like proof concept site would show data kind getting sent request like say theres one person world exact set data almost like workaround clever workaround track somebody make identify unique person even like wasnt cookie involved something yeah fascinating world cant see anybody dark yet lot signal figure whos real person whos whos robot whos let step back gonna jump around place let step back thats like interviews get like technical topics lets use bitcoin measure time started coinbase bitcoin 10 mentioned incredible system security transactions everything thought theres lot going version one back early days first prototype coinbase look like like take write think make work enough least make believe gonna work well definitely didnt know gonna work mean kind felt like following gut mean working airbnb software engineer project manager working fraud prevention stuff instance read bitcoin white paper kind december 2010 started going bitcoin meetups bay area bitcoin kind like new reserve currency also stable coins right new inventions yeah basically feel like crypto secret hiding plain sight create economic freedom people world fair free global economy well limit way didnt know argentina whyd end argentina okay basically living houston texas college went school never studied abroad kind like dont know felt like needed adventure something life like running startup trying time tutoring company could work anywhere plan know im gonna go like month every city around south america like almost like force comfort zone never traveled foreign country whatever didnt really speak language anyway landed buenos aires thinking id go around south america never basically set buenos aires apartment cell phone stuff like dont wanna next month stayed time took day trips yeah kind formative experience regard got chance sort unexpectedly experience social effects hyperinflation interesting also ive never really really wanna go person likes tangos person likes argentinian national team soccer steak right things argentina known okay economic freedom one limits economic freedom comes government government regulations kinds things throughout world cryptocurrency help resist sort elaborate little bit things limit economic freedom crypto help ease today world like traditional financial system basically every country world part currency theres group people institutions countries thats controlling economic policy money supply manipulated right like many currencies linked gold standard us kind famously came 1970s instance read ray dalio stuff like talks theres thousands fiat currencies existence time basically eventually get disconnected backing like hard commodities get overinflated printed times stress nixon guess like us vietnam war something like kind drove government spending times stress say hey temporary measure need break peg temporary like famous words used go print bad thing course sort erodes peoples like wealth hold assets cash basically like poor people tend youre wealthy hold stocks like real estate things like really tax poorest people society inflation anyway crypto way little bit like return gold standard digital era right bitcoin theres guaranteed scarcity deflationary theres never gonna 21 million bitcoin thats really important principle also think bitcoin like cryptocurrency generally really important terms asked regulation right think like wanted make global borrowing lending marketplace global exchange would go 200 countries world sometimes like maybe 50 states us get lending licenses operating exchange whatever thats incredible amount work cant even business many countries like bribe somebody corrupt whatever defi decentralized finance people published like uniswap decentralized exchange everybody world matter country youre jurisdiction interface decentralized exchange theres central company operating smart contract ethereum blockchain globally decentralized theres throat choke theres one person company go like hey shut thing even everybody whos working uniswap today stopped uniswap smart contract would continue operate ethereum blockchain similarly like borrowing lending marketplace like somebody india wants borrow somebody us whatever theres difficult traditional financial world smart contract thats decentralized enable anybody access really kind great democratizing force creating new financial system fair free yeah ways clever way thats enabling people novel way uniswap sense competitive coinbase way way people dont know coinbase centralized let ask doesnt go spirit crypto since crypto decentralized pros cons centralized exchange dont think coinbase fully centralized many different products way think exchange brokerage centralized regulated financial service business actually important crypto ecosystem wanna allow lot fiat money world flow crypto economy proud think weve helped lot money flow people money crypto choose hold variety ways choose hold self custodial wallet decentralized choose use decentralized exchanges love uniswap really dont think like direct competitor us basically integrated uniswap number products love defi decentralized exchanges whole thing coinbase wallet self custodial wallet decentralized allows people hold crypto dont trust us explain self custodial wallet wallet self custodial wallet yeah confusing custodial wallet means youre trusting coinbase store crypto private keys people institutions everything meeting today thats nice simpler theyre afraid losing crypto make accidental mistake custodial crypto products important help get bunch people ecosystem im supportive self custodial wallets think ways future people gonna want store crypto trust third party institution ways much authentic ethos crypto coinbase help convert fiat crypto frankly thats centralized thing crypto go self custodial world store get technical details second basically saying youre gonna store keys device even coinbase gets court order seize actually cant architecture point view cant coinbase gets hacked something cant lose funds thing take responsibility taking individual person could get hacked theres whole bunch really cool research happening make self custodial wallets resilient accidental loss hacks user error dont know much youve looked various cryptography things basically multiple signatures different keys different devices need two three three five theres whole technology called multi party computation threshold signing signatures really cool things would run locally security measures cryptography measures protect without centralized component right simple example would lets say two three key signature one key might stored coinbase thats quorum couldnt unilaterally move funds another key device phone lets say oh cool normal situation key phone one two three get signed quickly day day use lets say lose phone something third key thats could store backup somewhere like google drive icloud could trust third party thats coinbase also one key cant anything unilaterally one key thats simple example get way complicated yeah thats awesome idea funds get seized coinbase cant anything better lose phone maybe case yeah yeah provides even lose phone recovery mechanism get one key coinbase one backup provider recover new one back phone know yeah coinbase longer government say north korea government says youre longer like coinbase shut country something like get even access two perhaps silly question isnt self custodial wallet competitor notion coinbase mean offer self custodial wallet weve built one like one doesnt bleed like guess im asking sort financial question like coinbase make money transactions decrease number significantly negatively affect transactions focused growing number pie number people using cryptocurrency yeah like traditional financial service firm would probably say well storing lets keep custody us thats prove world valuable whatever dont really believe like think actually kind want encourage users move self custody time ready willing technology needs mature im trying like force anybody doesnt want thats like future get billions people using crypto doesnt mean go somewhere else easier yeah thats sort point like using protocol theres low switching costs keeps companies accountable right like want access visa network theres one company world go like visa want access bitcoin network theres dozens hundreds companies arguably could argue worse us company think better makes bitcoin interesting cryptocurrency interesting nobody controls low switching costs customers better customers means companies space going held high standard minute lose someones trust theyre going move bitcoin service thats good world think coinbase theres ideas layer one layer two layer three technologies think coinbase layer one layer two layer three said theres many products coinbase umbrella hard answer question think acknowledge existence layer three know usually people using terms layer one layer two theyre referring like layer one would blockchain layer one blockchain like bitcoin ethereum something like centralized service like coinbase even decentralized self custodial wallet yeah wouldnt consider us like layer one decentralized protocols integrating coinbase yes layer two thing basically transactions without settlement blockchain get benefits faster transactions without security associated blockchain layer three suppose sort apps built top know least think talking michael saylor considers coinbase layer three technology interesting okay im really particularly familiar kind distinction layer three two dont see fundamentally different okay mean one way asking layer two like magic happening order make transactions associated blockchain happen instant theyre quick coinbase coinbase yeah magic going youre okay say many cryptocurrencies currently coinbase two yeah lot two yeah understand incorporate technologies yeah make magic sort universal transactions happen across different cryptocurrencies theres centralized products decentralized products right centralized products storing crypto youre moving one accounts another account like eth1 account eth2 account eth coinbase centralized account eth centralized transaction chain make faster saves customer fees confirms instantly truly using decentralized blockchain right also send bitcoin address ethereum address instance putting transaction chain decentralized products like coinbase wallet self custodial wallet every transaction happening chain basically shows little bit evolution coinbase blockchains like early days networks scalable l2 solutions instance sort hacks like moving crypto chain moving accounts stuff like otherwise minor fees would eaten us alive company right yeah blockchains starting scale theres whole bunch work needs done getting l2 solutions think transactions going chain whether l2 l1 ideally shouldnt many transactions chain internal coinbase ledger something thats really spirit crypto say chain includes layer two technology blockchain proposes yeah guess asking much fun magic happening chain within coinbase youre saying early days youre trying less less look theres bunch high frequency traders use centralized products even regular retail people dont want pay gas fees stuff theyre trying actually back envelope calculated one point like would completely infeasible like high frequency traders put everything chain point thats basically dexs important think going move decentralized time great basically dexs decentralized exchanges way yeah anyway want encourage move decentralized time dont centralized things arent going away like long time decade theres going big institution pension fund central bank thats like right got hold crypto lets set account centralized way thats thats fine important know number cryptocurrencies currently coinbase know number hundred depends depends jurisdiction youre know institution versus retail theres like theres many different categories hundred yeah take become become asset become cryptocurrency coinbase add technology coinbase okay well trying get away idea listed coinbase seen like endorsement something actually think important considered judge jury know like imagine early days internet like whats good webpage whats bad webpage like would totally wrong anytime big tech companies try make review review boards like know apple famously gets trouble lot app store review process right something think like committee people somewhere thinks looks silly may turn next big thing right difficult basically test legality right check know believe security cant listed coinbase theres rigorous process go currently way laws us cant weve acquired broker duo license sec trying work get operational hopefully someday trade real crypto securities today thats possible us least look sort cybersecurity crypto asset see theres flaw smart contract know way somebody could manipulate without customers permission look compliance pieces well like actors behind like know kind criminal history anything like believe meets listing standards basically test legality everything customer protection want list want market point decide kind like amazon something like know product might three stars might five stars starts get one star consistently like probably fraudulent defective something like maybe amazon remove otherwise want let market decide things thats generally way assets think especially like low market cap assets going traded dexs coinbase dont need list every asset centralized exchange think dexs really good long tail becomes even even clear people like endorsement coinbase like assets good ones bad like know belief theres going millions assets time hope doesnt like make news every time add one future basically yeah wonder get even look coinbase example know people imagine sort tag twitter something like like interview sort founder particular coin right yeah hard know whats first whats interesting technology whats whos scammer whos actually legitimately representing ambitious new thing versus scam know theres sources like verification signal unfortunately coinbase part become little bit youre trying get away youre trying get many sort let people decide youre thinking like amazon star type system people could rate yeah think well actually probably add like user ratings reviews well cautious like know real people theres bunch stuff already think wisdom crowds good terms getting feedback items also gonna review mentioned earlier right like okay meets minimum bar listed site yeah think yeah important know coin scam well see things know hate use word scam lot judgment calls gotta kind court may jury may land either way things would red flags look would know bunch asset owned insider insiders short vesting periods know background founders like may criminal records theyve perpetrated frauds past right theres difference something product like doesnt anything interesting something thats actual fraud outright scam lot data whats cool available chain look like tokenomics behind see owns selling know like inappropriately pumping like youtube twitter making promises hey value thing may higher future like big big nos would know dont wanna go whole thing like want enable innovation space allow anybody curtail advancement industry like kind fraudulent thing get rich quick thing tricky industry im trying figure know whats interesting understand research hard know let ask tricky one add centralized exchange privacy preserving cryptocurrency like monero yeah technically difficult like monero example forget specific one like privacy preserving cryptocurrency blockchains ever possible add thats great question answer maybe heres reason regulated financial service business various licenses regulated various regulators part licenses requires us quote reasonable program monitor suspicious activity know aml program anti money laundering right coin hundred percent anonymous cant really blockchain analytics track source funds things might going makes harder reasonable program around thats defensible privacy preserving coins like zcash something called view key view key basically another key allows deanonymize transactions specific situations want instance know support zcash one ways got comfortable youre buying coinbase know basically view key transactions anonymous youre buying see goes afterwards whole standard program gets hops away road mean people could eventually turn privacy preserving aspects know tough judgment calls least terms interaction customer everything feel comfortable think theres broader point actually think privacy coins good thing world allowed like know despite weve made judgment call operate regulated safe compliant way taking coinbase hat minute think world would better place privacy coins kind like internet first came online like https everything http know people afraid put credit cards internet messages could intercepted stuff whole internet basically moved https little lock icon browser better like financial information like important information keep private right theres times like lets say youre running charity something want total auditability transparency whole world donated money go thats great want public like personal money something like dont want broadcasting whole world ways thats blockchains know pseudonymously like public ledger know owns address basically deanonymize know think basically people fight privacy freedoms kinds privacy money good thing would like see future chosen coinbase seat table regulators kind conversations table regulations like level understanding regulators worried thinking positive negative regulations youre facing youre educating struggling pushing back supporting kind stuff yeah oh man theres many cause mean live like know maybe hundred countries point conversations map im trying think broad strokes could paint id say one trend thats positive basically regulators around world last five years would say common find regulator today asking preserve innovation potential technology keeping bad actors five years ago saying bad activity prevent maybe say fraction ill give like us specific example although operate many countries go dc would say know 50 60 people meet basically know theyre camp crypto lot potential regulate make sure bad people dont something bad stay lot upside basically create awful regulation celebrate actually encourage innovation happen us thats huge change three years ago probably 30 people saying like 60 like almost double getting harder find like true crypto skeptics dc id say know maybe like 20 30 people like willing say something negative like actually think net negative like really hard defend position point almost like one five americans used tried crypto point youre kind condemning 20 fellow citizens say point know especially nfts things like huge segment people dont even care investing whatever came space basically thats conversation happening know delayed years like india europe asian countries countries really embraced crypto theyre like trying really theyre ahead us theyre trying actually attract best startups entrepreneurs like know like dubai uk australia kind pushing good regulation el salvador actually guess adopted like bitcoin legal tender another country central african republic think supposedly well know theres countries like china autocratic saying hey threat power like gonna try really curtail kind regulations feel limiting empowering like specific examples yeah okay mean basically think securities laws us need clarified crypto many different things thats people dont realize like crypto like bitcoin ethereum many others probably like commodities theyre controlled one person know like anyway theres people wanna raise money company thats sounds like security regulated sec commodities regulated cftc theres cryptocurrencies like currencies like stable coins central bank digital currencies probably know regulated treasury someone like theres whole another category cryptocurrencies none things theyre nfts like artwork theyre metaverse items decentralized identity voting think theres unhelpful point view folks hey like bad activity need shut gonna pursue enforcement actions something like people dc dont feel way anymore think people us dont feel way anymore lot using stuff general view theres lot upside potential agree lets get rid fraud scams wanna get rid lets create relatively simple test says like nobody controls 20 threshold probably like commodity someones raising money theyre selling thing business probably security like medium exchange currency none things maybe artwork whatever legal test like would help clarify regulator regulating also wanna probably like sandbox innovation youre startup youre less dont know number less amount payment volume customer funds youre storing like let things get ground without soul crushing amount legal bills uncertainty us get would great think bunch countries rushing around world sort create regulation attract innovation international bodies like imf g20 stuff theyre starting look proposed regulation hope coinbase bunch crypto companies help conversation whole policy effort think actually crypto policy efforts like probably one biggest things dc right moves slow speed government yeah meantime trying help people use crypto ultimately thats democracies thats care like theyll people country want want governments start understanding differences crypto space commodities securities currencies nfts still dont understand supposed make sense nfts nfts exactly perspective regulator yeah categories yeah nfts could think like artwork although knows gonna go could mentioned metaverse right mentioned kind unique identity thing yeah like theres people selling virtual land nfts actually bought nft thats like like citizenship like city dow wyoming like ive never almost like badge attestation like get access location theres like people like tickets events like know theyre called poaps like proof attendance things like itll interesting see nfts go time could get thats danger dont wanna try like define regulation dont even know things gonna go efforts policy arm education yeah education advocacy trying like helpful educational resource essentially give us feedback theyre like hey dont dont like happy anything thats requested generally go get licenses weve tried right thing absence clarity clear law says basically good things think may required future show good faith effort towards right thing thats part like innovating regulated field know whole topic table let less case united states government agencies seize persons cryptocurrency forcing coinbase hand youre centralized phone number call okay complicated topic like really wanna sure people wanna store crypto right like self custodial wallets like coinbase wallet embracing decentralization wanna avoid us rule law right reasonable protections place around like search seizure things like know coinbase publish transparency reports get subpoenas court orders things like various countries around world situations ordered freeze accounts things like know follow law another way put regulated financial service business money used part breaking law thats particular jurisdiction particular right thing sometimes actually get court orders subpoenas overly broad weve seen need follow due process right weve seen past like well need freeze huge number accounts like well well actually gone court like pushed back said like probable cause threshold met like weve cases behalf customers yeah actually really kind unfortunate frustrating large business spend lot resources basically interacting inbound requests kinds lawyers people requesting things silly ridiculous push back say kind tax every company certain size ultimately gets passed customer higher fees employ armies lawyers deal stuff educate something much innovation legal space lawyers working coinbase new cutting edge thing youre theres lot gray area youre supposed operating like hard lawyer coinbase like much precedence guess im asking mean like said three years kind new space yeah well probably hard lawyer coinbase fun whenever youre new field thats growing fast isnt lot case law precedent set thats also opportunity go create stuff thats lot legal careers made like take complex situation balance difficult things like prevent bad activity still enable innovation thats hard question theres go draft legislation circulate policymakers come policies operate business environment law unclear right like try right thing like strike right balance yeah lot lawyers come creative stuff mentioned one things youre focused expanding number people maybe billion people coinbase using cryptocurrency get billion q4 last year 89 million verified accounts coinbase given quarter maybe like 10 little million like really active look globally think estimates ive seen maybe theres like 200 million people something like ever used tried crypto long know ways billion like far get get billion things one blockchains got become way scalable kind like running dial modems need broadband like expensive slow transactions think get l2s working scalability know well see another order magnitude kind come think second one would clear regulation would help lot talk know pension funds know various asset managers sovereign wealth funds stuff lot tell weve got 1 portfolio crypto today really would rather like 20 waiting clear regulation coming saying clear test saying assets commodities regulated scpc scc treasury whatever would big unlock transactions one things mentioned payments sorry yeah well unlock lot users yeah mean remittance like huge thing people sending money home families countries fees super high yeah get blockchains scalable theres global adoption like think well see remittance quarters move crypto lot theres also thing thats driving lot crypto adoption basically creation third party apps dapps theyre sometimes called decentralized dapps lot startups know like used use early 2000s called themcom startups dont need saycom cause everybodys using internet theres like hundreds thousands crypto startups think future wont need call crypto startups cause theyll called startups cause everyones using internet crypto whatever anyway use cases utility crypto getting better better like third party apps getting funded created think theres going killer set killer dapps like thing nobody live without still waiting theres going bunch like like internet like killer web companies know like uber wikipedia airbnb google like theres going big winners therell thousands basically new like happened thecom startups early 2000s like lot best entrepreneurs building crypto startups tons venture money flowing space lot smart young people think bitcoin cryptocurrency become reserve currency world point cause kind controversial idea actually think yes think bitcoin could end becoming reserve currency world ive reading ray dalio recently new book like changing world order thought really well researched book talks looks back history right looks like empires going back various chinese empires dutch ottomans everybody rise able reserve currency rose produced like came good education innovation better trade anyway us measures kind looks like maybe really good run coming little bit china kind coming knows thatll play way like world complicated could could switch guess us dollar gonna seeing inflation future chinese yuan like necessarily better right mean ton debt well like could really yuan could inflated well right probably think theres group people today probably traditional dont know like people run big banks like governments stuff theyre really radar today think theres basically group younger people kind 25 35 year old range tech savvy theyre starting think crypto like primary thing financial life like basically hold wealth crypto use dollars euros whatever happen need something convert last minute like im traveling might convert local currency moment thats hold wealth segment population like massive yet gdp point view think leading indicator things could going actually good world kind like especially china continue rise authoritarian view itll kind centralized east versus decentralized west people west free world really kind embracing crypto open fair free global financial system think enormously beneficial humanity think basically bitcoin reserve currency gold standard crypto economy thats pretty crazy yeah gold standard mean also like ray dalio feel like china drive lot either response directly mean think ruble im paying close attention financial systems think theyre trying tie gold thats interesting maybe itll one authoritarian regime switch bitcoin standard first west pressure catch versus way around fascinating think forcing function kind perturbation required switch change anything honestly financial system could youre saying waiting people young embracing crypto enter positions power essentially hope thats case innovation wait sorry say older folk pass away thats efficient way make change yeah thats super interesting topic peoples minds become less plastic age guess feature called wisdom also need wild ones explore exploration versus exploitation wrote blog post thats really interesting september 2020 titled coinbase mission focused company like talking one interesting thing said blog post going distracted activism within company thats related mission company thats rare thing company state company ceo state especially climate first describe little detail meant receive blowback definitely received blowback yeah ill describe meant want talk came talk meant theres lot companies right including tech companies exclusively think like great companies important mission theyre trying something really good world unfortunately theyre getting little distracted times employee activism causing company basically jump whatever current thing try help like positive interpretation negative interpretation would virtue signal view actually kind destructive largely american company phenomenon way worry making america less competitive even though think kind internationally minded us citizen whole life put statement employees us confused like brian need say saying youre going focus work work thats already certain pockets us certain cities particular employees peculiar cultural phenomenon evolved think people really wanted company worked almost acting like government something like trying solve hardest societal issues least opinion contribute solution almost everything uncomfortable situation ceo id never quite situation time employees past kind asking questions would asking like make product better like competitor regulator got place around time questions receiving think even things related company broader societal issues like brian whats stance xyz controversial thing often like didnt opinion really hard questions right didnt really felt like distracting company people internally getting fights lot like disagreeing thing like social slack internally turning social media almost people putting flame wars culminated way walkout happened company received like demands employee groups various things like basically antagonistic thing management employee like team wanna antagonistic lets somebody else outside company trying improve world dimension yeah eventually like okay company aligned dont feel dont like job ceo frankly like job come every day like squirm front like difficult societal questions dont think wanna job like either theyre gonna go im gonna go founded company really believe mission theyre gonna go realized basically made exit package available anybody wasnt board direction 5 employees took got company realigned towards mission work way people go anything like political social activism outside work totally fine like everybody stuff like personal life work also disagree work way work know like disagreement culture like lets try get truth dont bring stuff work thats gonna create division make workplace refuge division crazy things like aligned work mission lets yeah really really really refreshing hear speaking theres sense companies take issues publicly ceo position anywhere else seem optimize virtue signaling versus solving particular problem solve particular problem really really put huge hire huge number basically create company company take particular thing allow internally care particular issue youre basically pacifying number employee like making sure slack doesnt get hand youre kind perspective especially issues care fake virtue signaling basically trying understand make look best would make company look best particular aspect seems shallow optimizing wrong thing solving problems making look like good guy trying leverage say im good guy situations wrong thing perhaps perspective ceo leader also creating division unnecessary division within people like get yeah theres something us gets extremely argumentative certain topics really bring emotion think probably saying emotion even probably okay maybe productive emotion mission company like really care disagreements versus like something nothing increasing economic freedom using crypto yeah fascinating refreshing rare think thats rare city youre mentioning mean theres bunch cities san francisco one city culture sad san francisco also bay area also hub historically greatest innovation human history theres tension culture emerge like innovation done people mission driven get bunch smart people together solve difficult problem get maybe sometimes much blinders try balance requires focus solve actual problem yet thats also place culture emerged fascinating human dynamic dont know somebody one day tell history silicon valley innovation social dynamics occurred anyway think thats rare well people dont wanna get attacked like super dont wanna get canceled right super uncomfortable nobody wants called racist whatever people wanna say twitter get attacked yeah yeah definitely got attacked mean knew would controversial reason frankly kind wits end like well like said earlier like job ceo job sucks like either dont wanna go im gonna make company something want id spent eight 90 years life point kind building thing like well could go start another company takes long time get momentum things coinbase rare thing happened world feel passionate yeah im gonna go like need make company wanna work really interesting huge outpouring support knew would controversial would get attacked predictably journalists new york times people kind like went started writing hit pieces company shortly thereafter basically call people whove left company get quotes whatever want theyll write story mainstream media lost lot trust mainstream media frankly course kind become obvious since mainstream media like hyper politicized point basically either super left super right really focused truth thats kind unfortunate think journalism actually like really important society whole thing got eroded us luckily theres sort new media people like whole bunch people blog post help statement 95 people remained still something struggle also culture broader tech space okay interesting thing 95 people stayed got huge outpouring support people said thank god finally spoke said something frankly making fun place work either realized think think nassim taleb blog post tyranny 1 something like theres basically relatively small group one 5 something like really upset something majority company like 5 theres another 15 something sympathetic cause theyre actually somewhat suggestible go along whatever sounds reasonable like real issues theyre talking say real theyll kind get swept theres 80 company basically doesnt agree wants get work done without drama distraction theyre afraid speak speak theyre afraid called racist like fired ostracized amongst peers require get bad enough place finally say know feel like live short term attacks press ultimately freeing dont really care actually build company want build without caring cool lot really great people reached coinbase like im early engineer google wherever culture gotten kind messed want work company thats willing stand weve gotten lot good people come basically realized way diversity numbers stuff people told drafting poster dont post people underrepresented groups never want work company like dont think thats true talked erg groups theyre telling care stuff much theyre telling want respected work good work contribute gut telling advice wrong tell year diversity numbers basically either better every category turned false look hate polarizing either dimension want get good work done build good stuff technology think companies reasonable policies want get rid bias hiring want attract great people different backgrounds pledge 1 put 1 company equity foundation hope able good stuff lets give back way main message guess core mission core work economic freedom products main value contributing world lets hopefully get 89 million verified users billion whatever think thats well biggest impact tempting though interesting companies get tempted help step almost like drug cant forget mean like us life companies get distracted maintaining focus youre absolutely right way coinbase add value world maximize mission stuff get wealthier successful becomes tempting help shallow ways fascinating kind brought light refreshing shouldnt controversial sort focus getting stuff done well let ask mean think things tie together theres like general trend like censorship theres like cancel culture theres like freedom values kind even like freezing peoples accounts like trucker thing happened seems like theres general trend authoritarian policies feel like tide turning like theres counter examples weve seen recently think last gasp old way things theres desperation fair kind internet wheres source lot people voice making power centers world really nervous thats thats coming think internet tricky weird full bots full like misinformation kinds full large groups conspiracy theories mean misinformation broadly people misusing word misinformation theyre governments labeling random things misinformation censor think like new world met lots interesting people like crazy people anarchists really brilliant people started nights weekends trying put together prototype initial thought well smtp protocol runs email git protocol version control people made like gmail github people dont wanna run email server even git server wanna like use hosted thing security backups thought head time bitcoins new protocol theres probably gonna somebody makes hosted service security backups makes bitcoin protocol easy use maybe make like hosted bitcoin wallet something gonna make gmail bitcoin something bunch people told bad idea like smart friends told like well first dont really get youre like bitcoin sounds like scam something youve gotten involved people understood bitcoin told thought dumb idea theyre like dude store bitcoin youre gonna get hacked like nobody know would kind thought like know im gonna go like make store everyones bitcoin would much right job day job know let make prototype ill tell people like beta thing like dont put real money see theres interest feel like im onto something maybe ill go company cause really wanted entrepreneur time like 29 almost turning 30 always wanted like start company know wasnt yet employee company great anyway prototype hacking together nights weekends actually wrote whole bitcoin node ruby turned maybe weird decision hindsight cause ruby wasnt performant language weve subsequently rebuild many times yeah hosted bitcoin wallet thing didnt users way applied combinator cause like maybe somebody writes check like make feel like real company trying find co founder time unsuccessfully basically wandering desert lot self doubt cause like dont know friends dont think kind dumb maybe bitcoin gonna get shut like stupid thing definitely feeling wandering lost desert lots self doubt paul graham combinator group kind wrote first check went interviewed stuff wrote check like 150k first time somebody really looked kind said worth pursuing like maybe youre onto something maybe youre like lets least try kind gave confidence quit job try ill wrap story saying like found right co founder combinator still didnt customers thing basically launched hosted bitcoin wallet people signing posted reddit places like maybe like hundred people would sign nobody would come back like combinator often tell like talk customers improve product talk customers improve product thats youre supposed try find product market fit emailed like five users signed like hey worked app saw signed get phone get phone like five folks like didnt come back guy like well app okay beta like dont bitcoins didnt really know remember light bulb kind went head like well put buy bitcoin button would used like yeah maybe went process co founder time like got basically get like bank partnership payment rails know exchange basic exchange functionality stuff mentioning earlier place minute launched feature could click buy put bank counter credit card buy bitcoin showed account day forward like number users started go like finally found product market fit two years wandering desert werent even thinking buy ramps would think would wallet place store bitcoin youve already gotten yeah okay mean cause thats pain work others convert dollars fiat currency bitcoin yeah mean overwhelmed immensity task sort allowing think deeply whole thing letting optimism take know really looking forward like something crazy like big challenge wanted love kind crisis moments like know im determined right especially get like set something im like know im gonna figure way make fucking thing work like matter reveled sort read books startups like every startup like know major setbacks like nothing works sign youre something right idea anything right like kind loving experience weird way felt felt stressful time like know nothing working felt like right path somehow kept going dont know darkest moment youve gone mind time tougher moments said self doubt yeah yeah whered go whered go mind moment youre like laying hopeless well theres couple moments im remembering mean whatever reason like big chip shoulder time like really want something important world like know could good life like work good companies write software im reason never wanted probably would healthier honestly like expected value outcome thats probably better thing life like like man really want something important bigger impact like willing sacrifice lot like sleep going friends stuff remember one like years working stuff remember one darker moments probably like maybe five employees time remember like bunch bad things happened like first remember time sleep deprived kind exacerbates everything look like exxon valdez spill like natural disasters like sleep deprivation often involved reason sleep deprived working much like site would go offline middle night wed get id get paged like pager duty id get woken sometimes like two three times night like try fix something go back sleep environment kind get get discouraged one bad thing happened bug website thousands people reddit twitter like pissed coinbase like balances showing wrong like fuck company like hate guys id never feeling thousand people mad time know feel like im pretty chill guy like time people dont get mad one another one pause thats interesting saying like heres dream im trying create something forever reputation dream ruined never irrecoverable kind feeling yeah well didnt youre right didnt know time like end like everybody tiny everybody hates us yeah nobody told starting company like youre bunch people hate like counterintuitive thing cause know companies think good things world least youre trying right even someones like trying theyre theyre failing im generally rooting least youre trying right thats case founders ive known gone theyre surprised amount hate get think actually like muscle build tolerance like know go talk somebody whos like feels terrible cause youre center storm like go go talk like know family person like dude didnt even hear like theyre busy life idea negative press like whatever put put link yeah theres interesting person id like bring example bill gates yeah gets large amount hate internet yeah theres something talking seems touch hate believe least understanding resources hes trying actually lot good yet theres gigantic amount hate conspiracy theories stuff like right feels like thats case hes somehow touch people internet really finally taking hold theres billions devices everybody voice almost basically governments powerful people slightly losing hold power theyre starting freak little bit thats young people coming gain power think well rebalance everything theres like said promising signs obvious majority people want freedom means lot things means economic freedom means freedom voice freedom move around freedom act way without reasonable sort limitations people dont best interests gain hope regular people fighting like demanding able freedom speech specifically sort resisting crude overreach government acts censorship least united states hopefully percolates rest world thats struggling much basic level people put prison words say banned twitter right could worse lessons failures successes takes run company think one things learned leadership never really thought natural leader honest dont think natural leader always envisioned good leaders like military generals like seem confident theyre like bark orders charge hill actually like introverted kind wasnt really confident way communicated realized theres lots different kinds leaders kind ceo want right kind like product technical focus ceo preferred sort hear everyones opinion wasnt gonna like render decision room like kind heated moment like piss half people would like right im gonna go think ill send decision later today tomorrow whatever found ways kind make work could basically always tried avoid like people getting like super emotional something like think theyre thinking judgment goes right like never make decision youre angry right would always sort try get sense people like trying right trying seek truth little tricks like okay argue persons position argue one like see genuinely represent know youre listening kinds things guess sorry getting back question leadership think basically kept things little outside comfort zone comfort zone kept getting bigger bigger know think thats build confidence thing thats scary like little outside like first started coinbase never managed anybody would scared death put like controversial opinion like sort right 5 people go didnt know percent gonna way could 1 could 50 like went scary scary thing like dont know think right im gonna enough scary things like youll build confidence feel like im still journey every year two coinbase theres big thing comes like oh god like didnt sleep well week like next level right thats learn grow youre still going mountain fog one step time yeah quickly ask couple efforts super interesting youre involved first little bit old school fascinating effort research hub whats github open science yeah okay basically ive chance try help couple companies get ground cause wanna see various efforts succeed one ive always thought like scientific research like open source software couldnt much faster right theres youve probably seen like academic setting right theres kinds things feel antiquated scientific research everything funding process grants peer review works submit journals costs associated journals know people youd think like youd get paid something would available taxpayers free theyre like theyre pay walled theres like big companies sort view kind held back innovation preprint servers like bioarchive archiveorg really helped websites look like theyre kind like 15 years ago something yeah like craigslist something yeah anyway one things coinbase went public last year little bit liquidity like right let fund small team lets see like go make something better prototype researchhubcom people check basically know first version kind like reddit science theres like various hubs like journals know publish papers use electronic lab notebook sort modern day paper pdf thats static living document ideally future know get comments feedback people update time want people able share code data sets associated paper research paper pdf future want make even like know people get funding science site even license innovations theyve made thing ive noticed life theres kind like theres bunch people working science theres bunch people building companies rarely intersect get best things like spacex genentech even google like even coinbase based research paper bitcoin white paper business people like creating companies dont scientific innovation theyre like marketing based know whatever lot scientists making things never actually benefit humanity theyre commercialized turned products somehow create translation layer two groups help know helps align market forces align scientific research market forces theyre incentivized like discover crispr something like like billionaire know like downstream implications going antiquated tech transfer office whatever youre entrepreneur looking commercialize latest scientific innovations thats kind like longterm vision site think early step today weve got like really passionate community jumping like know computer science longevity various bio hubs whatever like beginning source best innovations also discuss improve publish site question incentives first let say people listening outside academia might familiar absurd situation theres journals like mentioned scientists publishing journals journals provide little value except matching reviewers unpaid digital world theyre providing basically almost value except hosting paper put paywall charge people access charge like even netflix fees youre talking lot money theyre basically blocking research wide open world creating paywall fascinating like scam thats actually holding back dont shitty scam youre making much money feel like definition scam least making money like significant amount money youre basically making shady money holding back human knowledge okay put aside people get little confused journals arent ones paying scientists people think like journals somehow funding scientists therefore right put paywall funding coming elsewhere journals middleman nobody asks especially digital world anyway said interesting kind incentives scientists prestige theres thing journals theres prestigious journal pass review process get journal prestigious conference computer science thats seen good thing resume oh resume within community thats respected thing way achieve kind incentive open setting research hub like could say got x z like look im impressive happened research hub think youre right like whole academia like progress track like got published many citations kind like false economy reputation like theres real money backing think weve thought little bit think research hub team opportunity something basically says like okay top paper 2022 biology basically publish list leaderboards like top month year different categories actually probably give grants awards addition fund people almost like fellows even give like know like nobel prize like research hub prize something like ship people maybe even ship like print version journal top papers category month whatever like people want put wall lab like think need sort change dont know like traditional folks academia science would probably think like crazy idea think need change culture celebrate getting published paywall journals almost like friends dont let friends publish like paywall journals like cause thats helping humanity like know prestigious publish open science way get top spot celebrated published whatever dont even want name one know well theres currently culture already shifted almost everybody publishes archive archive yeah culture scene friends dont let friends publish open prestige thing missing like anyone publish archive know actually strong paper funny enough even crappy systems word mouth powerful like like citation system pretty powerful like say okay strong paper dont need reviewers human eyes reviewers like community reviewers already like part would nice like know nature level like respect respectful accomplishment yeah something like leaderboard stable kind system yeah mention theres crypto angle research hub coin associated research coin basically people know upvote paper like support youll accumulate research coin basically like rep like reward token way guess measure communitys collective view paper form peer review even weighted like reputation people voting sort thing time yeah think last thing ill say think rep like prestige point view wont start way itll probably start like little quirky like know like remember youtube first started like people posting weird cat videos stuff like know million subscribers youtube thats probably better getting like tv show nbc whoever traditional gatekeeper hope might take 10 years 20 years whatever im hoping sort new prestigious way young people publish science itll come viewed prestigious journals traditional journals viewed old fashioned well definitely system could lot better theres lot incredible brilliant people science deserve better better platforms another thing youre taking helping new limit looking longevity whats idea yeah okay see im excited science like think know science sort basically get scientific innovation get better products get better economic growth get kinds like surplus society go arts philosophy like kinds stuff new limits yeah kind got started hosting dinners scientists last year learning kinds latest stuff happening bio theres lot really cool stuff happening like car cells crispr things anyway one topics started learn something called cell reprogramming know people maybe heard induced pluripotent stem cells could take like skin cell turn back stem cell shinya yamanaka nobel prize work done 2006 know kind crazy thing turn one cell another type cell well people recently experimenting different types transcription factors would either dont want cell go way back stem cell end getting like cancerous cells things like want basically cell revert little bit earlier know would call waddington landscape basically like go become act start act like bit younger cell de differentiate become like stem cell decided might interesting area go fund think team come together theres like really talented people whove come together help get ground theyre basically building platform test lot different transcription factors different cell types hopefully find ways rejuvenate different types cells tissues extend human health span mean moonshot goal know get mars could therapy dont know 10 20 years take whole body point view sort rejuvenating tissue one type tissue like immune system eventually whole body maybe even brain know dont issue people older trouble learning theyre ossified thinking always think know actually little inspired elon right like biggest things world like probably high technology risk work maybe theyre kind low chance working work would enormous impact like idea trying hard tech problems especially people like founders like whove made money software think kind like golden age software theres like fortunes made make money hope people like atoms bits know try harder things like biotech know guess hes cars rockets stuff anyway think try hard tech know physical science problems well see advance team human yeah hes also bio neuralink feel like bio tough messy dont understand well dont understand risk higher terms risk higher like deal actual sort get human get stuff could therapies actual human bodies tricky prove safe effective kinds things fda mean tricky difficult long journey mean give quick plug yeah im board new limit hiring talented scientists interested cellular programming space dont necessarily coming like aging background anything like theres sort small group people even new thing new limit relatively new yeah new theres small team today handful people hiring people excited space reach thing research hub theres small team thats really awesome thats like software engineering design product kind stuff advice would give put old wise sage hat advice would give young people today high school maybe undergrad college life like career career proud maybe life proud people whatever want happy right theres one way think people particular type people lot people actually want impact world thats get sense fulfillment right mean need like health physical health need good relationships like theres lots things people want something important want fulfilling work way feel like theyre contributing think lot people young people today thinking like activist something like theres people world power lot people dont dont power way change world speak truth power like criticize power try pressure change dont think thats right way actually impact world everybody probably think people power realize way easy critic hard actually change things fix youll get lot accolades friends things like kind go around criticizing easy like everything broken could better including stuff im working find like frustrating theres million things want better like coinbase person arena like theodore roosevelt quote think said right like go chew glass stare abyss like really want impact either join company mission trying fix thing youre passionate start company doesnt exist start charity suitable company whatever go try part solution dont criticize part problem hope people realize actually meaningful impact way think technology actually one important ways improve world like look climate change like lot best ideas like carbon sequestration things technology thing right want try fix education like look like khan academy stuff going online right want fix know whatever transportation like financial system global freedom like equality things like theres typically way get something changed world today technology think people bizarre theres kind like anti tech thing going look nothing perfect like create something new like tens millions people use billions people use like theres going bad people use okay theres know society complicated like think things net positive people world good least view yes mitigate like 1 bad people trying abuse something 99 people world good way improve world technology joining companies starting companies working right stuff hope young people youre sure like get started anything thats learn basically optimism power change easy distract critic thats almost like acknowledging thats basically everybody power fixer like chew glass look abyss thats much fun sounds think meaning whole thing life yep whats meaning life whats existence got youre trying increase amount economic freedom planet trying alleviate suffering yeah dont really think point life know somebody told know go like kind really big existential questions get little scary like stare cliff theres like theres nothing know one person told one time like know brian probably snorkel dont scuba guess think trying say like friends done right theyll go like know epic meditation retreats like theyll kind come back existential dread like whats meaning like far tell organic molecules ocean started like dividing replicating selfish gene stuff like basically ended kind like really naive algorithm thats kind trying get us survive replicate dna like every animal happened develop like really cool neocortexes sort self aware big questions maybe well create another know computers get better well create simulation inside thing think cool like basically want keep watching movie know unfold thats part want work like new limit really cool cause helped people live longer whether thats uploading brain cloud know basically get biology work strong ai work whatever one two hopefully works get keep watching movie see unfolds think thats fun dont know thats like answer guess dont think theres real purpose try fun well cool thing get write movie watch yeah thats exactly right mean thats like steve jobs quote hes like everything around invented somebody like crazy idea thought realize kind anything want thats start go start go try crazier stuff mean another one areas get like know youre think build comfort zone around like people upset also build range think possible right like 20s like reading books like self improvement goal write goals stuff goals like someday wanna make 100000 year something like know seemed like little outlandish wrote goals like wanna rental property something anyway slowly started get things done couple years started think little bigger remember one time wrote goal like whats craziest thing could think like wanna write wanna start billion dollar tech company thats crazy never started like million dollar tech company tech company really business writing goal remember wrote piece paper like like probably every day year something almost right dont know every day like wrote lot little things started happen like right well maybe move back bay area buenos aires maybe try apply combinator whatever like started thinking ideas whatever gets fired doesnt like company goal startup thing could anything right maybe wanna publish book like something creatively whatever anyway think like within seven years probably like 10 years writing goal coinbase valuation billion dollars realm even possible within 10 years accomplish 10 years think less year think im like okay whats next goal whats okay maybe wanna get billion people accessing open financial system products every day would cool humanity thats pretty crazy goal like theres 8 billion people something right theres one eight maybe radically like make like right investments whatever like help radically extend human health span whatever right try crazier stuff dont know even doesnt work like hopefully youll advance state affairs like something interesting happen people today look people trying stuff theyre like oh god theyre theyre genius whatever like theyre idiot like one two neither one true like anybody start thinking want like go get like go something little bigger like fun universe way smiling helping write dream big theres something karma energy put world people help doors open youll notice doors opened actually shot making happen funny world yeah mean dont really subscribe like woo woo interpretations rational brain interpretation wake every day write like want get done towards longer goals larger goals mind day start notice opportunities think brian thank dreaming big thank youre incredible engineering scale trying help people world actually helping personally get crypto cause easy thank much thank much giving extremely valuable time today awesome conversation thanks awesome podcast love listen often thanks listening conversation brian armstrong support podcast please check sponsors description let leave words benjamin franklin investment knowledge pays best interest thank listening hope see next time wonder stay touch voice people without destroyed outrage wisdom dont know wisdom ive thought yeah wanna always open feedback especially people like best interests heart right become isolated like know surrounded yes people mean knows maybe like putin people like situations idea listen much try please everyone youll never get anything done mean best leaders people act believe theyre something net positive world humanity actually dont really care piss portion people almost anything youre gonna significance world today gonna piss 5 people maybe 49 people whatever maybe 60 dont know never wanna become surrounded people work say yes think like well im genius im like thats become dictator whatever also cant care much people think youll never anything thats truly authentic one thought way think really good question ive thought lot like know people generally kind hate zuck hate bill gates hate dont really hate elon well actually elon lot haters different thing measured measured looking surveys think zuck loved hated right zuckerberg loved hated hes hated think bill gates elon think like 40 hate zuck people asked elon double digits low double digits interesting look data ask right ask sometimes dont claim know people well like ive met briefly impression theyre actually smart people trying good things world theres much difference despite public perception really hated arent mean complicated question obviously zuck facebook got blamed whole election thing didnt help social media gotten lot pressure like hey arent solving societys tough problems like well theyre one company one thing ive noticed lot people like aspergers right little bit sometimes people aspergers dont really emote way think almost form like bias cognitive type something like person doesnt emote right dont trust intentions thing ive thought sometimes think leaders like maybe zuck bill gates come across like little bit pr rehearsed like theyre basically theyre giving pr approved answers elon says whatever thinks like fault even people hate says like least believe authentic ive always thought im like cause fuck sides right like come youre like saying whatever stream consciousness youll often end like pissing people team like saying tripping like regulation youve theres kinds things running public company cant say certain stuff youre pr approved answer like nobody trusts youre saying anyway something think lot dont think right answer im trying find balance internet theres premium authenticity like youre saying people really really appreciate leaders challenge make sure im authentic also dont say stupid shit thats interesting thing ive noticed interacted bunch leaders careful much surround pr folks best would say let say nice thing marketing pr folks best marketing folks extremely good understand exactly great marketing great pr authenticity showing revealing beauty opposed pr marketing fear oh dont say dont say dont start living kind pushes towards bubble cant express beautiful quirks weirdness kind stuff also cool beautiful things youre find like especially tech things like even like coinbase way reveal beauty showing things could showing theres great engineering going underneath letting nerds shine doesnt like kind commercials like happy family using coinbase send transaction flowers mom something like like could also like gritty stuff real stuff thats general observation made said talking dark moments theres people internet pissed site said might something else yeah sleep deprived like bunch people internet pissed balances fucked like people tweeting companys give money back whatever oh yeah somebody posted didnt started get customer support inquiries like like people company backed maybe like 20000 support requests people couldnt get ahold us somebody posted cell phone number reddit like like need get ahold ceo whatever cause everyones upset money remember office like late night weve working like 12 hours sleep deprived im trying hack like get bug fixed need like food office phone blowing day cause someone posted phone number internet theres like guy guy like trying deliver food needed answer phone like get food downstairs like shit gotta see thats started answering call like brian im like nope wrong number click pick next call like every finished call another call like coming like im reporter japan like asking security nope wrong number click like finally get delivery guy downstairs bring food like surviving like fix bug remember basically point night like fuck need basically curled like ball floor like cried little bit think let kind wallow self pity kind took nap five minutes like lets fucking solve like know stop like little whatever like got back sleep deprivation combined stress pressure site going everybody wants site pressure people number users growing growing growing pressure mentally mentally tough source strength time like like somebody patted back said got yeah well definitely helped co founder know theres like old saying better great relationship single better single bad relationship co founders actually blow lot companies find right co founder lucky find fred important definitely moments know like kind know width end whatever like like dude lets rally like basically carried team know couple times like really key moments advice would give startup founders particular stage surviving five five employees stage yeah well pre product market fit best advice period action produces information like keep stuff know remember like paul graham paul graham great line like think thats line like startups like sharks stop swimming die know even youre like sure like anything itll like itll produce information like people liked didnt true times something instead debating endlessly like try know like right shipped like couple times like minute shipped like knew know built wrong idea next wasnt would idea wed actually gone exercise going build like favorite analogy youre like base mountain thats shrouded fog youre looking mountain youre trying think like okay get see like three four steps ahead cause fog thick take steps unknown take three steps another three steps revealed ahead sometimes youll end local maximum youll retrace steps whatever come cliff know people life dont take steps fog unknown scary theyre like dont know fail like dont know thats going work might run money wont able get job dont know whatever reason like one things separates think entrepreneurial people kind inclination sort comfort risk tolerance actually really risky think like know least places like know go startup fails like youre going youre even valuable next employer right go raise seed round pay salary try like two years three years doesnt work go get another job like youre werent paying salary time think think people overestimate risk startup never never start seems crazy friends think silly like thats sort default nature every big startup idea basic fear kind fear see youre guy see cute girl bar fear associated coming like asking like whats actual risk exactly right shell say thanks im interested thanks guess risk like thats going mentally difficult deal rejection like mentally difficult deal failure bunch ideas excited implement realize theyre good could difficult keep pushing suppose thats life youre supposed know perseverance failures risk low thats whole time fog mountain youre looking product market fit yeah thats right know usage product keeps growing without marketing dollars anything like like people keep coming back every week month youre kind keep youre basically watching stats nothing working see little wiggles false hope metrics basically keep talking customers fixing improving product talk customers improve product talk customers improve product know try run money really scrappy youre lucky hit kind threshold like okay thing good enough hit use case itll organically start grow bit whole different set problems hit product market fit scale thing hire people know hire executive team raise money like problems totally change yeah well whole thing thats question thats fascinating back girl bar hire people like find good friends find good relationships specific case hire good people engineers executive one thing ive done lot reps hiring point coinbase 5000 people probably first 500 people something maybe range know interviewed every single one remember theres probably like dont know average maybe 10 people went process every one hired something like time 500 employees done like 5000 interviews something like burned interviews days like seven interviews day maybe know youve lots interviews maybe wouldnt get burned different kind interviews different different different youre first interviews lead rejection yeah also exhausting yeah theres whole part interview candidate experience right sometimes know right person wanna make sure good experience yes like youre exhausted youre sixth interview youre like well thanks coming wrap like youre gonna create detractor someone whos like fuck company brian rude whatever honestly work little bit early days many interviews like needed make sure people came like know made feel comfortable asked couple like warmup questions like oh getting office like find okay like week like know like factory assembly line like boom boom boom like yeah also theres moment cause ive interviewed bunch people like teams stuff theres also moment early know gonna good fit still land plane kind stuff could get really really really exhausting yeah anyway sorry yeah basically tried weve tried many things years make interviews efficient cause huge time sink team know basically well usually get like 25 minutes ive seen youre trying hire like big team lets say know people like contractors something necessarily full time employees ive seen people actually 10 minute interviews even interview like thousand people almost like week something im sure quite works let little less basically get six six done hour youre need get team 30 contractors whatever purpose youre talking full time employees usually like 25 minute know youre oftentimes like one thing weve done well put like google form online like put basic hurdles like know ask put answer check spreadsheet correct like funny examples early days coinbase wed put like brain teasers stuff dont anymore like normal interviews references kinds things ask interviews know usually like like think need person accomplish role right get really specific like usually something pretty hard ill ask question like tell time x tell hardest hardest kind problem youve solve specifically overcome right im asking see actually stuff need get done im also kind asking like culture questions im interviewing im trying see like concise communicators give clear answer stop talking people like ramble like five 10 minutes ask first question people know theyre interrupters like church interruption like wont stop talking interrupt im always patient wait thats weird im looking see humility like know ill tell us people ill tell time something went really wrong like conflict someone team im kind looking part solution still holding onto like blame criticism like well told shouldnt way didnt listen know like bad signs im looking yeah get job done work together team communicate effectively fit cultural values know kinds things yeah mean theres cause ive even help podcast also mit ive done bunch hiring always looking said brain teasers kinds simple questions reveal lot information always challenging used still ask question think better work hard work smart know idea ive think ive matured kind believe people say work smart question dont actually work smart right textbook answer better work smart reality people havent actually ever done anything say work smart theyre like havent really struggled general belief time order discover means work smart efficient work ass really fail lot failure feels like hard work always suspicious people would say work smart would want interrogate question also know learned people exceptionally exceptionally efficient really know means work smart even young age like cant disqualify based dig deeper interesting people ive ever worked would say work hard unapologetically theyre usually ones know efficient interesting thing like ive always searched questions nature see get person reveal something profound brief question possible know course theres basic attention detail brain teasers stuff like depending role programming see solve tricky puzzle like one doesnt require lot effort requires certain nonlinear way thinking mean maybe dont want reveal questions sometimes find leaning said like solve hard problem past talk thats one know started brain teasers periodically coinbase got away relatively quickly think one tough one actually think show somebody kind performs pressure dont think super reliable indicator theres people really good typical work situation thats typical work situation somebody puts spot like live interview sometimes people get nervous cant think clearly like dont computer front whatever normally use yeah im little skeptical brain teaser thing whole yeah whole question like lot universities getting rid know entrance exams youre hiring right universities sometimes becoming less reliable indicator like university ive heard companies havent done yet ive heard companies actually creating like college grads like basically exams like standardized testing almost get people door degree almost like doesnt mean used whole topic yeah thats fascinating fascinating trying hire great team also help find right place work yeah like two way street right found product market fit coinbase become today ooh let ask engineering question actually sort ruby wallet days interesting challenges engineering things solved engineering regulation financial hiring lawyers post product market fit yeah lot scaling got build actual company remember still writing lot code hiring like maybe 25 people something remember one investors came one day like brian much time spending writing code like maybe 50 something like much time spending hiring people like probably 20 like think need flip numbers like company going scale youre ceo dont need writing code every day youre going transition stuff like even people cant stuffs locked head maybe theyre going well first six months something like dont start transition youre never going build real company going youre going bottleneck know like lot founders took like really internalize lesson id always heard people say know still holding much decision making probably still way like even day coinbase continually push decision making org like even 5000 people like owners things temptation people push become bottleneck anyway yeah basically need make sure enough money dont die theres kind downturn hit break even profitability position periodically profitable periods crypto would go unprofitable kind manage psychology balance sheet make sure didnt like die downturn lot crypto companies basically professionalize whole bunch services quickly thrown together like 20 year olds right whether cybersecurity like okay get like really senior experienced cybersecurity person someone whos senior cant get hands dirty come company 25 50 people get finance person come finances mess like didnt even really know much money certain times stuff mean embarrassing say true like remember point raised think like series c something like think bank accounts put like 25 million like different bank account none stuff touched actual operations business cause like operations messy needed hire new finance person like id heard horror stories actually startups thought x amount money turned way less whole thing insolvent like three weeks wanted padding least like right least count save us go like super negative right mean like cheap hack like could come could hire like real cfo finance team like okay got arms around much cash sounds silly high volume money coming anyway ordering hiring way like many engineers early said cfo didnt even cfo bit like landscape hiring building company engineering focused well lets see mean first person hired like need solve customer support brought someone staying till midnight every night trying customer support got engineers think maybe sixth hire something like recruiter cause turned need build hire person hire people turned great force multiplier youre going list eventually want hire senior people needed legal compliance needed really badly cause kinds questions legality hard find legal people work crypto like serious adults cause cutting edge new world yeah mean nobody like nobody three years experience cause around years yeah finding people adjacent fields theres certain personality type people willing join early companies structure cant really commit youre going team boss whatever like everythings chaos flux takes yeah hiring one hardest things early stage sure got find people crazy enough join journey one interesting things coinbase youve written weve talked well talk bit youre focused mission yeah youre kind think simplifies things makes hiring easier makes working coinbase easier makes mean similar elon thing pretty clear pretty clear suppose whats mission coinbase well increase economic freedom world economic freedom yeah economic freedom term kind like gdp economists use basically measure different countries around world looks things like property rights enforced free trade currency stable start companies wanna start join ones wanna join corruption bribery prevalent relatively free theres several different organizations basically score countries economic freedom really cool thing economic freedom basically positively correlates things want society like higher growth economy also things like higher self reported happiness citizens better treatment environment better income poorest 10 people negatively correlates things dont want society like corruption bribery war even things like pretty crazy provocative idea give people good property rights rule law allow trade basically encourages good stuff whole society benefits like one things may noticed growing various places spent year living buenos aires argentina went hyperinflation theres certain like pessimism creep countries dont economic freedom basically like everyone bit vibe like dont stick head dont try hard could gone tomorrow like things really valuable life family friends past better future dont really people dont try many dont try hard youre really sure actually keep upside labor try hard dont try hard whereas america historically high economic freedom countries people basically like try stuff theyre like good people ill get keep part improve lot life children community whatever realized read bitcoin white paper long time ago least hunch time like might really powerful piece technology inject good financial infrastructure countries around world dont basically good economic freedom principles like property rights things like countries world long smartphone crypto got invented everybody could economic freedom crypto kind really well suited economic freedom want property rights based like crypto remember 12 word phrase app phone store much wealth want cant taken away even theres like refugees need flee wanna take wealth cant often traditional financial system crypto lets right crypto inherently global allows free trade cross border payments makes easy accept payments people globally provides stable currency everyone'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_nostopw'] = corpus_nostopw\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Yn3udwP0jIe",
        "outputId": "e65647b7-0979-40e6-e27a-af43a305c70d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id            guest                    title  \\\n",
            "0   1      Max Tegmark                 Life 3.0   \n",
            "1   2    Christof Koch            Consciousness   \n",
            "2   3    Steven Pinker  AI in the Age of Reason   \n",
            "3   4    Yoshua Bengio            Deep Learning   \n",
            "4   5  Vladimir Vapnik     Statistical Learning   \n",
            "\n",
            "                                                text  \\\n",
            "0  As part of MIT course 6S099, Artificial Genera...   \n",
            "1  As part of MIT course 6S099 on artificial gene...   \n",
            "2  You've studied the human mind, cognition, lang...   \n",
            "3  What difference between biological neural netw...   \n",
            "4  The following is a conversation with Vladimir ...   \n",
            "\n",
            "                                        text_nopunct  \\\n",
            "0  as part of mit course 6s099 artificial general...   \n",
            "1  as part of mit course 6s099 on artificial gene...   \n",
            "2  youve studied the human mind cognition languag...   \n",
            "3  what difference between biological neural netw...   \n",
            "4  the following is a conversation with vladimir ...   \n",
            "\n",
            "                                        text_nostopw  \n",
            "0  part mit course 6s099 artificial general intel...  \n",
            "1  part mit course 6s099 artificial general intel...  \n",
            "2  youve studied human mind cognition language vi...  \n",
            "3  difference biological neural networks artifici...  \n",
            "4  following conversation vladimir vapnik hes co ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 4: Vector Space Representation - TF-IDF\n",
        "\n",
        "Create TF-IDF vector representations of the transcripts.\n"
      ],
      "metadata": {
        "id": "cY3gRAq90sC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_mtx = vectorizer.fit_transform(df['text_nostopw'])"
      ],
      "metadata": {
        "id": "L4DZ5WTw0tcM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'Computer Science'"
      ],
      "metadata": {
        "id": "PK12fY1w3GSm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_vector = vectorizer.transform([query])"
      ],
      "metadata": {
        "id": "hffDzM_q3KSl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = cosine_similarity(tfidf_mtx, query_vector)\n",
        "type(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TWzcfZo3Om8",
        "outputId": "935a0982-e9f0-4874-a449-8859864667e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_df = pd.DataFrame(similarities, columns=['sim'])\n",
        "similarities_df['ep'] = df['title']\n",
        "print(similarities_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN2hsXRu3bSQ",
        "outputId": "9ea004c9-2c93-4dec-9af8-5fdca473892a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        sim                       ep\n",
            "0  0.045080                 Life 3.0\n",
            "1  0.072728            Consciousness\n",
            "2  0.014514  AI in the Age of Reason\n",
            "3  0.056815            Deep Learning\n",
            "4  0.023408     Statistical Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k7wYThSa3fJi",
        "outputId": "59529ef0-5155-4442-870d-b51753ba3b59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          sim                                                 ep\n",
              "0    0.045080                                           Life 3.0\n",
              "1    0.072728                                      Consciousness\n",
              "2    0.014514                            AI in the Age of Reason\n",
              "3    0.056815                                      Deep Learning\n",
              "4    0.023408                               Statistical Learning\n",
              "..        ...                                                ...\n",
              "314  0.036157    Singularity, Superintelligence, and Immortality\n",
              "315  0.018635   Emotion AI, Social Robots, and Self-Driving Cars\n",
              "316  0.000945  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
              "317  0.003397                                              Poker\n",
              "318  0.030312  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
              "\n",
              "[319 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8d7fb36-c460-4d57-aa0f-60f0066550f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>ep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.045080</td>\n",
              "      <td>Life 3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.072728</td>\n",
              "      <td>Consciousness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.014514</td>\n",
              "      <td>AI in the Age of Reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.056815</td>\n",
              "      <td>Deep Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.023408</td>\n",
              "      <td>Statistical Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>0.036157</td>\n",
              "      <td>Singularity, Superintelligence, and Immortality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>0.018635</td>\n",
              "      <td>Emotion AI, Social Robots, and Self-Driving Cars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>0.000945</td>\n",
              "      <td>Comedy, MADtv, AI, Friendship, Madness, and Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>0.003397</td>\n",
              "      <td>Poker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>0.030312</td>\n",
              "      <td>Biology, Life, Aliens, Evolution, Embryogenesi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d7fb36-c460-4d57-aa0f-60f0066550f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8d7fb36-c460-4d57-aa0f-60f0066550f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8d7fb36-c460-4d57-aa0f-60f0066550f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09ad2aef-f39d-4d0d-aec3-5320e194babf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09ad2aef-f39d-4d0d-aec3-5320e194babf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09ad2aef-f39d-4d0d-aec3-5320e194babf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9ddab861-6d62-446f-93ce-16376ea3b173\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('similarities_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ddab861-6d62-446f-93ce-16376ea3b173 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('similarities_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "similarities_df",
              "summary": "{\n  \"name\": \"similarities_df\",\n  \"rows\": 319,\n  \"fields\": [\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02289658494365527,\n        \"min\": 0.0,\n        \"max\": 0.11099388085646306,\n        \"num_unique_values\": 309,\n        \"samples\": [\n          0.0074725594411843765,\n          0.006146241962354582,\n          0.047856522063188925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ep\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"Deep Learning, Education, and Real-World AI\",\n          \"Bad Vegan\",\n          \"Thousand Brains Theory of Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 5: Vector Space Representation - BERT\n",
        "\n",
        "Create BERT vector representations of the transcripts using a pre-trained BERT model.\n"
      ],
      "metadata": {
        "id": "p3YezhMz3jp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393,
          "referenced_widgets": [
            "b46eda1da079473982209305d673e3ad",
            "6654a5ce797a4863bb2ffc326e7b83a9",
            "8ef50d8494f94a67b165b0f4e85c2758",
            "c416f52d60654c5fbc15f07ac01bba54",
            "37727aadf3004a298e305c8f8c2bc0d0",
            "41f89ce905474f23b0da957185dc6010",
            "45f28cd635bc4050a9395ab7c2e3ff7b",
            "b2868e9638354bcaabec4874eccc7e5a",
            "dc0a60186fa64ce8af14320ef2d1997a",
            "c0156988a61540709c90529e5835044e",
            "9fa9566e61c040c89c3da5f5389d18fe",
            "e59ea67ad8db4e81b6d3319c49c51ea0",
            "d35655c190c34bdba475e2b3ff3e4abf",
            "16bb2b3bba9d4b1088a9ec1e5a9218ea",
            "98153321b1824ff5b206a93bfb8cd74b",
            "c91b3f353fc447f8aafd4c3846b7b716",
            "dccc3d1e1c0b4755b4186e21ae4c9bc1",
            "52a347dd66274d4b966ee1c09db56753",
            "51ea4ed8f0724db29c343e4303dfec38",
            "73e1dac54a264538a13561463bf8d198",
            "7da8435e826b4d4492584875e25477bf",
            "67ad53c9850b416e89aebf168c2bd36a",
            "d911a0b72dd64068837db0561769ebf0",
            "df85ebc1ea3e46be844552e1ccf99d2a",
            "568bdcd6f8234fb88621a48dd255d762",
            "b3b2d668eecf4879bad9b67b384106fe",
            "fa480ddc171640fd871d9601b2bd6794",
            "3f86a58d27854e4f8cec469b44110dc8",
            "beaf2f9bc7a948b1ba3e0eb9d78a1ffe",
            "940b79d26d4a43ad8d6c2e5c6ff7d4f2",
            "185076c58401491abbc4134a1cd7ebc7",
            "14557273c3b1403eb8c0806a4dfebd6f",
            "f476010e050a473995790659e4d3f9cb",
            "d369f4327c3c40bead8de6badc36ae2d",
            "3fe7d6f17be44e0b91866ad20722c126",
            "eff156f4b3fd46a4aea43bf6a83f9e56",
            "f1970e95d98d4b2da0d87169a1b02b51",
            "2ce49dc271e34bae99ac9e6c44f3f71e",
            "9128952178f34493b6e4cc9ab37b6cf4",
            "f0dde6d2ae3c475eb9d1d43a59973f3d",
            "fd61cc41c3154062ba71eca6ff404b66",
            "75174c8ddea54fa9abaa1f3d922fcfed",
            "b05d502e10a84b5db2c7ee79c0c35875",
            "4658afc476ec4298b85ee6f07ff59834",
            "23195e6157d34b05b8259f8d53f3324e",
            "8aff3b2efc5a4598919df79da0dd5a7b",
            "3425e9af1a064f37889aa72f04cd52ff",
            "b2de67991d8d48a182a9cb6179c85503",
            "7b2e0a4976ab4c42b7c5aa54e08bc5f2",
            "4e53bee0ef0341d692c035be884d01f1",
            "e6f5bcd9d8494012983cc2c3e406211b",
            "d909f8d64fbf4963ad60265a3e9f8936",
            "81158416b7554322959e1b9c1e07d2c6",
            "cf1e456ddcbb4fef88347f028acd2f7e",
            "10c9c16ff6914d10ba02b9dc4c95a8d3"
          ]
        },
        "id": "4LvVCA6J3k3C",
        "outputId": "68010d2a-20d7-48b3-b35b-5597114cfcb9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b46eda1da079473982209305d673e3ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e59ea67ad8db4e81b6d3319c49c51ea0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d911a0b72dd64068837db0561769ebf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d369f4327c3c40bead8de6badc36ae2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23195e6157d34b05b8259f8d53f3324e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bert_embeddings(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
        "        outputs = model(**inputs)\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token representation\n",
        "    return np.array(embeddings).transpose(0,2,1)"
      ],
      "metadata": {
        "id": "BvCbVd1N5Wdj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_bert = generate_bert_embeddings(corpus) #Full corpus"
      ],
      "metadata": {
        "id": "9Tg54n4y5nCb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_bert.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZLZ5soK6MeG",
        "outputId": "b18c27c6-49c9-4e20-8131-cfffe26376ac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(319, 768, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = ['Computer Science']\n",
        "query_bert = generate_bert_embeddings(query)"
      ],
      "metadata": {
        "id": "Y2nINN0V6T9o"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_bert.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOKQcf1q6UfI",
        "outputId": "9fa71cb2-5724-437f-d6e1-727b186bef0d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = cosine_similarity(corpus_bert.reshape(319,768), query_bert.reshape(1,768))\n",
        "type(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkhZzx5J6gWf",
        "outputId": "11106a6e-e821-46f4-fb92-c27fd47bf596"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 6: Query Processing\n",
        "\n",
        "Define a function to process the query and compute similarity scores using both TF-IDF and BERT embeddings.\n"
      ],
      "metadata": {
        "id": "Ap-M9_Gj7DAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT\n",
        "\n",
        "Create the embedding using tokenizer, load in dataframe with the cosine similarity and the tittle"
      ],
      "metadata": {
        "id": "evuFKouc7Snp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_bert(query):\n",
        "    query_bert = generate_bert_embeddings(query)\n",
        "    similarities = cosine_similarity(corpus_bert.reshape(319,768), query_bert.reshape(1,768))\n",
        "    similarities_df = pd.DataFrame(similarities, columns=['sim'])\n",
        "    similarities_df['ep'] = df['title']\n",
        "    return similarities_df"
      ],
      "metadata": {
        "id": "5ixTsTuu7Oha"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_similarity_query=retrieve_bert(['gpt'])"
      ],
      "metadata": {
        "id": "pbNWTE917R7J"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF\n",
        "\n",
        "Vectorize the query and create the dataframe with the cosine similarity"
      ],
      "metadata": {
        "id": "v9iHBTOC-PbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_tfidf(query):\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    similarities = cosine_similarity(tfidf_mtx, query_vector)\n",
        "    similarities_df = pd.DataFrame(similarities, columns=['sim'])\n",
        "    similarities_df['ep'] = df['title']\n",
        "    return similarities_df"
      ],
      "metadata": {
        "id": "NmDtICfP-FXu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_similarity_query=retrieve_tfidf('gpt')"
      ],
      "metadata": {
        "id": "A0i1upO7-57R"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Retrieve and Compare Results\n",
        "\n",
        "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
      ],
      "metadata": {
        "id": "sA1gSCqV_BOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ordenar_df(df):\n",
        "    return df.sort_values(by='sim', ascending=False)"
      ],
      "metadata": {
        "id": "BTwDXk5G_EGD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Test the IR System\n",
        "\n",
        "Test the system with a sample query.\n",
        "\n",
        "Retrieve and display the top results using both TF-IDF and BERT representations."
      ],
      "metadata": {
        "id": "M29vDXCV_RH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF"
      ],
      "metadata": {
        "id": "dmTLnupx_lQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idf_top_df = retrieve_tfidf('gpt')\n",
        "top_idf = ordenar_df(idf_top_df)\n",
        "print(top_idf[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxm936mV_SiX",
        "outputId": "ff380f45-515e-4a7e-bdeb-773c14139848"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          sim                                                 ep\n",
            "213  0.099371  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
            "17   0.032536                                     OpenAI and AGI\n",
            "94   0.028676                                      Deep Learning\n",
            "120  0.028510                    Friendship with an AI Companion\n",
            "117  0.025214  Math, Manim, Neural Networks & Teaching with 3...\n",
            "119  0.011263                           Measures of Intelligence\n",
            "130  0.011053  The Future of Computing and Programming Languages\n",
            "276  0.007757                         Sara Walker and Lee Cronin\n",
            "35   0.007033         fast.ai Deep Learning Courses and Research\n",
            "266  0.006228  Origin of Life, Aliens, Complexity, and Consci...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT"
      ],
      "metadata": {
        "id": "VR8B_S4u_m3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_top_df = retrieve_bert(['gpt'])\n",
        "bert_top = ordenar_df(bert_top_df)\n",
        "print(bert_top[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8dQ03OF_isv",
        "outputId": "873e98e0-36bb-48f9-e59b-49d8fcce39e4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          sim                                                 ep\n",
            "216  0.709173  Virtual Reality, Social Media & the Future of ...\n",
            "49   0.703856    Neuralink, AI, Autopilot, and the Pale Blue Dot\n",
            "199  0.669967                        Totalitarianism and Anarchy\n",
            "133  0.666933  On the Nature of Good and Evil, Genius and Mad...\n",
            "39   0.660287                                             iRobot\n",
            "153  0.659555  Aliens, Black Holes, and the Mystery of the Ou...\n",
            "96   0.657686           Going Big in Business, Investing, and AI\n",
            "163  0.654897  Sleep, Dreams, Creativity & the Limits of the ...\n",
            "34   0.654668        Machines Who Think and the Early Days of AI\n",
            "273  0.654259        Bitcoin, Inflation, and the Future of Money\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Compare Results\n",
        "\n",
        "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
        "\n",
        "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "The relevance of the results differs between TF-IDF and BERT, as TF-IDF produces lower and less precise similarity scores, with less relevant and more general episodes, while BERT generates higher scores and more pertinent results to the query. In terms of strengths and weaknesses, TF-IDF is easy to use and effective with simple texts, but it struggles to grasp deep context, limiting its effectiveness in complex queries. On the other hand, BERT better understands meaning and context, providing more relevant results for complicated queries, although it is more resource-intensive and complex to use. In conclusion, although TF-IDF is suitable for simple tasks, BERT provides better results for complex queries thanks to its better understanding of the content."
      ],
      "metadata": {
        "id": "qqP36I3R_9v-"
      }
    }
  ]
}